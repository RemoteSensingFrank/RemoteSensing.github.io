<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="随感，遥感，机器学习....想到什么写什么"><title>吴蔚 | 生命不息，折腾不止！</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/5.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">吴蔚</h1><a id="logo" href="/.">吴蔚</a><p class="description">生命不息，折腾不止！</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h2 class="post-title"><a href="/2017/08/15/tensorflow-第九弹/">tensorflow-第九弹</a></h2><div class="post-meta">2017-08-15</div><div class="post-content"><p>说过要做读书笔记的，说话要算话，从今天开始一天至少看一节；  </p>
<blockquote>
<p>神经网络的拓扑结构随着时间的变化也在不断的发生着变化，但是我们可以使用一种统一的范式进行描述，我们可以将神经网络简单的描述为神经一个有限元的集合 $N={u_1,u_2…,}$ 被称为节点或神经元和以及有限元的集合 $H\subseteq N \times N$ 被称为边，相互按照一定的方向连接组成的网络。神经网络的表现由一系列变量决定，这些变量我们称之为权重，由于神经网络是一个复杂的网络，整体分析比较麻烦，另外各个层的网络存在相似性，因此我们目前只分析单个有限元的的一次处理，并不涉及到权重的变化过程。对于 $x_t (t=1,…,T)$ 其中每一个 $x_t$ 表示某一层神经元，我们称之为event，实际上对于任意的一个 $x_t (t=1,…,T)$ 它的值的来源方式存在两种情况，直接由环境输入，或者有前一个event的生成，我们考虑由前一个event生成的情况 $event_k-&gt;event_t$ 则 $x_t = f(net_k)$ 而 $net_k$ 为生成网络，而 $f$ 称为响应函数，生成的网络可能有多种情况，如线性网络，或者乘性网络，也可能有更加复杂的多项式网络。响应函数也有多种选择。实际上在神经网络的计算过程中不管是采用哪种网络类型，随着传递的层次的增加，权重参数的数目会以指数的形式增加，由此造成参数过于复杂的情况，在此情况下发展了共享参数的神经网络，权重参数的共享极大的减少了参数的数目，降低的我网络的复杂度。另外对于监督学习的情况，一般来说都是假设判断结果和实际结果的误差最小，由误差最小的原则对神经网络的权重进行调整，由此得到最佳判别的神经网络，另外监督学习的网络认为输入的event与上一次的event是相互独立的。这个假设在序列决策和增强学习中存在着问题，针对此问题发展了增强学习的方法，增强学习的方法假设下一次的evnet能够回推到输入的event，而权重的调整目标在于使得经过计算后的event能够最好的恢复输入数据。  </p></div><p class="readmore"><a href="/2017/08/15/tensorflow-第九弹/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/08/13/tensorflow-第八弹/">tensorflow-第八弹</a></h2><div class="post-meta">2017-08-13</div><div class="post-content"><p>好了，本来准备今天写写关于深度学习的东西，不过下午的时候找到了一本关于深度学习的书，介绍整个深度学习的过程发展的历史的，读了几章也没有详细的进行记录，看看做过的关于tensorflow的学习，觉得单纯的实践如果没有理论的指导的话就像依葫芦画瓢，不能对新的问题能够哦灵活的运用，而且单纯的CNN也不是能够解决所有问题的，所以还需要补充一些理论的知识，在理论知识夯实的基础上针对特定的问题进行简化和优化从而能够更好的进行学习，或者能够达到快速或通过较小的样本也能够获取比较好的学习效果的目的，所以接下来的几章应该就是关于这本书的读书笔记了……</p></div><p class="readmore"><a href="/2017/08/13/tensorflow-第八弹/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/08/09/无人机处理/">无人机处理</a></h2><div class="post-meta">2017-08-09</div><div class="post-content"><p>很久没有做关于tensorflow的更新了，主要的原因有两个，第一是这一周，从上周三开始都在参加培训，晚上很多时候都再加班感工，所以没有那么多时间去更新关于机器学习的知识了，而且我们关于机器学习的一些简单的介绍已经差不多结束了，下一阶段主要是更深入的介绍以及实现我们自己的机器学习算法，所以在这里我们就先把tensorflow放一放，差不多到这个周末再开始新的学习，另外一个就是最近把以前做的那个通过openMVG和openMVS进行无人机影像处理的的代码进行了一些重构和整理使得代码的结构更加的清晰，代码的可读性更好，另外将SIFTGPU引入，结合openMVG和openMVS进行特征点的提取和匹配以期能够最大限度的提高处理的效率。<br>额，说到这里还是要提一提我们无人机影像处理的整个流程和结构了，结构图为：<br><img src="http://blogimage-1251632003.cosgz.myqcloud.com/%E6%97%A0%E4%BA%BA%E6%9C%BA%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.png" align="center/"><br>我们稍微分析一下这个结构图，获取无人机影像数据后我们先不要想那么多，马上进行特征提取和特征匹配，因为后续的所有操作都离不开这两个步骤，这两个步骤也是前期最耗时的步骤，在完成这两个步骤后再进行判断，判断影像是否包含POS数据，如果包含那么就进行全局的调整，如果不包含则通过序列影像调整的方法进行处理，处理后得到稀疏的点云以及整体的各个影像的旋转矩阵，这个时候需要进行光束法平差，实际上图画得有一丢丢的问题，光束法平差包含在序列影像和全局影像求解的过程中，得到稀疏点数据后实际上我们就可以进行简单的影像颜色调整和拼接了，这个时候拼接得到的数据并不是真正射影像，仅仅是经过几何校正后的影像。进一步的处理就需要进行密集匹配，得到密集的点云，在密集点云的基础上进行正射校正得到正正射影像。<br>原理就简单的介绍一下，下面详细介绍一下编译的环境和其中所遇到的问题，主要问题在于，在linux下我们通过cmake文件进行编译，由于对cmake不熟由此造成走了很多弯路，另外由于宏定义的问题导致进行了多次的修改，由此造成版本比较混乱的问题，另外一个问题就是编译的debug和release版本的问题，在不同版本下运行效率差别特别大，所以这个也让我纠结了很长时间。在git的过程中由于担心siftGPU无法编译成功，因此对于siftGPU重新git了一个分支，下一步就是将这个分支中的siftGPU处理完善，然后将其合并到主分支当中。</p></div><p class="readmore"><a href="/2017/08/09/无人机处理/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/07/31/tensorflow-第七弹/">tensorflow-第七弹</a></h2><div class="post-meta">2017-07-31</div><div class="post-content"><p>今天有一个环境没有部署成功心里还是很不开心的，不过想想还是坚持学习以及记录，毕竟坚持了这么久不好突然放弃，上次我们提到了使用tensorflow搭建一个简单的三层CNN网络并用来训练MNIST数据库，如果大家测试过的话可以发现训练精度能够在98%以上，当然咯，具体的精度与参数的设置和迭代次数是有关系的。相信通过上一讲大家对CNN印象很深刻，下面我们将要介绍的是CNN的数学原理，当然咯一涉及到数学的东西就比较多的公式，应该会比较无聊，不过顺着公式再看看我们以前写的代码会发现我们的代码很有意思。  </p></div><p class="readmore"><a href="/2017/07/31/tensorflow-第七弹/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/07/30/tensorflow-第六弹/">tensorflow-第六弹</a></h2><div class="post-meta">2017-07-30</div><div class="post-content"><p>好了，经过前很长时间的准备和学习，我们目前应该掌握的技能应该包括</p>
<ul>
<li>1.tensorflow的工作流程，也就是图的构建的流程</li>
<li>2.tensorflow的可视化工具，tensorboard的使用以及变量的可视化方法，以及如果查看数据流图</li>
<li>3.通过爬虫从网上获取大量数据的方法</li></div><p class="readmore"><a href="/2017/07/30/tensorflow-第六弹/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/07/27/tensorflow-第五弹/">tensorflow-第五弹</a></h2><div class="post-meta">2017-07-27</div><div class="post-content"><p>今天加了个班，回来就差不多只能去写写博客总结一下了，以前老师觉得写博客是浪费时间。不过现在想想好像也还好啦，一直在学习的过程中也需要时常进行一下总结。所谓学而不思则罔嘛，昨天调通了多线程的爬虫代码，今天来总结一下，好了废话不多说我们直接进入主题。<br>多线程对我们来说已经不用解释了，我们重点要讲的是如何通过python实现多线程以及多线程爬虫的设计，首先总结一下通过python进行多线程的代码的编写，我们首先来看两个demo：（算了，demo删掉了）我们就直接分析python多线程的写法吧，首先需要import threading这个模块，我们需要定义一个类，此类继承自threading类，然后实现run函数，将线程操作放在run函数中，这一点不知道是不是必要的，不过demo都在run函数中，所以也不做它想以后干脆都写在run函数中算了，这样一个线程类就写好了，在python中启动线程也比较简单，直接start就能够启动线程了，python的线程是轻量级的所以创建和启动都比较容易，至于有什么缺点，这个暂时不去研究了。知道了线程的创建方法之后我们下一步去研究一下如何将爬虫代码修改为多线程，我们采用上次的百度图片的爬虫代码进行研究。<br>我们分析爬虫代码的耗时过程可以发现主要有两个耗时的过程，第一个为解析，从html，百度的json数据中解析出需要的url是一个比较耗时的过程，另外一个是图片的获取和保存是一个耗时的过程，由于有这两个耗时过程，我们可以对这两个过程进行拆分，将其拆分为两个线程并行处理，简单的思路就这样，我们下面对代码进行分析：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> Queue <span class="keyword">as</span> queue</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">urlqueue = queue.Queue()</span><br><span class="line">headers=(<span class="string">"User-Agent"</span>,<span class="string">"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:53.0) Gecko/20100101 Firefox/53.0"</span>)</span><br><span class="line">opener = urllib2.build_opener()</span><br><span class="line">opener.addheaders = [headers]</span><br><span class="line"></span><br><span class="line">listurl = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#thread1</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">getURLThread</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,key,pagestart,pageend,proxy,urlqueue)</span>:</span></span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line">        self.pagestart = pagestart</span><br><span class="line">        self.pageend   = pageend</span><br><span class="line">        self.proxy     = urlqueue</span><br><span class="line">        self.key       = key</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        page = self.pagestart</span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> range(self.pagestart,self.pageend+<span class="number">1</span>):</span><br><span class="line">            url=<span class="string">'http://image.baidu.com/search/avatarjson?tn=resultjsonavatarnew&amp;ie=utf-8&amp;word=%E8%BE%B9%E7%89%A7&amp;rn=60&amp;pn='</span>+str(<span class="number">60</span>*page)</span><br><span class="line">            data1 =opener.open(url).read()</span><br><span class="line">            listurlpat = <span class="string">'"objURL":"(.+?)",'</span></span><br><span class="line">            urlpage = re.compile(listurlpat,re.S).findall(data1)</span><br><span class="line">            <span class="keyword">for</span> urli <span class="keyword">in</span> urlpage:</span><br><span class="line">                time.sleep(<span class="number">7</span>)</span><br><span class="line">                <span class="keyword">for</span> urlj <span class="keyword">in</span> urlpage:</span><br><span class="line">                    <span class="keyword">try</span>:</span><br><span class="line">                        print(urlj)</span><br><span class="line">                        urlqueue.put(urlj)</span><br><span class="line">                        urlqueue.task_done()</span><br><span class="line">                    <span class="keyword">except</span> urllib2.URLError <span class="keyword">as</span> e:</span><br><span class="line">                        <span class="keyword">if</span>(hasattr(e,<span class="string">"code"</span>)):</span><br><span class="line">                            print(e.code)</span><br><span class="line">                        <span class="keyword">if</span>(hasattr(e,<span class="string">"reason"</span>)):</span><br><span class="line">                            print(e.reason)</span><br><span class="line">                            time.sleep(<span class="number">10</span>)</span><br><span class="line">                    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                        print(<span class="string">'exception:'</span>+str(e))</span><br><span class="line">                        time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">getContent</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,urlqueue,proxy)</span>:</span></span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line">        self.urlqueue = urlqueue</span><br><span class="line">        self.proxy = proxy</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        i = <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">True</span>):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                imagename = <span class="string">'Baidu_Dog/'</span>+str(i)+<span class="string">'.jpg'</span></span><br><span class="line">                imageurl = urlqueue.get()</span><br><span class="line">                urllib.urlretrieve(imageurl,imagename)</span><br><span class="line">                print(<span class="string">'get image'</span>+url)</span><br><span class="line">                i+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">except</span> urllib2.URLError <span class="keyword">as</span> e:</span><br><span class="line">                <span class="keyword">if</span>(hasattr(e,<span class="string">"code"</span>)):</span><br><span class="line">                    print(e.code)</span><br><span class="line">                <span class="keyword">if</span>(hasattr(e,<span class="string">"reason"</span>)):</span><br><span class="line">                    print(e.reason)</span><br><span class="line">                    time.sleep(<span class="number">10</span>)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                print(<span class="string">'exception:'</span>+str(e))</span><br><span class="line">                time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">control</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,urlqueue)</span>:</span></span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line">        self.urlqueue = urlqueue</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">True</span>):</span><br><span class="line">            print(<span class="string">'process~ing'</span>)</span><br><span class="line">            time.sleep(<span class="number">60</span>)</span><br><span class="line">            <span class="keyword">if</span>(self.urlqueue.empty()):</span><br><span class="line">                print(<span class="string">'finished!'</span>)</span><br><span class="line">                exit()</span><br><span class="line"></span><br><span class="line">key=<span class="string">'AI'</span></span><br><span class="line">proxy = <span class="string">'119.6.136.122:80'</span></span><br><span class="line">proxy2 = <span class="string">''</span></span><br><span class="line">pagestart = <span class="number">1</span></span><br><span class="line">pageend=<span class="number">40</span></span><br><span class="line"></span><br><span class="line">t1 = getURLThread(key,pagestart,pageend,proxy,urlqueue)</span><br><span class="line">t1.start()</span><br><span class="line"></span><br><span class="line">t2 = getContent(urlqueue,proxy)</span><br><span class="line">t2.start()</span><br><span class="line"></span><br><span class="line">t3 = control(urlqueue)</span><br><span class="line">t3.start()</span><br></pre></td></tr></table></figure></p></div><p class="readmore"><a href="/2017/07/27/tensorflow-第五弹/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/07/25/总想写点啥/">总想写点啥</a></h2><div class="post-meta">2017-07-25</div><div class="post-content"><p>到这里工作已经有一段时间了，差不多一个月吧，到目前为止一直在工作，在学习，在生活，总想找一个平衡点去平衡生活工作的各个方面，可是实际上工作跟我想的也不太一样，目前感觉既没有学到想学的也没有享受到轻松，所以总是处于一种很矛盾的状态，我想做的好一点，又想做自己喜欢做的东西，可是目前来说是那么的难。在前面的路上并没有人能够给与我什么指导和帮助，我感到很困惑，其实也渐渐体会到了一种意志被消磨的感觉，可能是跟待在实验室太像了让我觉得有些烦躁了，感觉实际上就是从一个坑跳到了另一个坑，应该说比实验室还不如，在实验室起码有足够的时间能够让我自己去探索，去做自己觉得有意思的事情，去完成一些让自己很有成就感的工作，可是在这里我还没有感觉到很大的成就感，可能也是自己的工作没有做好的缘故吧，虽然说开发的工作也能够学习到很多新的东西，可是总是感觉有那么一些无奈，感觉自己真的就是一个写代码的机器了，领导们只关心能不能做，好像并不需要去对问题进行深入的研究，对于这一点是我最不习惯的地方，在实验室里总是养成了一种更加深入的思考和猜想的习惯而在这里并没有这样的氛围，只不过是一个项目接着一个项目，虽然也谈不上不充实可是总觉得少了一点什么。<br>可能是自己比较矫情，在这个时候还满腹牢骚，但是面对着这些问题，在晚上夜深人静的时候就不由自主的会去想，会去疑惑对自己来说重要的究竟是什么，是按部就班的工作还是做一些不一样的事情，心里总是有一些躁动，想去看看不一样的风景，其实不一样的风景也许并不是那么美好。也许安安心心的做好手上的事情才是最好的选择吧。<br>其实安排的工作对我来说都算不上难，毕竟一直就在做着这方面的工作，也能够比较高效的完成工作，我想着大概就是我到现在为止还有时间想着这些乱起八糟的事情的原因吧，很羡慕我的同事，不知道他的生活是什么样，也不知道他会不会有跟我一样的思考，如果不去思考，不去为自己的未来做打算，我将会走向哪里呢。又如果只是完成工作上的事情不抓紧时间为未来学习，以后又将会怎样。工作了这么长的时间真的感觉很累，很累，一直在学习，白天的时候发挥最大的能力和工作效率争取把事情给完成了，然后晚上做一些自己觉得有意思的事情，着一段时间来也一直都在这么做，可是这样真的觉得好累好累，不知道自己什么时候会坚持不下去，不过毕竟现在还年轻，总是能够坚持的吧，至于以后谁知道呢……<br>本来有很多东西想写，想写写自己对于工作得看法，工作这么长时间的感受，以及在这边生活的感受，以及对未来的计划等等，可是每当面对着屏幕的时候就开始跑题，就开始胡乱的去想，然后就写下了这些杂乱的文字。写着写着还有一些困了，我想自己本是不应该这么累，感觉压力这么大的，可是是什么在催着我呢，其实我也不知道，如果只是完成手上的工作然后好好休息其实也可以很轻松的，可能是习惯了去为未来生活所以很累吧，我想每个人都有那么一些焦虑吧，或者是现在或者是未来，或者沉湎于过去，不过既然已经开始了，那我也不想半途而废了，再坚持坚持，也许再坚持坚持未来就来了呢！</p></div><p class="readmore"><a href="/2017/07/25/总想写点啥/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/07/24/tensorflow-第四弹/">tensorflow-第四弹</a></h2><div class="post-meta">2017-07-24</div><div class="post-content"><p>前面三个部分都是关于深度学习，tensorflow框架的东西，再接着深入就要涉及到了深度学习更加深层次的内容了，涉及到深度卷积和深度置信网络了，这一部分涉及的原理比较多，因此相对来说会比较复杂，而为了进行深度学习我们必须在另一个部分进行比较深入的研究，那就是数据，深度学习必然伴随这大数据，可以说没有大数据就没有深度学习。我们接下来学习跟数据有关的一些内容，主要就是针对数据获取和数据预处理两个部分。<br>我们知道网络上的数据很多，也很复杂，有各种标签的数据，这些数据有的对我们有用，而有些数据对我们来说就没有什么意义了，如何快速获取大量对我们来说有意义的数据是我们亟待解决的问题，所以这一部分看似和tensorflow没有什么关系，实际上它是机器学习的基础，所以我们再后面一部分会着重的介绍数据获取和数据处理，直到这一部分学习完才会继续真正的深度学习方法的学习和介绍，好了废话不多说。<br>我们这次主要讲爬虫，什么是爬虫或者说robot，简单的来说就是能够从网上获取数据的工具，而这样的工具都是通过代码实现的，我们把这样的代码或者工具就叫做爬虫。好了介绍完爬虫我们基本上就知道爬虫是干什么的了，没错爬虫就是替代我们从网上获取数据的，那么它的工作原理是怎么样的呢，我们会通过两个网站的分析进行介绍：  </p></div><p class="readmore"><a href="/2017/07/24/tensorflow-第四弹/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/07/23/tensorflow-第三弹/">tensorflow-第三弹</a></h2><div class="post-meta">2017-07-23</div><div class="post-content"><p>好不容易可以发第三弹了，在这一回的学习和编码过程中遇到了很多的坑，当然咯，要做机器学习特别是用一门自己并不是很熟悉的语言去做，总归是有一些坑的，不过好在这些坑在这两天都被我填上了，所以现在也可以记录一下。在上一回的学习过程中我们通过tensorflow的简单逻辑回归的拟合说明了tensorflow的图的构造以及启动的过程，这一次准备做一些更加深入的学习，采用BPNN对MNIST手写数字库进行分析和识别。首先介绍一些MNIST库，如果做过机器学习和手写数组识别的人入门必备的一个数据，数据包括6w个28×28大小的手写数字图标和它们的label，以及1w个测试样本。数据全部以二进制形式存储，所以读取很方便，另外在tensorflow的教程中已经存在了MNIST数据读取的功能，极大的简化了我们的处理，让我们专注于神经网络结构的设计。<br>下面我们分析一下神经网络结构的设计，我们做的是最简单的BP神经网络，也就是三层前馈神经网络，其结构如图：<br><img src="http://blogimage-1251632003.cosgz.myqcloud.com/bpnn.png"><br>上图是一个比较好的三层BP神经网络的示意图，从图上可以看到假设样本有 $x={x_1,x_2….x_N}$ N个变量，则输入为一个N维的向量，关于这一点在做多波段图像的同学们可能需要注意一下，到底什么是样本什么是变量搞清楚。这N个变量作为输入层，然后输入层经过如下运算得到隐含层：<br>$h=W\cdot x+b$  (1)<br>隐含层的神经元的数目是给定的，为什么要给定隐含层的神经元数目，这个确定了隐含层的复杂度，理论上来说隐含层的神经元数目越多其拟合效果应该更好，但是隐含层神经元数目太多会导致两个问题(1)参数数目成指数增长，需要更多的训练样本才能进行充分学习；(2)出现对结果变化影像很小的无效参数，这些参数对结果的贡献很小，甚至可以忽略不计，除了增加计算复杂度再没有别的作用，因此应该去掉这些参数。所以合理的设置隐含层个数的问题也是神经网络调参过程的一个重要问题。<br>在(1)式中我们得到了隐含层的输入，实际上对于隐含层，其并不是输入等于输出，而是有一个响应函数，将输入从 $[+\infty,-\infty]$ 转换到[-1,1]这种转换有很多种，一般来说满足条件的转换有，sigmoid转换，tanh转换，relu转换等，采用这些转换是因为这些转换有一些特点，1.单调，2.在区间内处处可导；在选取这些函数后我们得到隐含层的输出，然后对应隐含层到输出层:<br>$o=W_2 \cdot h+b$  (2)<br>然后输出层与label结果比较，通过比较可得误差，然后通过误差调整误差函数 $\Delta$ 然后通过调整得到输出层的 $W_2$ 和 $b2$ 然后得到计算的 $h$和实际 $h$ 之间的差距然后对数据进行调整 $w1$ 和$b1$ 。至于如何调整，一般来说采用的是梯度下降法进行调整，至于为什么能够进行最优的求解，具体的算法分析可以参考其他文档，在这里并不做详细的分析，我的其他博客上有具体的分析。好了，分析完BPNN的原理之后我们看看其实现的代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np;</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"mnist/MNIST_data/"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'input'</span>):</span><br><span class="line">    x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>],name = <span class="string">'x-input'</span>)</span><br><span class="line">    y = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>, <span class="number">10</span>],name=<span class="string">'y-input'</span>)</span><br><span class="line">    x_image = tf.reshape(x,[<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>],name=<span class="string">'img'</span>)</span><br><span class="line">    tf.summary.image(<span class="string">'image'</span>,x_image,<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">w1 = tf.Variable(tf.truncated_normal(shape=[<span class="number">784</span>,<span class="number">50</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">init1 = tf.constant(<span class="number">0.1</span>, shape=[<span class="number">50</span>])</span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">50</span>]),</span><br><span class="line">                         name=<span class="string">'biases1'</span>)</span><br><span class="line"></span><br><span class="line">w2 = tf.Variable(tf.truncated_normal(shape=[<span class="number">50</span>,<span class="number">10</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">init2 = tf.constant(<span class="number">0.1</span>, shape=[<span class="number">10</span>])</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">10</span>]),</span><br><span class="line">                         name=<span class="string">'biases2'</span>)</span><br><span class="line"></span><br><span class="line">hidden1 = tf.nn.relu(tf.matmul(x,w1)+b1)</span><br><span class="line">y_ = tf.nn.relu(tf.matmul(hidden1,w2)+b2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'loss'</span>):</span><br><span class="line">    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_))</span><br><span class="line">    tf.summary.scalar(<span class="string">'loss'</span>,loss)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'accuracy'</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'correct-predict'</span>):</span><br><span class="line">        correct_predict = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'accuracy'</span>):</span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_predict, <span class="string">"float"</span>))</span><br><span class="line"></span><br><span class="line">merged = tf.summary.merge_all()</span><br><span class="line">step = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    writer = tf.summary.FileWriter(<span class="string">'tensorflow-start_Log'</span>, sess.graph)</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100000</span>):</span><br><span class="line">        batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">        summary,_=sess.run([merged,step], feed_dict=&#123;x: batch_xs, y: batch_ys&#125;)</span><br><span class="line">        <span class="keyword">if</span> i%<span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            train_acc = accuracy.eval(feed_dict=&#123;x: batch_xs, y: batch_ys&#125;)</span><br><span class="line">            print(<span class="string">'step'</span>,i,<span class="string">'training accuracy'</span>,train_acc)</span><br><span class="line">            writer.add_summary(summary, i)</span><br></pre></td></tr></table></figure></p></div><p class="readmore"><a href="/2017/07/23/tensorflow-第三弹/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/07/20/tensorflow-第二弹/">tensorflow-第二弹</a></h2><div class="post-meta">2017-07-20</div><div class="post-content"><p>刚刚研究了一下以前写的tensorflow发现就开了个头，而且都是两个月之前的事情了，现在看起来作为入门介绍起来也是一件比较简单的事情了，这一段时间按照官网的教程也写了一个mnist识别的cnn的例子，当然咯自己也写了一个自己的图像训练的代码，只是目前还没有开始训练……但是按照官网教程写的东西毕竟只是依葫芦划瓢而已并没有深入理解，这一次慢慢去深入理解tensorflow的机制。其实再tenflow的情况下主要分为两个操作，一个是构建Graph，Graph由很多op，和tensorflow构成，好了今天我们从一个简单的线性回归的例子开始进行深入的剖析。<br>线性回归可以简单的表示为$y=a\cdot x+b$的形式，那么我们在获取了一系列的x，y数据的情况下可以拟合得到线性方程，而线性拟合通常直接求解，但是我们为了说明tensorflow的原理所以强行用梯度下降算法进行迭代拟合求解，废话不多说，下面我们构建起线性拟合的Graph：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> RandomState</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'input'</span>):</span><br><span class="line">    x = tf.placeholder(tf.float32,name = <span class="string">'xinput'</span>)</span><br><span class="line">    y = tf.placeholder(tf.float32,name = <span class="string">'yinput'</span>)</span><br><span class="line">    tf.summary.scalar(<span class="string">'x'</span>,x)</span><br><span class="line">    tf.summary.scalar(<span class="string">'y'</span>,y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'parameter'</span>):</span><br><span class="line">    a = tf.Variable(<span class="number">0.0</span>,name=<span class="string">'a'</span>)</span><br><span class="line">    b = tf.Variable(<span class="number">0.0</span>,name=<span class="string">'b'</span>)</span><br><span class="line">    tf.summary.scalar(<span class="string">'a'</span>,a)</span><br><span class="line">    tf.summary.scalar(<span class="string">'b'</span>,b)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'predict'</span>):</span><br><span class="line">    y_=a*x+b;</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'loss'</span>):</span><br><span class="line">    loss = tf.square((y_-y),name=<span class="string">'loss'</span>)</span><br><span class="line">    tf.summary.scalar(<span class="string">'loss'</span>,loss)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'train_step'</span>):</span><br><span class="line">    train_step = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(loss)</span><br><span class="line">    <span class="comment">#tf.summary.scalar('train_step',train_step)</span></span><br><span class="line"></span><br><span class="line">merged = tf.summary.merge_all()</span><br><span class="line"><span class="comment">#data prepare</span></span><br><span class="line">xdata = np.linspace(<span class="number">0</span>,<span class="number">0.5</span>*np.pi,<span class="number">3000</span>)</span><br><span class="line">ydata = <span class="number">0.4</span>*xdata+<span class="number">0.5</span>;</span><br><span class="line">rdm = RandomState(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    writer = tf.summary.FileWriter(<span class="string">'tensorflow-start_Log'</span>, sess.graph)</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2000</span>):</span><br><span class="line">        idx = rdm.randint(<span class="number">0</span>,<span class="number">3000</span>)</span><br><span class="line">        summary,_=sess.run([merged,train_step],feed_dict=&#123;x:xdata[idx],y:ydata[idx]&#125;)</span><br><span class="line">        writer.add_summary(summary, i)</span><br><span class="line">    a_value,b_value = sess.run([a,b])</span><br><span class="line">    print(a_value)</span><br><span class="line">    print(b_value)</span><br></pre></td></tr></table></figure></p></div><p class="readmore"><a href="/2017/07/20/tensorflow-第二弹/">阅读更多</a></p></div><nav class="page-navigator"><a class="extend prev" rel="prev" href="/page/7/">上一页</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/9/">下一页</a></nav></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://www.wuweiblog.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/书评/">书评</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/图像处理/">图像处理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/学习/">学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/小说/">小说</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/影评/">影评</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学/">数学</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/游戏/">游戏</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随感/">随感</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/随感-摄影测量/" style="font-size: 15px;">随感-摄影测量</a> <a href="/tags/开发/" style="font-size: 15px;">开发</a> <a href="/tags/数学/" style="font-size: 15px;">数学</a> <a href="/tags/ArcGIS环境配置/" style="font-size: 15px;">ArcGIS环境配置</a> <a href="/tags/学习/" style="font-size: 15px;">学习</a> <a href="/tags/图像处理数学原理/" style="font-size: 15px;">图像处理数学原理</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/效率/" style="font-size: 15px;">效率</a> <a href="/tags/tensorflow学习/" style="font-size: 15px;">tensorflow学习</a> <a href="/tags/机器学习，图像处理/" style="font-size: 15px;">机器学习，图像处理</a> <a href="/tags/潜规则-书评/" style="font-size: 15px;">潜规则,书评</a> <a href="/tags/沉默的大多数，书评/" style="font-size: 15px;">沉默的大多数，书评</a> <a href="/tags/未来简史-书评/" style="font-size: 15px;">未来简史,书评</a> <a href="/tags/呼兰河传-书评/" style="font-size: 15px;">呼兰河传,书评</a> <a href="/tags/将夜-书评/" style="font-size: 15px;">将夜,书评</a> <a href="/tags/图像处理/" style="font-size: 15px;">图像处理</a> <a href="/tags/openMVG-openMVS学习/" style="font-size: 15px;">openMVG openMVS学习</a> <a href="/tags/你好疯子，影评/" style="font-size: 15px;">你好疯子，影评</a> <a href="/tags/喜剧之王，影评/" style="font-size: 15px;">喜剧之王，影评</a> <a href="/tags/雪中悍刀行-书评/" style="font-size: 15px;">雪中悍刀行,书评</a> <a href="/tags/随感/" style="font-size: 15px;">随感</a> <a href="/tags/linux-学习/" style="font-size: 15px;">linux 学习</a> <a href="/tags/The-Legend-of-1900/" style="font-size: 15px;">The Legend of 1900</a> <a href="/tags/随感，毕业/" style="font-size: 15px;">随感，毕业</a> <a href="/tags/校正方法，控制点，光束法平差/" style="font-size: 15px;">校正方法，控制点，光束法平差</a> <a href="/tags/linux学习/" style="font-size: 15px;">linux学习</a> <a href="/tags/电影十二公民/" style="font-size: 15px;">电影十二公民</a> <a href="/tags/小说/" style="font-size: 15px;">小说</a> <a href="/tags/随感－代码重构/" style="font-size: 15px;">随感－代码重构</a> <a href="/tags/R-学习/" style="font-size: 15px;">R 学习</a> <a href="/tags/V字仇杀队-浪潮，影评/" style="font-size: 15px;">V字仇杀队,浪潮，影评</a> <a href="/tags/月亮与六便士/" style="font-size: 15px;">月亮与六便士</a> <a href="/tags/狗子日记/" style="font-size: 15px;">狗子日记</a> <a href="/tags/爱乐之城，影评/" style="font-size: 15px;">爱乐之城，影评</a> <a href="/tags/星际穿越，影评/" style="font-size: 15px;">星际穿越，影评</a> <a href="/tags/社交网络，影评/" style="font-size: 15px;">社交网络，影评</a> <a href="/tags/秒速五厘米/" style="font-size: 15px;">秒速五厘米</a> <a href="/tags/图像处理的数学原理/" style="font-size: 15px;">图像处理的数学原理</a> <a href="/tags/白日梦想家，影评/" style="font-size: 15px;">白日梦想家，影评</a> <a href="/tags/海涛之声，影评/" style="font-size: 15px;">海涛之声，影评</a> <a href="/tags/饥荒/" style="font-size: 15px;">饥荒</a> <a href="/tags/一个叫欧维的男人决定去死，书评/" style="font-size: 15px;">一个叫欧维的男人决定去死，书评</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/08/29/不读书(六)/">不读书(六)</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/22/tensorflow-二十七弹/">tensorflow-二十七弹</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/13/tensorflow-二十六弹/">tensorflow-二十六弹</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/22/RPC（共线条件方程）校正迭代方法分析/">RPC（共线条件方程）校正迭代方法分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/15/混合高斯分布/">混合高斯分布</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/08/python修饰符/">python修饰符</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/04/向往的生活/">向往的生活</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/25/空房子/">空房子</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/20/Flask服务器linux离线配置/">Flask服务器linux离线配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/17/月亮与六便士/">月亮与六便士</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/RemoteSensingFrank" title="Github" target="_blank">Github</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">吴蔚.转载请注明</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-107160167-1','auto');ga('send','pageview');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>