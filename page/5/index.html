<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="随感，遥感，机器学习....想到什么写什么"><title>吴蔚 | 生命不息，折腾不止！</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/5.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">吴蔚</h1><a id="logo" href="/.">吴蔚</a><p class="description">生命不息，折腾不止！</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h2 class="post-title"><a href="/2017/10/29/关于几何精校正的问题/">关于几何精校正的问题</a></h2><div class="post-meta">2017-10-29</div><div class="post-content"><p>以前总觉得进行影像几何精校正是一件比较简单的事情，但是事实往往不太让我们满意，实际上我们通过上一次的<a href="http://wuweiblog.com/2017/09/20/%E5%85%AC%E5%BC%8F%E5%8F%8D%E6%8E%A8/" target="_blank" rel="noopener">分析</a>可以知道，通过矩阵Ｐ在已知影像坐标和高程的情况下如何对影像坐标进行求解从而达到对影像进行精校正的目的，实际上我也这么求解了，可是事实证明求解的过程没有错，但是求解的结果却出现了问题，为了验证问题出在哪里，我从得到的光束法平差结果进行分析，首先我们分析求解公式的正确性，因此我们选取光束法平差的匹配点和求解的三维点进行误差分析：<br><img src="http://blogimage-1251632003.cosgz.myqcloud.com/%E5%B7%AE%E5%BC%82.jpg" align="center"><br><img src="http://blogimage-1251632003.cosgz.myqcloud.com/%E8%AF%AF%E5%B7%AE.png" align="center"><br>从上面的误差图比较中我们可以看到，实际上直接通过高程计算得到的结果与前方交会的结果存在较小的误差，实际上因为采用UTM投影坐标进行计算，如果采用局部坐标系进行计算则误差更小，说明计算的结果应该是正确的．证明了结果的正确性之后我们需要做的是分析高程的影响，因为高程对数据的影响很大，在实际的计算过程中我们是首先给一个平均高程然后迭代计算，实际上如果给一个平均高程差别不大的话似乎没有问题，但是差别比较大的化计算的结果就会出现较大的误差影响计算结果，必须考虑高程的误差，于是我们从高程 $[-300,300:5]$ 与真实数据相比我们将模拟数据高程从-300到300之间变化以步长为5得到计算误差随着高程变化的结果如图：<br><img src="http://blogimage-1251632003.cosgz.myqcloud.com/%E9%AB%98%E7%A8%8B%E5%8F%98%E5%8C%96%E8%AF%AF%E5%B7%AE.png" align="center"><br>从图上结果可以看出，实际上随着高程的变化，计算结果的变化较大，也就是说高程的变化会极大的影响位置的误差，所以在计算的时候给平均高程的做法会带来极大的校正误差，因此需要换一个思路进行求解，首先求取了加密点之后应该将加密点作为控制点采用多项式的方法进行几何粗校正，用此方法进行几何粗校正虽然不是很准确但是坐标相对来说是比较准确的，在此基础上得到高程点然后进行精校正，采用这样的校正方法应该可以得到比较好的校正结果，不过实际校正结果还有待验证.</p></div><p class="readmore"><a href="/2017/10/29/关于几何精校正的问题/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/10/15/面对生活/">面对生活</a></h2><div class="post-meta">2017-10-15</div><div class="post-content"><p>前两天重新看了这部＜白日梦想家＞记得第一次看的时候就有很深的感触，不过那个时候还在上学，所以对于工作，对于梦想什么并没有什么深刻的体会，到如今工作了几个月再看一遍这部电影，又有了不一样的体会，以下有大量剧透：<br>Walter是一个杂志社底片管理的主管，虽然平日生活平平淡淡可是他总是会处于一种出神的状态，幻想自己能够做一些具有传奇色彩的事情，可是实际上他每日的生活就是检查底片，在现实生活中的他寡言少语，有些内向，甚至有些自卑，在网上向自己喜欢的姑娘说Hi对他来说都是一件比较困难的事情，因为日常生活的平淡，他在相亲网站上填写的个人资料也因为平平无奇而无人问津．然而生活总是会给我们一些选择，有一天他发现自己弄丢了一份珍贵的底片，于是踏上了追寻底片的路途，而这一路的奔波却改变了他的一生，见识了广袤的大海，在海上与鲨鱼搏斗，见识了火山壮丽，挑战了入云的雪山，这个追寻底片的过程也是追寻自己内心的过程，终于walter经历过这一切后找回了底片，也找到了真正的自我．<br>喜欢这部电影的原因就在于主角的追寻的过程，实际上大多数的人一生都是平淡的，大家总是喜欢安稳，可是实际上只有面临过颠沛流离才能感受到安稳不是么，既然我们从未上路过，又何来安稳的说法呢，每个人都有自己的白日梦，每个人都想体会那种传奇的人生，可是有多少人能够不顾一切的去尝试呢．当面临着狂风巨浪，面临着海上狂鲨，面临着喷发的火山，面临着巍巍高山，我们所有的犹豫，有所的彷徨都变得微不足道，我们必须收拾起所有的犹豫勇敢的行走在路上，最喜欢的一个镜头是下船后的walter抢单车的那一幕，如果生活是一场旅途稍一犹豫，我们就与精彩失之交臂…..</p></div><p class="readmore"><a href="/2017/10/15/面对生活/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/10/09/回不去的昨天/">回不去的昨天</a></h2><div class="post-meta">2017-10-09</div><div class="post-content"><p>国庆放了八天长假，从二号回去，到六号回广州，在家呆了四天，实际上除去去武汉的一天半，在家可能也就呆了两天多一点，见到多年不见的老同学其实还是挺开心的，可是又有些失落，从本科到现在我们逐渐在成长，同时回忆也成为了我们永远回不去的昨天，可能是因为今天有些感冒，脑袋昏昏沉沉所以没有了平时奋斗的念头，而一旦松懈下来各种负面的情绪就一齐涌上心头，觉得很累，觉得很失望，觉得不知道自己所做的一切有什么意义或价。回家待着的两天，在路上看到有小朋友在开心的疯玩实际上是很羡慕的，就如同小时候的我们羡慕那些大人们一样吧，终于自己也长大了，也经济独立了，也终于彻底离开了家，到千里之外的城市来打拼，可是却并没有小时候所想得那么快乐，记得以前的时候听他们说一天的工资能有一百块，我当时听了心里羡慕不已，一天一百块，那是多么一笔巨款呀，对于当时一天只有一块钱的零花钱的我来说简直是一件遥不可及的巨款。以前总是想着如果有一台自己的电脑可以随时上网打游戏那该是多么幸福的一件事情，等到真的有了一台属于自己的电脑后发现原来每天打游戏也不是那么快乐，反而更加空虚了。<br>在小鹏哥的婚礼上看着在那里弹琴的小鹏哥，似乎又回到了我们大一大二的时候，那个时候没有什么别的爱好，每天除了学习就是弹琴，以前的时候没有感觉，可是猛然回头发现原来离我们进大学已经有七年的时间了，记得刚进大学的时候，那个时候还下着雨，爸爸妈妈送我去的学校，学校里面人很多，刚到宿舍有些人已经到了，只能在剩下的空位中随便找一个铺了铺盖，然后跟着爸妈在学校里面晃了一圈。第二天老爸老妈就回去了，接下来的时间都是我一个人在学校渡过了。本科四年硕士三年，在这七年的时间里，而这七年也许是人生中最快的七年了，在这几年中没有生活的压力，也没有什么其他乱七八糟的想法，每天做的都是自己喜欢的事情，所以日子过得特别快。转眼的时间七年就过去了，看到曾经的同学都已经结婚，还是有些难以置信，似乎在自己的印象中昨天他们还坐在北区情人坡的草地上弹琴唱歌，没有想到如今已经已经要踏入人生的新篇章了。<br>这几天一直都在奔波，二号晚上回家，三号上午到家里，四号中午就出发去武汉了，然后五号回来，六号晚上来到广州，如此匆忙，很多人问为什么要回家呢，不回家不是也挺好的么，不回家不是能够更加从容和舒适么，可是每当回去看到爸妈期待的眼神又觉得就算奔波也是值得的吧，实际上自己这二十几年来一直在读书，也没有能够为家里做些什么，以后也恐怕不会回家工作，所以恐怕也很难说能够为家里做些什么吧，爸妈上了年纪总是希望能够有人陪着吧，回家的时候妈妈向我抱怨说如果不是因为在广州工作，如果在岳阳或者在长沙工作，现在应该已经买房买车了，可是现实生活没有如果，既然已经选择了在大城市打拼，也就不去想如果的事情了，平时不会有这么多的感慨，只是现在自己身体感到不适所以总是会有更多的负面情绪吧，感到疲惫，感到孤独，感到无所适从，只想着能够躲到一个安全的港湾中好好的休息，过了今天，等到明天感冒好了又能够找回奋斗的状态吧。最后突然想到了李白的一首诗</p></div><p class="readmore"><a href="/2017/10/09/回不去的昨天/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/09/30/tensorflow-十九弹/">tensorflow-十九弹</a></h2><div class="post-meta">2017-09-30</div><div class="post-content"><p>话说在看论文的过程中看到了有很多神经网络的概念，不管什么学科都是建立在前人的基础之上的，所以了解一下现在相对来说比较古老的深度神经网络结构对我们充分理解深度学习，梳理学习过程是很有帮助的，因此这一讲我们着重了解一下各种其他类型的深度学习网络：</p>
<h3 id="1-LeNet"><a href="#1-LeNet" class="headerlink" title="1.LeNet"></a>1.LeNet</h3><p>必须要将他列为经典，必学的网络结构之一，我们现在神经网络中很多特点都是由他开始的，主要设计与应用的目的在于对手写数字进行识别，其网络结构如图：<br><img src="http://blogimage-1251632003.cosgz.myqcloud.com/Lenet.png"></p></div><p class="readmore"><a href="/2017/09/30/tensorflow-十九弹/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/09/29/tensorflow-十八弹/">tensorflow-十八弹</a></h2><div class="post-meta">2017-09-29</div><div class="post-content"><p>又来到了快乐的机器学习时光，在上一讲中我们提到了如何将自定义数据转换成tensorflow输入的格式，这真是一个好消息，这样我们就可以愉快的训练我们自己的数据了，不过……(我就知道事情不会这么简单)不过自己的数据集还没有训练好，而且数据集太大了，八十几个Ｇ害怕自己的电脑受不了，不想在笔记本上跑，所以暂且没有使用自定义的数据，不过还是想看看处理效果，好奇害死猫呀，这不就开始倒腾已有的数据，在这里我训练的是pascal的数据，数据包含二十种第五ｎ多图像，具体多少张我也不知道．我们同样是采用下面的步骤进行处理:</p></div><p class="readmore"><a href="/2017/09/29/tensorflow-十八弹/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/09/27/青春的旋律/">青春的旋律</a></h2><div class="post-meta">2017-09-27</div><div class="post-content"><p>昨晚看了这部《海涛之声》，不得不说吉普力工作室总是能够给人惊喜，虽然已经看过一遍，但是再看一遍依然会有一种青春的感觉，洋溢这青春的气息。其实《海涛之声》讲述的不过是一个学生时代的小故事，下面的内容会有大量剧透，请谨慎:<br>一个从从小娇生惯养的姑娘-武藤里伽子，因为父母离异的关系被迫从繁华的东京搬家到高知县城上高中，正好和男主角一个班，然而从东京来到高知县后虽然在体育和成绩上都非常优秀，但是总是与其他同学格格不入，由于口音的问题武藤总是显得十分孤傲不愿与人交流，由此也导致了很多非议。然而男主的好朋友松本从一开始就喜欢上了武藤，然而命运总是让人难以琢磨，阴差阳错中武藤找男主杜崎拓借钱买了去东京看父亲，而女主的朋友却因为不想欺骗家里不能陪女主去，无奈之下男主杜崎拓陪着女主去了女主父亲家，原本想象中无比美好的父亲的家里却是一地鸡毛，最后不得不和男主在旅馆挤了一晚上，而这期间男主对武藤也更加的了解，当然武藤对男主杜崎拓也有了更多的了解，也许情愫就是在这一刻产生了吧，可是因为松本的缘故，杜崎拓只能百般抗拒，为了朋友与武藤大吵了一架，为了避嫌而刻意的疏远其实很容易就被武藤和松本看穿．其实年少时的我们又何尝不是这样呢，友情与朦胧的爱情，总是很难去取舍，也难以作出断决，而往往我们以为两全其美的方法不过是自欺欺人罢了．后来拓为了怀念自己喜欢的人而上了东京的大学，而来自东京的里加子却令人意外地上了拓的家乡高知县的大学，松本则考到京都。三人就这样分开了。几年后的同学会上，老同学再次相逢，相比与曾经的年少轻狂，各奔东西后的大家都显得豁达了很多，是呀，曾经我们的世界就这么大，所以喜欢与讨厌也分得那么清楚，随着我们世界的慢慢变大，即使曾经不是那么喜欢的人如今看来也是那么的亲切，曾经耿耿于怀的事情也变得豁然开朗起来，重逢的松本对拓说:”我并不是生气知道你也喜欢里加子的事情，我气的是我知道你是在让我！”因为是好朋友，所以相让是耻辱。朋友是对等，所以若是相让就有轻视的感觉……拓似乎释然了．这也许就是最真诚的友情和最纯粹的爱情吧，友情是平等，而爱情也不一定是占有，也许只有青春少年才会有如此纯真的感情吧．当然这时拓才能真正直面自己的内心，原来曾经的那份悸动只是深深埋藏，却从未改变．<br>和我们的青春片不同，这部片子仅仅是描述了简单的学生生活，没有轰轰烈烈的逃学逃课，早恋堕胎，然后各种生离死别歇斯底里，可是生活不就是这样么，学生时代的我们，青春年少的我们，所谓爱情不过是那么朦胧的悸动，在平静生活中的点点涟漪罢了，也许就是在伴随着我们入梦的海涛声中的点点星光，我们的青春变得更加美好．真实的生活总是能够打动人，快乐也罢，悲伤也罢，电影总是喜欢将少数的例子拍给我们看，可是我们无数的普通的经历过的不过是简单的生活，虽然有遗憾，却仍然那么美好，那么怀念不是么？毕竟那些就是我们的青春，我们也曾经如此真诚，如此傻傻的……</p></div><p class="readmore"><a href="/2017/09/27/青春的旋律/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/09/26/tensorflow-十七弹/">tensorflow-十七弹</a></h2><div class="post-meta">2017-09-26</div><div class="post-content"><p>终于到了十七弹，虽然理论基础还没有介绍完，但是我们还是赶快进行进一步的学习，这一次我们主要来说一个很有用的工具，Fast-RCNN，为什么要说这个，因为目标识别要用到它，所以我们不得不在接下来的一段时间中都对这个RCNN进行研究，当然，我们已经了解了神经网络的基础知识，了解了卷积神经网络，也了解到了循环神经网络，卷积神经网络更多的是用于目标的识别，而循环神经网络更多的是用于对序列数据进行处理，而我们现在要做的是在影像上对目标进行检测，当然咯，最简单的办法就是拿一个框在影像上移动，然后框出目标，这样的方法耗时长不说，对于分辨率不一样的目标识别效果也并不好，由此催生了我们的RCNN，在这一讲中我们并不对RCNN的具体算法进行介绍，我们仅仅只讨论这个工具怎么用．　　<br>在tensorflow中很多模型都已经被实现了，所以我们也不需要再重复造轮子，<a href="https://github.com/tensorflow/models.git" target="_blank" rel="noopener">具体参考</a>这里有使用tensorflow实现的各种深度学习算法，以及论文中出现的比较新的算法，通过tensorflow工具，很方便的去调用，我们针对objecct-detection这个功能进行深入的研究，首先不研究算法，我们先看看他的数据转换的过程：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> PIL.Image</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> dataset_util</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> label_map_util</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">flags = tf.app.flags</span><br><span class="line">flags.DEFINE_string(<span class="string">'data_dir'</span>, <span class="string">''</span>, <span class="string">'Root directory to raw PASCAL VOC dataset.'</span>)</span><br><span class="line">flags.DEFINE_string(<span class="string">'set'</span>, <span class="string">'train'</span>, <span class="string">'Convert training set, validation set or '</span></span><br><span class="line">                    <span class="string">'merged set.'</span>)</span><br><span class="line">flags.DEFINE_string(<span class="string">'annotations_dir'</span>, <span class="string">'Annotations'</span>,</span><br><span class="line">                    <span class="string">'(Relative) path to annotations directory.'</span>)</span><br><span class="line">flags.DEFINE_string(<span class="string">'year'</span>, <span class="string">'VOC2007'</span>, <span class="string">'Desired challenge year.'</span>)</span><br><span class="line">flags.DEFINE_string(<span class="string">'output_path'</span>, <span class="string">''</span>, <span class="string">'Path to output TFRecord'</span>)</span><br><span class="line">flags.DEFINE_string(<span class="string">'label_map_path'</span>, <span class="string">'data/pascal_label_map.pbtxt'</span>,</span><br><span class="line">                    <span class="string">'Path to label map proto'</span>)</span><br><span class="line">flags.DEFINE_boolean(<span class="string">'ignore_difficult_instances'</span>, <span class="keyword">False</span>, <span class="string">'Whether to ignore '</span></span><br><span class="line">                     <span class="string">'difficult instances'</span>)</span><br><span class="line">FLAGS = flags.FLAGS</span><br><span class="line"></span><br><span class="line">SETS = [<span class="string">'train'</span>, <span class="string">'val'</span>, <span class="string">'trainval'</span>, <span class="string">'test'</span>]</span><br><span class="line">YEARS = [<span class="string">'VOC2007'</span>, <span class="string">'VOC2012'</span>, <span class="string">'merged'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dict_to_tf_example</span><span class="params">(data,</span></span></span><br><span class="line"><span class="function"><span class="params">                       dataset_directory,</span></span></span><br><span class="line"><span class="function"><span class="params">                       label_map_dict,</span></span></span><br><span class="line"><span class="function"><span class="params">                       ignore_difficult_instances=False,</span></span></span><br><span class="line"><span class="function"><span class="params">                       image_subdirectory=<span class="string">'JPEGImages'</span>)</span>:</span></span><br><span class="line">  img_path = os.path.join(data[<span class="string">'folder'</span>], image_subdirectory, data[<span class="string">'filename'</span>])</span><br><span class="line">  full_path = os.path.join(dataset_directory, img_path)</span><br><span class="line">  <span class="keyword">with</span> tf.gfile.GFile(full_path, <span class="string">'rb'</span>) <span class="keyword">as</span> fid:</span><br><span class="line">    encoded_jpg = fid.read()</span><br><span class="line">  encoded_jpg_io = io.BytesIO(encoded_jpg)</span><br><span class="line">  image = PIL.Image.open(encoded_jpg_io)</span><br><span class="line">  <span class="keyword">if</span> image.format != <span class="string">'JPEG'</span>:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'Image format not JPEG'</span>)</span><br><span class="line">  key = hashlib.sha256(encoded_jpg).hexdigest()</span><br><span class="line"></span><br><span class="line">  width = int(data[<span class="string">'size'</span>][<span class="string">'width'</span>])</span><br><span class="line">  height = int(data[<span class="string">'size'</span>][<span class="string">'height'</span>])</span><br><span class="line"></span><br><span class="line">  xmin = []</span><br><span class="line">  ymin = []</span><br><span class="line">  xmax = []</span><br><span class="line">  ymax = []</span><br><span class="line">  classes = []</span><br><span class="line">  classes_text = []</span><br><span class="line">  truncated = []</span><br><span class="line">  poses = []</span><br><span class="line">  difficult_obj = []</span><br><span class="line">  <span class="keyword">for</span> obj <span class="keyword">in</span> data[<span class="string">'object'</span>]:</span><br><span class="line">    difficult = bool(int(obj[<span class="string">'difficult'</span>]))</span><br><span class="line">    <span class="keyword">if</span> ignore_difficult_instances <span class="keyword">and</span> difficult:</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    difficult_obj.append(int(difficult))</span><br><span class="line"></span><br><span class="line">    xmin.append(float(obj[<span class="string">'bndbox'</span>][<span class="string">'xmin'</span>]) / width)</span><br><span class="line">    ymin.append(float(obj[<span class="string">'bndbox'</span>][<span class="string">'ymin'</span>]) / height)</span><br><span class="line">    xmax.append(float(obj[<span class="string">'bndbox'</span>][<span class="string">'xmax'</span>]) / width)</span><br><span class="line">    ymax.append(float(obj[<span class="string">'bndbox'</span>][<span class="string">'ymax'</span>]) / height)</span><br><span class="line">    classes_text.append(obj[<span class="string">'name'</span>].encode(<span class="string">'utf8'</span>))</span><br><span class="line">    classes.append(label_map_dict[obj[<span class="string">'name'</span>]])</span><br><span class="line">    truncated.append(int(obj[<span class="string">'truncated'</span>]))</span><br><span class="line">    poses.append(obj[<span class="string">'pose'</span>].encode(<span class="string">'utf8'</span>))</span><br><span class="line"></span><br><span class="line">  example = tf.train.Example(features=tf.train.Features(feature=&#123;</span><br><span class="line">      <span class="string">'image/height'</span>: dataset_util.int64_feature(height),</span><br><span class="line">      <span class="string">'image/width'</span>: dataset_util.int64_feature(width),</span><br><span class="line">      <span class="string">'image/filename'</span>: dataset_util.bytes_feature(</span><br><span class="line">          data[<span class="string">'filename'</span>].encode(<span class="string">'utf8'</span>)),</span><br><span class="line">      <span class="string">'image/source_id'</span>: dataset_util.bytes_feature(</span><br><span class="line">          data[<span class="string">'filename'</span>].encode(<span class="string">'utf8'</span>)),</span><br><span class="line">      <span class="string">'image/key/sha256'</span>: dataset_util.bytes_feature(key.encode(<span class="string">'utf8'</span>)),</span><br><span class="line">      <span class="string">'image/encoded'</span>: dataset_util.bytes_feature(encoded_jpg),</span><br><span class="line">      <span class="string">'image/format'</span>: dataset_util.bytes_feature(<span class="string">'jpeg'</span>.encode(<span class="string">'utf8'</span>)),</span><br><span class="line">      <span class="string">'image/object/bbox/xmin'</span>: dataset_util.float_list_feature(xmin),</span><br><span class="line">      <span class="string">'image/object/bbox/xmax'</span>: dataset_util.float_list_feature(xmax),</span><br><span class="line">      <span class="string">'image/object/bbox/ymin'</span>: dataset_util.float_list_feature(ymin),</span><br><span class="line">      <span class="string">'image/object/bbox/ymax'</span>: dataset_util.float_list_feature(ymax),</span><br><span class="line">      <span class="string">'image/object/class/text'</span>: dataset_util.bytes_list_feature(classes_text),</span><br><span class="line">      <span class="string">'image/object/class/label'</span>: dataset_util.int64_list_feature(classes),</span><br><span class="line">      <span class="string">'image/object/difficult'</span>: dataset_util.int64_list_feature(difficult_obj),</span><br><span class="line">      <span class="string">'image/object/truncated'</span>: dataset_util.int64_list_feature(truncated),</span><br><span class="line">      <span class="string">'image/object/view'</span>: dataset_util.bytes_list_feature(poses),</span><br><span class="line">  &#125;))</span><br><span class="line">  <span class="keyword">return</span> example</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(_)</span>:</span></span><br><span class="line">  <span class="keyword">if</span> FLAGS.set <span class="keyword">not</span> <span class="keyword">in</span> SETS:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'set must be in : &#123;&#125;'</span>.format(SETS))</span><br><span class="line">  <span class="keyword">if</span> FLAGS.year <span class="keyword">not</span> <span class="keyword">in</span> YEARS:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'year must be in : &#123;&#125;'</span>.format(YEARS))</span><br><span class="line"></span><br><span class="line">  data_dir = FLAGS.data_dir</span><br><span class="line">  years = [<span class="string">'VOC2007'</span>, <span class="string">'VOC2012'</span>]</span><br><span class="line">  <span class="keyword">if</span> FLAGS.year != <span class="string">'merged'</span>:</span><br><span class="line">    years = [FLAGS.year]</span><br><span class="line"></span><br><span class="line">  writer = tf.python_io.TFRecordWriter(FLAGS.output_path)</span><br><span class="line"></span><br><span class="line">  label_map_dict = label_map_util.get_label_map_dict(FLAGS.label_map_path)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> year <span class="keyword">in</span> years:</span><br><span class="line">    logging.info(<span class="string">'Reading from PASCAL %s dataset.'</span>, year)</span><br><span class="line">    examples_path = os.path.join(data_dir, year, <span class="string">'ImageSets'</span>, <span class="string">'Main'</span>,</span><br><span class="line">                                 <span class="string">'aeroplane_'</span> + FLAGS.set + <span class="string">'.txt'</span>)</span><br><span class="line">    annotations_dir = os.path.join(data_dir, year, FLAGS.annotations_dir)</span><br><span class="line">    examples_list = dataset_util.read_examples_list(examples_path)</span><br><span class="line">    <span class="keyword">for</span> idx, example <span class="keyword">in</span> enumerate(examples_list):</span><br><span class="line">      <span class="keyword">if</span> idx % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        logging.info(<span class="string">'On image %d of %d'</span>, idx, len(examples_list))</span><br><span class="line">      path = os.path.join(annotations_dir, example + <span class="string">'.xml'</span>)</span><br><span class="line">      <span class="keyword">with</span> tf.gfile.GFile(path, <span class="string">'r'</span>) <span class="keyword">as</span> fid:</span><br><span class="line">        xml_str = fid.read()</span><br><span class="line">      xml = etree.fromstring(xml_str)</span><br><span class="line">      data = dataset_util.recursive_parse_xml_to_dict(xml)[<span class="string">'annotation'</span>]</span><br><span class="line"></span><br><span class="line">      tf_example = dict_to_tf_example(data, FLAGS.data_dir, label_map_dict,</span><br><span class="line">                                      FLAGS.ignore_difficult_instances)</span><br><span class="line">      writer.write(tf_example.SerializeToString())</span><br><span class="line"></span><br><span class="line">  writer.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  tf.app.run()</span><br></pre></td></tr></table></figure></p></div><p class="readmore"><a href="/2017/09/26/tensorflow-十七弹/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/09/22/EM算法/">EM算法</a></h2><div class="post-meta">2017-09-22</div><div class="post-content"><p>记得曾经写过一篇关于EM算法的博客，在新浪博客上，不知道是因为是没有仔细学习还是别的什么原因，突然发现自己又不太理解这个算法了，所以在这里又详细进行了一番思考和记录。</p>
<h2 id="准备知识"><a href="#准备知识" class="headerlink" title="准备知识"></a>准备知识</h2><h3 id="1-贝叶斯公式："><a href="#1-贝叶斯公式：" class="headerlink" title="1.贝叶斯公式："></a>1.贝叶斯公式：</h3><p>相信学过统计的同学们对这个公式都不会陌生，贝叶斯公式是表示在确定事件A发生的条件下事件B发生的概率，因而我们将此概率称为最大后验概率，公式表示为：<br>$$P(A|B)=\frac{P(B|A)P(A)}{P(B)}\propto L(A|B)P(A)\quad(1)$$<br>其中$P(A)$为事件A出现的先验概率，$P(A|B)$为在B发生的条件下A发生的概率。</p></div><p class="readmore"><a href="/2017/09/22/EM算法/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/09/22/tensorflow-十六弹/">tensorflow-十六弹</a></h2><div class="post-meta">2017-09-22</div><div class="post-content"><p>时隔这么久，又回到了深度学习，其实这一段时间一直有在学习，不过都不系统，想要根据自己的数据训练出一个学习库针对需要的应用进行学习，但是实际上数据获取了，但是数据格式的转换把我难住了，如何进行数据格式的转换，使得转换后的数据格式满足tensorflow/Models的输入需要是要面临的巨大问题，另外数据的标注也是一个不得不面对的问题，由于需要的数据量比较大，则对数据进行标注也是一个很耗费时间的工作，所以就先放一放了，计划是采用Fast-RCNN进行目标的检测，实际上结合了RNN和CNN的深度网络能够 比较高校和准确的在影像上识别出目标，而且需要的训练样本相对较少，在应用中具有很大的优势，但是这次我们从基础开始，讲一讲传说中的RNN。<br>经过以上一段时间的学习相信大家对CNN都有所了解，主要分为：<br>$$[输入]\to[卷积，池化，映射]^n \to [全连接]^n\to[输出]$$<br>简单的来说包含输入层，中间的卷积层池化层，全连接层以及输出层这几个部分，其中卷积池化层可以多次进行，全连接层实际上也是一个神经网络，由此构建了一个深度CNN网络，在CNN中有一个重要的概念就是权值共享，通过权值共享缩小了参数规模，使得学习规模变小，从而使得深度学习成为可能。<br>这一次我们所提的RNN(循环神经网络)和CNN在理念上存在着一些相似性，具体的东西在下面会交代，实际上RNN主要用于解决输入数据存在着序列相关的问题，在CNN的过程中每次输入都是独立的，因此每一层只与其上一层和下一层有关而在RNN中每一层不仅与上一层和下一层有关，另外还与本层的上一次输入有关，由此使得RNN能够对序列数据进行处理，使得RNN在NLP上具有重要的应用。<br>RNN模型图：<br><img src="https://lh3.googleusercontent.com/-sD4LDKBV2CQ/WcSD4gBW8XI/AAAAAAAACX0/OOlvuN52Ve0RSHr-9O3YJLV3ok89t286gCLcBGAs/s0/rnn.png" alt="RNN模型" title="rnn.png"><br>通过以上模型可以看出整个RNN的运行过程，左侧为pack的模型，右侧为unpack的模型，上图的模型中$x_i$为输入数据$A$为隐含层的网络单元结构，$h_i$为输出数据，我们看到每一个隐含层的网络单元结构不仅要与输入和输出相连还要与它本身相连，由此构成了一个循环神经网络。<br>实际上在应用过程中，简单的RNN由于其结构比较简单，在进行循环的过程中通过上一次的输入调整$A$然而实际上在网络深度较大的情况下，早期的数据已经无法对$A$产生影响，或者说影响已经被抹去了，因此传统简单的RNN神经元只有短时记忆而不具备长期记忆功能，对于深度较大的应用来说有着明显的缺陷，因此需要对神经元的结构进行调整，由此产生了LSTM结构：<br><img src="https://lh3.googleusercontent.com/-IO7_OIIy5kA/WcS1fjQGSCI/AAAAAAAACYI/-LKRPcuDwQIG2W5-s2CQ--Cd8JSiv7LNQCLcBGAs/s0/LSTM.png" alt="简单神经元与LSTM对比" title="LSTM.png"><br>从以上对比可以看出LSTM在神经元的循环过程中有着更复杂的结构,另外由于LSTM能够克服传统RNN无法处理的短时记忆的问题，因此在网络中同时包含了短期记忆和长期记忆的两种情况，下面我们仔细谈谈LSTM的神经元结构：<br><img src="https://lh3.googleusercontent.com/-KRiyDpdgBwU/WcS3qvMeTEI/AAAAAAAACYY/R5-UN4xOeNEZlY2yltpfWSP3trDQNxaBwCLcBGAs/s0/LSTMShort.png" alt="LSTM步骤详细分析" title="LSTMShort.png"><br>OK，这样的话我们先分析上面四幅图中的图a，图a指示的是从上次和输入获取的信息中无用的部分，就是需要放弃的部分，计算方法为：<br>$$f_t=\sigma(W_f\cdot[h_m,x_t]+b_f)(1)$$<br>在记忆过程中并不是所有的信息都是有意义的，放弃那些没有意义的输入对于进行长期的记忆具有重要的作用，图b表示获取需要存储的信息，这一里包含了两个部分：</p></div><p class="readmore"><a href="/2017/09/22/tensorflow-十六弹/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2017/09/20/公式反推/">公式反推</a></h2><div class="post-meta">2017-09-20</div><div class="post-content"><p>正常情况下通过前方交会求解公式为：<br>$$x=PX(1)$$<br>其中矩阵$P$包含内参矩阵，旋转和平移矩阵，即$P=K[R|t]$,在此情况下进行求解，则必须将像点坐标 $x$和空间点坐标$X$转换为齐次式，求解过程为：<br>根据公式$x=PX$,则有 $[x \times P]X=0$ 求解以上齐次线性方程组，通过SVD分解进行分解，在有两个同名点的情况下得到$V$矩阵为求解结果。<br>然而对于几何校正的应用来说，需要根据矩阵$P$计算地面点的坐标，然而$x=PX$中有三个未知数但是只有两个方程组，是一个欠定问题，无法进行求解，实际上在真实求解过程中一般都是假设地面的高程已知，在高程已知的情况下需要求解的参数就只有2个，能够通过以上方程进行求解了，在此探讨整个求解过程，虽然求解过程比较简单，但是在计算机视觉中似乎没有人提到应该如何进行求解。<br>我们将式（1）展开，则有:<br>$$<br>\begin{bmatrix}<br>x\\<br>y\\<br>1\<br>\end{bmatrix}=<br>\begin{bmatrix} a_1 &amp;a_2&amp;a_3&amp;a_4\\ b_1 &amp;b_2&amp;b_3&amp;b_4\\ c_1 &amp;c_2&amp;c_3&amp;c_4 \end{bmatrix}\cdot<br>\begin{bmatrix} X\\ Y\\ Z\\ 1 \end{bmatrix}<br>(2)<br>$$<br>根据式（2）可知三个线性方程组，现在目标在于在已知$Z$的情况下求解$X$和$Y$,因此我们可以将(2)式乘开，有：<br>$$<br>x=a_1X+a_2Y+a_3Z+a_4(3)\\<br>y=b_1X+b_2Y+b_3Z+b_4(4)\\<br>1=c_1X+c_2Y+c_3Z+c_4(5)\\<br>$$<br>实际上对于式(3)-(5)有用的能够用来计算的式子只有(3)(4),下面我们重点考虑(3)(4)式，在计算过程中由于矩阵$P$是已知的，因此$a_i,b_i,c_i$都是<br>已知值，$Z$也是已知的，则式(3)(4)可以转换为：<br>$$<br>x-a_3Za_4=a_1X+a_2Y(6)\\<br>y-b_3Z-b_4=b_1X+b_2Y(7)\\<br>$$<br>将上式写成矩阵的形式则有：<br>$$<br>\begin{bmatrix}\hat{x}\\ \hat{y}\end{bmatrix}=<br>\begin{bmatrix}a_1&amp;a_2\\ b_1&amp;b_2\end{bmatrix}\cdot<br>\begin{bmatrix}X\\ Y\end{bmatrix}(8)<br>$$<br>则直接对上式进行求解可以得到$X,Y$，以上都是在理想情况下的数学推到结果，得到的结论也是显而易见的，为了验证结论的正确性需要在程序中同时通过正解和反解的方式进行验证，经过思考发现实际上计算结果与式(3)-(5)有差异，实际上在计算过程中齐次坐标可能并不是１，因此将式(3)-(5)修改为：<br>$$<br>kx=a_1X+a_2Y+a_3Z+a_4(9)\\<br>ky=b_1X+b_2Y+b_3Z+b_4(10)\\<br>k=c_1X+c_2Y+c_3Z+c_4(11)<br>$$<br>其中$k$为比例系数，则采用x=(9)/(11),y=(10)/(11),在已知$P,Z$的情况下上式转换为：<br>$$<br>x=\frac{a_1X+a_2Y+a_3Z+a_4}{c_1X+c_2Y+c_3Z+c_4}(12)\\<br>y=\frac{b_1X+b_2Y+b_3Z+b_4}{c_1X+c_2Y+c_3Z+c_4}(13)\\<br>$$<br>由式(12)(13)解算得到Ｘ，Ｙ，最后求解结果用矩阵表示为：<br>$$<br>\begin{bmatrix}\hat{a_1}&amp; \hat{a_2} \\ \hat{b_1}&amp;\hat{b_2}\end{bmatrix}\cdot<br>\begin{bmatrix}X\\ Y\end{bmatrix}=<br>\begin{bmatrix}T1\\ T2\end{bmatrix}(14)<br>$$<br>求解式(14)可得$X,Y$</p></div><p class="readmore"><a href="/2017/09/20/公式反推/">阅读更多</a></p></div><nav class="page-navigator"><a class="extend prev" rel="prev" href="/page/4/">上一页</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/6/">下一页</a></nav></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://www.wuweiblog.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/书评/">书评</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/图像处理/">图像处理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/学习/">学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/小说/">小说</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/影评/">影评</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学/">数学</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/游戏/">游戏</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随感/">随感</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/The-Legend-of-1900/" style="font-size: 15px;">The Legend of 1900</a> <a href="/tags/开发/" style="font-size: 15px;">开发</a> <a href="/tags/ArcGIS环境配置/" style="font-size: 15px;">ArcGIS环境配置</a> <a href="/tags/数学/" style="font-size: 15px;">数学</a> <a href="/tags/机器学习，图像处理/" style="font-size: 15px;">机器学习，图像处理</a> <a href="/tags/学习/" style="font-size: 15px;">学习</a> <a href="/tags/效率/" style="font-size: 15px;">效率</a> <a href="/tags/tensorflow学习/" style="font-size: 15px;">tensorflow学习</a> <a href="/tags/图像处理数学原理/" style="font-size: 15px;">图像处理数学原理</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/读书笔记/" style="font-size: 15px;">读书笔记</a> <a href="/tags/openMVG-openMVS学习/" style="font-size: 15px;">openMVG openMVS学习</a> <a href="/tags/你好疯子，影评/" style="font-size: 15px;">你好疯子，影评</a> <a href="/tags/随感/" style="font-size: 15px;">随感</a> <a href="/tags/图像处理/" style="font-size: 15px;">图像处理</a> <a href="/tags/喜剧之王，影评/" style="font-size: 15px;">喜剧之王，影评</a> <a href="/tags/随感，毕业/" style="font-size: 15px;">随感，毕业</a> <a href="/tags/随感-摄影测量/" style="font-size: 15px;">随感-摄影测量</a> <a href="/tags/linux-学习/" style="font-size: 15px;">linux 学习</a> <a href="/tags/校正方法，控制点，光束法平差/" style="font-size: 15px;">校正方法，控制点，光束法平差</a> <a href="/tags/linux学习/" style="font-size: 15px;">linux学习</a> <a href="/tags/书评/" style="font-size: 15px;">书评</a> <a href="/tags/V字仇杀队-浪潮，影评/" style="font-size: 15px;">V字仇杀队,浪潮，影评</a> <a href="/tags/电影十二公民/" style="font-size: 15px;">电影十二公民</a> <a href="/tags/小说/" style="font-size: 15px;">小说</a> <a href="/tags/R-学习/" style="font-size: 15px;">R 学习</a> <a href="/tags/随感－代码重构/" style="font-size: 15px;">随感－代码重构</a> <a href="/tags/爱乐之城，影评/" style="font-size: 15px;">爱乐之城，影评</a> <a href="/tags/狗子日记/" style="font-size: 15px;">狗子日记</a> <a href="/tags/社交网络，影评/" style="font-size: 15px;">社交网络，影评</a> <a href="/tags/图像处理的数学原理/" style="font-size: 15px;">图像处理的数学原理</a> <a href="/tags/星际穿越，影评/" style="font-size: 15px;">星际穿越，影评</a> <a href="/tags/秒速五厘米/" style="font-size: 15px;">秒速五厘米</a> <a href="/tags/海涛之声，影评/" style="font-size: 15px;">海涛之声，影评</a> <a href="/tags/白日梦想家，影评/" style="font-size: 15px;">白日梦想家，影评</a> <a href="/tags/饥荒/" style="font-size: 15px;">饥荒</a> <a href="/tags/一个叫欧维的男人决定去死，书评/" style="font-size: 15px;">一个叫欧维的男人决定去死，书评</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/07/08/python修饰符/">python修饰符</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/04/向往的生活/">向往的生活</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/25/空房子/">空房子</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/20/Flask服务器linux离线配置/">Flask服务器linux离线配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/17/月亮与六便士/">月亮与六便士</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/17/狗子日记十一月四号/">狗子日记十一月四号</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/14/多愁善感/">多愁善感</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/07/不读书(五)/">不读书(五)</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/08/摄影测量P矩阵/">摄影测量P矩阵</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/13/狗日的生活/">狗日的生活</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/RemoteSensingFrank" title="Github" target="_blank">Github</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">吴蔚.转载请注明</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-107160167-1','auto');ga('send','pageview');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>