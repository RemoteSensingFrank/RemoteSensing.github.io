<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>吴蔚</title>
  
  <subtitle>生命不息，折腾不止！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.wuweiblog.com/"/>
  <updated>2018-08-30T15:29:18.590Z</updated>
  <id>http://www.wuweiblog.com/</id>
  
  <author>
    <name>John Doe Thanks the author of the theme</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>一座孤岛</title>
    <link href="http://www.wuweiblog.com/2018/08/30/%E4%B8%80%E5%BA%A7%E5%AD%A4%E5%B2%9B/"/>
    <id>http://www.wuweiblog.com/2018/08/30/一座孤岛/</id>
    <published>2018-08-30T14:39:50.000Z</published>
    <updated>2018-08-30T15:29:18.590Z</updated>
    
    <content type="html"><![CDATA[<p>&nbsp;&nbsp;&nbsp;&nbsp;第一次看这部电影应该是本科的时候，晚上本来在研究RNN，突然有点烦，又把这部剧情舒缓的动画翻出来看看。动画讲述一位澳大利亚女孩儿与一位纽约具有自闭症的中年通过书信往来结下深厚友谊的故事，小女孩儿Mary生活的家庭并不幸福，生活中缺少父亲的陪伴和母亲的关爱，另外由于既不聪明也不可爱，所以从小就没有什么朋友。一次偶然的机会，女孩儿突发奇想，想要给一位笔友写信，于是这封信漂洋过海来到纽约，让Max看到了这封信，由此揭开了他们长达二十年的友情。<br>&nbsp;&nbsp;&nbsp;&nbsp;这是一部黏土动画，没有什么激烈的剧情冲突，只是简单的通过一封封的书信介绍各自的生活以及对生活的看法。通过一封封的书信，我们看到了两个孤独的身影，跨过万水千山，相互鼓励相互安慰。我看到有人说是爱情，实际上却不是这么认为，爱情的力量可以跨越万水千山，也可以相互鼓励和安慰，但是爱情更多的陪伴，是双目对视时眼中溢出的爱意，是房间里留下的某个人的身影，是一日不见如隔三秋的思念。而友情却不是这样，与爱相似，但是与爱无关，可以陪伴，也可以潇洒离开。在这里我不想谈关于友情还是爱情，当我重新看完这一部影片后涌现最深刻的感受是孤独。<br>&nbsp;&nbsp;&nbsp;&nbsp;我们生而孤独，如同身处一座孤岛，这便是我们一生的牢笼，不管是身体上还是心理上，爱情是找到一个愿意踏上你的岛来陪你孤独的人，而友情是在另一座岛上理解你孤独的人。实际上这两种感情中的任何一种都是可遇而不可求的，所以我们不断的遇见，然后不断的忘记，最后发现原来还是只有自己。有时候我回家，坐在书房看着我的琴发呆，或者是关上了所有的灯，坐在客厅沙发上发呆。有时候我会想，如果我这一生就这么过去了，一个人默默的在这黑暗中死去，那该是一件多么悲伤的故事。前一些日子看到日本的一个无缘死亡，会感觉到有一些恐慌；一个人没有伴侣，失去所有亲人与朋友之后独自在自己的住所迎接死亡的到来，这该有多么可怕。实际上我们又注定要迎接死亡的到来，前几天的时候以为舅奶奶去世了，我是才知道消息。在我的印象中她的身体一直都很好的，直到我舅姥爷去世，她的身体便是一日不如一日了。也许是思念，也许是孤独，总之是一日不如一日。所以我会想，如果远在天边有一个人，他能够明白我的孤独，能够分担我的忧伤，分享我的快乐，这是一件多么美好的事情。实际上社交网络与通讯工具的发展让我们距离更近了，却更加疏离了。我想你，所以我给你电话，然后我还是想你，我又给你电话，然后你觉得我很烦，我也觉得自己很烦，所以我便不想你了,失去距离让我们的沟通更加高效，但是我们的思念变得廉价，我们的理解我们的同理心变得一文不值，所以我们变得更加孤独了，我们只想找到一个温暖的怀抱来填满我们空空荡荡的房间，而不是一个美好的灵魂来填满我们空空荡荡的心。<br>&nbsp;&nbsp;&nbsp;&nbsp;电影看完了，实际上还是很羡慕剧中Mary和Max，虽然面对生活的泥潭，但是如果我知道远在天边如果有一个人能够理解我，也在盼着我的消息，想想也应该是让生活无论如何都要继续下去的动力吧。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;第一次看这部电影应该是本科的时候，晚上本来在研究RNN，突然有点烦，又把这部剧情舒缓的动画翻出来看看。动画讲述一位澳大利亚女孩儿与一位纽约具有自闭症的中年通过书信往来结下深厚友谊的故事，小女孩儿Mary生活的家庭并不幸福，生活
      
    
    </summary>
    
      <category term="影评" scheme="http://www.wuweiblog.com/categories/%E5%BD%B1%E8%AF%84/"/>
    
    
      <category term="Mary and Max，影评" scheme="http://www.wuweiblog.com/tags/Mary-and-Max%EF%BC%8C%E5%BD%B1%E8%AF%84/"/>
    
  </entry>
  
  <entry>
    <title>不读书(六)</title>
    <link href="http://www.wuweiblog.com/2018/08/29/%E4%B8%8D%E8%AF%BB%E4%B9%A6(%E5%85%AD)/"/>
    <id>http://www.wuweiblog.com/2018/08/29/不读书(六)/</id>
    <published>2018-08-29T00:09:29.000Z</published>
    <updated>2018-08-29T08:36:12.035Z</updated>
    
    <content type="html"><![CDATA[<p>&nbsp;&nbsp;&nbsp;&nbsp;要是在四五年前看这本书，我可能不会喜欢，现在看起来却是看得我直冒冷汗。其实我不太喜欢潜规则这个词，这个词显得太不正义，总有一种鬼鬼祟祟的感觉，但是不得不承认，这个词的创立简直是对几千年来社会处事准则最准确的归纳和概括。为什么叫潜规则，因为这样的规则是不能放在台面上说的，为什么不能放在台面上说，因为其中涉及了太多人性中不是那么光明伟岸的一面，所以我们本能的对其缄口不言，但是行事中却默许其存在。<br>&nbsp;&nbsp;&nbsp;&nbsp;晶姐推荐的这本书在上周终于看完了，看前半部分的时候会震撼很多，后半部分反而习以为常了，本书全面的介绍了潜规则在中国这个集权社会中的体现，分析了潜规则形成的原因并解释了这么多年来一直存在的理由。整本书以古代官场为背景，分析了古代官场中一系列的潜规则现象。实际上几千年来，我国作为一个中央集权制的国家，国家掌握着最大的资源和话语权，而作为国家代表的官员则是国家资源分配权力的实际掌控者。实际上整个社会阶层呈现一个金字塔状，最底层是数量最多的百姓，然后依次向上是逐级官僚，实际上整个官僚体系都是建立在对农名阶级的剥削基础上。但是为了避免过度剥削而引起整个体系的崩塌，于是乎建立了一整套例如仁义道德，忠君爱民，清正廉明等等不过是一套看似华丽的外衣罢了，说到底不过是赤裸裸的利益勾结和利益计算而已。<br>以下是摘抄了书中的几个观点进行分析：</p><blockquote><p>1.一个变质的政府，一个剥削性越来越强、服务性越来越弱的政府，自然也需要变质的官员，需要他们泯灭良心，心狠手辣，否则就要请你走人。这这种背景下，清官和恶棍的混合比率（即清官少，恶棍多）并不是偶然的巧合，而是定向选择的结果。恶政好比是一面筛子，淘汰清官，选择恶棍。<br>2.这就是说，在进行官场谋划，努力摆平各种利害关系的时候，无需考虑老百姓的压力，他们根本就不能构成一个压力集团，甚至连一个舆论集团也不是，不过是一盘散沙。<br>3.第一次接受了圣贤的教育，第二次则是接受胥吏衙役和人间大学的教育。第一次教育教了官员们满口仁义道德，第二次教育教了他们一肚子男盗女娼。<br>4.大家都懂得爱护羊群的重要意义。奈何抵抗不住眼前绵羊的诱惑，也抵抗不住生育狼崽子的诱惑。这也是有道理的：我不吃，别的狼照样吃；我不生，别的狼照样生。个体狼的利益与狼群的集体利益未必一致。如果我的节制不能导致别人的节制，我的自我约束对羊群来说就没有任何意义，徒然减少自己的份额而已。在老狼忍不住饕餮的时候，我可以听到一声叹息：它们要是变成刺猬，俺们不就变成清官了么？<br>5.真实的常规是：对局者双赢，老百姓买单。<br>6.老百姓是个冤大头(大头就是钱的意思。冤大头本意是花了冤枉的钱，引申为上当、不合算等. )。人家骂了他，打了他，吸了他的血，他连找人家的家长哭诉告状都找不起。唯一合算的选择，只剩下一个忍气吞声，继续让人家吸血。</p></blockquote><p>&nbsp;&nbsp;&nbsp;&nbsp;我们选取其中的部分进行详细分析，首先第一个条，劣币驱逐良币理论，官场中正直清廉的官员往往只占极小部分，而且往往郁郁不得志。为什么会出现这样的状况，实际上分析一下做正直官员与做一个非正直官员所承担的风险和收益就可以看出来，做一个正直官员往往面临着得罪同事，得罪上司等一系列风险，维护百姓的利益实际上可能还得不到好评，而一个非正直的官员既能够得到上司的好评又能够得到同事的好评，甚至能够赚得不菲的身价，而他所冒的风险仅仅是收到一些背地里的差评，而这些差评似乎对其官场生涯无关紧要，在风险和收益严重不成比例的情况下，出现劣官驱逐良官的现象也是必然的。另外第五条，对局者双赢，老百姓买单，这个看似不好理解，实际上很好理解，所谓清官与贪官的对局，从官吏组成结构来看只是一个上层制度的调整而已，是一个长期的剥削和短期过度剥削的理念对局，而下层的百姓永远免不了被剥削，因此从官吏阶层来看，对局者是处于双赢的局面的，而百姓总是付出代价的阶级。<br>&nbsp;&nbsp;&nbsp;&nbsp;以上截取了书中的部分观点，实际上我们更关心的是如何解决这个问题，从书中似乎看不到解决问题的具体方略，不过有一点是很明确的，那就是阶层的对立。实际上政府由于其具有较大的话语权，因此虽然说冠冕堂皇的将自己定义为服务者也不能免除其处于管理者的姿态。因此要解决以上问题，首要就是解决管理与服务的定位问题。而这个问题的关键在于执法权的归属问题，实际上所谓的内部监督说到底，立法执法都是统一个阶级，那就难以避免会出现潜规则的现象，因此需要权力的制衡，三权分立能够很好的实现权力的制衡，但是如果处于同一阶级，这样的制衡便失去了意义，重点在于对立的阶层需要掌握制衡的权力。以上是我的一点点看法，个人的意见，不对此负责。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;要是在四五年前看这本书，我可能不会喜欢，现在看起来却是看得我直冒冷汗。其实我不太喜欢潜规则这个词，这个词显得太不正义，总有一种鬼鬼祟祟的感觉，但是不得不承认，这个词的创立简直是对几千年来社会处事准则最准确的归纳和概括。为什么叫
      
    
    </summary>
    
      <category term="书评" scheme="http://www.wuweiblog.com/categories/%E4%B9%A6%E8%AF%84/"/>
    
    
      <category term="潜规则,书评" scheme="http://www.wuweiblog.com/tags/%E6%BD%9C%E8%A7%84%E5%88%99-%E4%B9%A6%E8%AF%84/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow-二十七弹</title>
    <link href="http://www.wuweiblog.com/2018/08/22/tensorflow-%E4%BA%8C%E5%8D%81%E4%B8%83%E5%BC%B9/"/>
    <id>http://www.wuweiblog.com/2018/08/22/tensorflow-二十七弹/</id>
    <published>2018-08-22T10:19:38.000Z</published>
    <updated>2018-08-28T23:46:33.777Z</updated>
    
    <content type="html"><![CDATA[<p>&nbsp;&nbsp;&nbsp;&nbsp;tensorflow的学习进行到这个阶段，实际上已经处于一个入门阶段了，在前面的学习过程中我们着重介绍了CNN的构造以及实现过程，另外也提及了一些关于爬虫的知识以及一些关于机器学习的数学基础，现在感觉整个CNN的过程已经掌握得差不多了，剩下就是各种CNN网络得实现了，这个实际上就跟拼接积木差不多了，是一些调参得过程，其中如果进行深入的数学分析就太复杂了，所以在这里先放一放，先接触一下其他的类型的深度网络，然后再回来研究网络的构造问题，下面主要进行RNN的学习:</p><blockquote><p>RNN:循环神经网络，Recurrent Neural Network。神经网络是一种节点定向连接成环的人工神经网络。这种网络的内部状态可以展示动态时序行为。不同于前馈神经网络的是，RNN可以利用它内部的记忆来处理任意时序的输入序列，这让它可以更容易处理如不分段的手写识别、语音识别等。——百度百科</p></blockquote><p>&nbsp;&nbsp;&nbsp;&nbsp;实际上RNN更重要的作用应该是对于语义的识别，百度百科的定义我们看看就行了。本次学习以及代码参考一下文章以及博客(如有侵权，联系删除)：<br><a href="https://blog.csdn.net/liuchonge/article/details/70809288" target="_blank" rel="noopener">使用TensorFlow实现RNN模型入门篇1</a><br><a href="http://lib.csdn.net/article/aiframework/66348?knId=1756" target="_blank" rel="noopener">RNN入门详解及TensorFlow源码实现–深度学习笔记</a><br><a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" target="_blank" rel="noopener">Recurrent Neural Networks Tutorial, Part 1 – Introduction to RNNs</a><br><a href="https://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html" target="_blank" rel="noopener">Recurrent Neural Networks in Tensorflow I</a><br><a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/" target="_blank" rel="noopener">Recurrent Neural Networks Tutorial, Part 2 – Implementing a RNN with Python, Numpy and Theano</a></p><h2 id="什么是RNN"><a href="#什么是RNN" class="headerlink" title="什么是RNN"></a>什么是RNN</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;既然要学习RNN，那么我们就得先了解一下到底什么是RNN，实际上RNN被创造得目的在于充分利用序列数据的前后文信息。在传统的神经网络中假设没一次的输入和输入（每一次训练）是独立的，但是实际上在生活中我们面对很多问题的时候都会有一个上下文的关系，比如写文章之类的。我们语句的不同输入顺序可能有完全不同的意思，RNN就是来处理这样的问题的。另外我们从另一个角度来思考RNN，也就是我们通常说的记忆，意思就是能够从以前所有的输入数据中提取信息。理论上来说RNN能从记忆无限长时间的信息，但是在实际应用过程中会限制回溯的步长。<br>这里要祭出那张经典的图了：<br><img src="https://blogimage-1251632003.cos.ap-guangzhou.myqcloud.com/rnn.JPG"><br>&nbsp;&nbsp;&nbsp;&nbsp;这张被引用过无数次的图很形象的说明了RNN的过程，实际上左边是RNN的过程，右边是RNN展开的过程，如果我们关心五个单词的句子，整个网络就可以展开成一个五层的神经网络，每个单词就是一层，整个结构为：</p><blockquote><ul><li>$x_t$ is the input at time step $t$. For example, $x_1$ could be a one-hot vector corresponding to the second word of a sentence.  </li><li>$s_t$ is the hidden state at time step t. It’s the “memory” of the network. s_t is calculated based on the previous hidden state and the input at the current step: $s_t=f(Ux_t + Ws_{t-1})$. The function f usually is a nonlinearity such as tanh or ReLU.  $s_{-1}$, which is required to calculate the first hidden state, is typically initialized to all zeroes.  </li><li>$o_t$ is the output at step t. For example, if we wanted to predict the next word in a sentence it would be a vector of probabilities across our vocabulary. $o_t = \mathrm{softmax}(Vs_t)$.  </li></ul></blockquote><p>&nbsp;&nbsp;&nbsp;&nbsp;上面就是几个参数的说明，实际上比较简单也就没有必要再翻译了，看看就好了，下面就上面这个过程做一个简单的说明：  </p><ol><li>实际上可以认为$s_t$是一个记忆网络，能够记录以前所有的信息，而输出层$o_t$的计算仅依赖于时刻$t$的记忆，但是实际情况会复杂一些，因为$s_t$并不能记忆住前面太多步的信息（实际上也没有必要记住前所有步的信息）  </li><li>RNN实际上展开后每一层都是共享的同一参数，所不同的仅仅是输入值，通过此种方式极大的减小了参数的数目（序列输入，输入网络层数可能极大）</li><li>实际上对于部分应用来说不是所有的中间输出步骤都是有效的，我们仅仅关心最后的输出，同样对于输入我们也不需要关心每次的输入，RNN的主要特征是它的隐藏状态，这些隐藏状态可以获取序列数据的信息。</li></ol><h2 id="RNN的应用"><a href="#RNN的应用" class="headerlink" title="RNN的应用"></a>RNN的应用</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;这里就随便谈谈了，实际上RNN做的最多的还是语义理解以及机器翻译工作，最常用的RNN模型问LSTM。具体的介绍参看<a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" target="_blank" rel="noopener">Recurrent Neural Networks Tutorial, Part 1 – Introduction to RNNs</a></p><h3 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;假设有一个m个字母的句子，我们建立如下一个语言模型去预测一个句子出现的可能性：<br>$$\begin{aligned}  P(w_1,…,w_m) = \prod_{i=1}^{m} P(w_i \mid w_1,…, w_{i-1})  \end{aligned}$$<br>&nbsp;&nbsp;&nbsp;&nbsp;通俗的来说，一个句子出现的可能性就是每个单词在它之前单词出现后可能性的后验概率的乘积。语言模型的重要之处在于可以通过语言模型形成一个打分机制，在机器翻译等工作中可以被用来选择最佳的翻译方式。语言模型的另外一个作用在于句式生成，如果我们有了足够丰富的句子，则我们可以通过构建好的语言模型生成句式。从上面的模型可以看出每一个单词生成的可能性都取决于其之前的所有单词，实际上很多模型都并不需要或者说从内存和计算时间的角度来说都无法关注到这么长远的记忆，因此我们会限制记忆的长度，并且对不同时长的记忆给不同大小的权重进行约束。</p><h2 id="RNN实现"><a href="#RNN实现" class="headerlink" title="RNN实现"></a>RNN实现</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;好了以上就是RNN的一些介绍，以及其的应用，为了更加快速的入门RNN，我们通过tensorflow构建一个简单的网络对我们生成的简单数据进行训练。</p><h3 id="训练数据集的说明"><a href="#训练数据集的说明" class="headerlink" title="训练数据集的说明"></a>训练数据集的说明</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;输入序列数据X：在第$t$步，$X_t$有百分之五十的可能性为1，另外百分之五十可能性为0，则$X$可能为$[1,0,0,1,1,1…]$<br>输出序列数据Y：对于任意第$t$步，$Y_t$有百分之五十的可能性为1，如果$X_{t-3}$步为1，则$Y_t$为1的可能性增加百分之50，如果$X_{t-8}$步为1，则$Y_t$为1的可能性下降百分之25%，通过这样的模式就确定了输出数据不仅和当前的输入有关，还与前几次的输入情况有关系；这样的一个网络实际上算是比较简单的网络结构了，我们根据以上生成的数据进行模型的构建。</p><h3 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;对于上面描述的这个简单问题，模型构建就很简单了,实际上对于一个模型来说我们首先要考虑的就是他的输入和输出问题，对于RNN模型我们输入是一个0或1的数据$X_t$以及上一个状态矢量$S_{t-1}$,输出$S_t$为可能性分布矢量，$P_t$是输出结果的预测，则有如下公式：<br>$$<br>\begin{aligned}<br>&amp;S_t=tanh(W(X_t\cdot S_{t-1})+b_s)\<br>&amp;P_t=softmax(US_t,+b_p)<br>\end{aligned}<br>$$<br>@表示向量的组合，$X_t$是一个二进制编码向量，$W$，$b_s$，$U$分别为状态矩阵，严格的来说应该证明为什么迭代就能够收敛到正确解，实际上对预测结果求导，然后导数为0分析其收敛特征，但是一般来说神经网络对于我们来说是一个黑盒过程，所以我们不太关心其背后的数学原理，假设能够收敛，则整个模型为:<br><img src="https://blogimage-1251632003.cos.ap-guangzhou.myqcloud.com/RNNsimple.JPG"><br>&nbsp;&nbsp;&nbsp;&nbsp;上图应该是比较好理解的图，$S_{-1}$为初始状态，可以都为0，然后进行循环计算，实际上训练过程有一个回溯的过程，我们在RNN的数学基础中再去讨论RNN的反向传播过程以及设置记忆长度为多少才合适的问题，现在我们只讲RNN的构造，RNN的构造主要是构造一个RNN_Cell然后复用就好了，主要代码为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">x = tf.placeholder(tf.int32, [batch_size, num_steps], name=<span class="string">'input_placeholder'</span>)</span><br><span class="line">y = tf.placeholder(tf.int32, [batch_size, num_steps], name=<span class="string">'labels_placeholder'</span>)</span><br><span class="line"><span class="comment">#RNN的初始化状态，全设为零。注意state是与input保持一致，接下来会有concat操作，所以这里要有batch的维度。即每个样本都要有隐层状态</span></span><br><span class="line">init_state = tf.zeros([batch_size, state_size])</span><br><span class="line"></span><br><span class="line"><span class="comment">#将输入转化为one-hot编码，两个类别。[batch_size, num_steps, num_classes]</span></span><br><span class="line">x_one_hot = tf.one_hot(x, num_classes)</span><br><span class="line"><span class="comment">#将输入unstack，即在num_steps上解绑，方便给每个循环单元输入。这里可以看出RNN每个cell都处理一个batch的输入（即batch个二进制样本输入）</span></span><br><span class="line">rnn_inputs = tf.unstack(x_one_hot, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义rnn_cell的权重参数，</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'rnn_cell'</span>):</span><br><span class="line">    W = tf.get_variable(<span class="string">'W'</span>, [num_classes + state_size, state_size])</span><br><span class="line">    b = tf.get_variable(<span class="string">'b'</span>, [state_size], initializer=tf.constant_initializer(<span class="number">0.0</span>))</span><br><span class="line"><span class="comment">#使之定义为reuse模式，循环使用，保持参数相同</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_cell</span><span class="params">(rnn_input, state)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'rnn_cell'</span>, reuse=<span class="keyword">True</span>):</span><br><span class="line">        W = tf.get_variable(<span class="string">'W'</span>, [num_classes + state_size, state_size])</span><br><span class="line">        b = tf.get_variable(<span class="string">'b'</span>, [state_size], initializer=tf.constant_initializer(<span class="number">0.0</span>))</span><br><span class="line">    <span class="comment">#定义rnn_cell具体的操作，这里使用的是最简单的rnn，不是LSTM</span></span><br><span class="line">    <span class="keyword">return</span> tf.tanh(tf.matmul(tf.concat([rnn_input, state], <span class="number">1</span>), W) + b)</span><br><span class="line"></span><br><span class="line">state = init_state</span><br><span class="line">rnn_outputs = []</span><br><span class="line"><span class="comment">#循环num_steps次，即将一个序列输入RNN模型</span></span><br><span class="line"><span class="keyword">for</span> rnn_input <span class="keyword">in</span> rnn_inputs:</span><br><span class="line">    state = rnn_cell(rnn_input, state)</span><br><span class="line">    rnn_outputs.append(state)</span><br><span class="line">final_state = rnn_outputs[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义softmax层</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'softmax'</span>):</span><br><span class="line">    W = tf.get_variable(<span class="string">'W'</span>, [state_size, num_classes])</span><br><span class="line">    b = tf.get_variable(<span class="string">'b'</span>, [num_classes], initializer=tf.constant_initializer(<span class="number">0.0</span>))</span><br><span class="line"><span class="comment">#注意，这里要将num_steps个输出全部分别进行计算其输出，然后使用softmax预测</span></span><br><span class="line">logits = [tf.matmul(rnn_output, W) + b <span class="keyword">for</span> rnn_output <span class="keyword">in</span> rnn_outputs]</span><br><span class="line">predictions = [tf.nn.softmax(logit) <span class="keyword">for</span> logit <span class="keyword">in</span> logits]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Turn our y placeholder into a list of labels</span></span><br><span class="line">y_as_list = tf.unstack(y, num=num_steps, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#losses and train_step</span></span><br><span class="line">losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit) <span class="keyword">for</span> \</span><br><span class="line">          logit, label <span class="keyword">in</span> zip(logits, y_as_list)]</span><br><span class="line">total_loss = tf.reduce_mean(losses)</span><br><span class="line">train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)</span><br></pre></td></tr></table></figure></p><p>&nbsp;&nbsp;&nbsp;&nbsp;从以上代码可以看出，输入有$n$个单元，其中$n$为我们记忆回溯的步长，state_size为隐藏层的状态向量，长度根据需求和输入确定，我们直接看核心部分rnn_cell函数，这个函数定义了RNN的核心运算，首先是W和b的定义，然后是定义运算，整个运算过程为：tf.tanh(tf.matmul(tf.concat([rnn_input, state], 1), W) + b)，实际上就是公式中所提到的，这里有一个concat运算，这个运算时将两个矩阵进行连接，由于最开始的时候已经将编码方式转换为了one-hot编码，one-hot编码实际上意思就是采用你一个0-1的向量来对参数进行编码，组成一个参数矩阵，具体的解释可以参考<a href="https://blog.csdn.net/tengyuan93/article/details/78930285" target="_blank" rel="noopener">OneHot编码知识点</a>，通过这样的编码方式编码成可理解的向量，然后通过unstack解绑，得到每一个batch每一个step的输入，最后通过循环填充数据，然后定义输出层与中间层的W与b，进行误差的估计并采用AdagradOptimizer（随机梯度下降）的方法进行迭代。好了，整个过程就介绍到这里，下面一节就准备对RNN的数学基础进行学习。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;tensorflow的学习进行到这个阶段，实际上已经处于一个入门阶段了，在前面的学习过程中我们着重介绍了CNN的构造以及实现过程，另外也提及了一些关于爬虫的知识以及一些关于机器学习的数学基础，现在感觉整个CNN的过程已经掌握得
      
    
    </summary>
    
      <category term="学习" scheme="http://www.wuweiblog.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow学习" scheme="http://www.wuweiblog.com/tags/tensorflow%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow-二十六弹</title>
    <link href="http://www.wuweiblog.com/2018/08/13/tensorflow-%E4%BA%8C%E5%8D%81%E5%85%AD%E5%BC%B9/"/>
    <id>http://www.wuweiblog.com/2018/08/13/tensorflow-二十六弹/</id>
    <published>2018-08-13T14:54:33.000Z</published>
    <updated>2018-08-19T02:00:15.826Z</updated>
    
    <content type="html"><![CDATA[<p>&nbsp;&nbsp;&nbsp;&nbsp;写了很多关于tensorflow的部分，但是都比较零散，因为以前不管是对于python还是对于机器学习都了解得不够深刻，因此写出来的东西也就显得比较零散，代码不能够构成一个体系，所以也就谈不上什么积累，不过是多了解了一些关于tensorflow的东西而已，现在不管是对于python还是对于深度学习都有了更加深刻的理解，所以准备重新对整个过程进行组织，代码进行更加有条理的重构，以便于进行进一步的扩展。<br>&nbsp;&nbsp;目前只搭了一个CNN的框架，整个构架描述为：</p><ul><li>1.定义神经网络的基本结构单元：</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;实际上神经所有的神经网络都会有一些基本的结构体，如权重，如偏置；因为就目前来说神经网络就是n多的拟合线性运算加上一个响应函数进行拟合，所以基本的结构单元都是相似的，因此我们定义了一个神经网络基类来初始化这些基础的结构<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment">#基础网络功能，包括：</span></span><br><span class="line"><span class="comment">#1.权重定义</span></span><br><span class="line"><span class="comment">#2.增益的定义</span></span><br><span class="line"><span class="comment">#3.二维卷积运算</span></span><br><span class="line"><span class="comment">#4.最大值池化</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaseNet</span>:</span></span><br><span class="line">    <span class="comment">#初始化权重</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(self,shape)</span>:</span></span><br><span class="line">        <span class="comment">#从截断的正态分布中输出随机值</span></span><br><span class="line">        initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</span><br><span class="line">        <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#初始化偏置</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(self,shape)</span>:</span></span><br><span class="line">        <span class="comment">#设置常数为0.1</span></span><br><span class="line">        initial = tf.constant(<span class="number">0.1</span>, shape=shape)</span><br><span class="line">        <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#二维卷积运算</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(self,x, W)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>], padding=<span class="string">"SAME"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最大值池化</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],</span><br><span class="line">                              strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>], padding=<span class="string">"SAME"</span>)</span><br></pre></td></tr></table></figure></p><p>&nbsp;&nbsp;&nbsp;&nbsp;从上面的代码中可以看到，我们定义的结构体包括：1.权重变量的定义；2.偏置变量的定义；3.卷积运算；4.池化操作；实际上卷积运算不是所有神经网络通用的操作，仅仅是卷积神经网络需要的操作，但是我们目前就是处理卷积神经网络，为了方便就这么写了。  </p><ul><li>2.特殊网络结构的定义：</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;定义好了基本的神经网络结构以后剩下的工作就是针对某一个神经网络进行特殊的定义，目前我们只定义了卷积神经网络，实际上卷神经网络相对比较简单，主要的结构有两个部分，第一个是卷积层，通过卷积层可以进行参数共享从而减小参数个数，另外通过不同的卷积核实际上可以提取不同的特征从而对目标进行识别，另外一个是池化操作，池化操作是神经网络的一个巨大创新，通过池化这个简单的操作对近邻的特征进行概括，并且通过池化操作可以得到待识别目标的旋转不变特征。</p><ul><li><ol start="3"><li>根据数据对网络进行实例化：</li></ol></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#-*- coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"../data/MNIST_data/"</span>,one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">ckptfiles = <span class="string">'./mnist_LeNet_ckpt/'</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">mnistLeNet</span><span class="params">(LeNet)</span>:</span></span><br><span class="line">    <span class="comment">#初始化网络</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        LeNet.__init__(self,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#控制变量定义</span></span><br><span class="line">        self.learning_rate = <span class="number">0.001</span></span><br><span class="line">        <span class="comment"># 记录已经训练的次数</span></span><br><span class="line">        self.global_step = tf.Variable(<span class="number">0</span>, trainable=<span class="keyword">False</span>)</span><br><span class="line">        self.x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>])</span><br><span class="line">        self.label = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>])</span><br><span class="line">        self.x_image = tf.reshape(self.x, [<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#网路层次定义</span></span><br><span class="line">        self.layer1(<span class="number">5</span>,<span class="number">5</span>,<span class="number">32</span>)</span><br><span class="line">        self.layer2(<span class="number">5</span>,<span class="number">5</span>,<span class="number">64</span>)</span><br><span class="line">        self.fullConnLayer(int(<span class="number">1024</span>))</span><br><span class="line">        self.outputLayer(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#计算参数定义</span></span><br><span class="line">        <span class="comment">#loss</span></span><br><span class="line">        self.loss = -tf.reduce_sum(self.label * tf.log(self.y + <span class="number">1e-10</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># minimize 可传入参数 global_step， 每次训练 global_step的值会增加1</span></span><br><span class="line">        <span class="comment"># 因此，可以通过计算self.global_step这个张量的值，知道当前训练了多少步</span></span><br><span class="line">        self.train = tf.train.AdamOptimizer(self.learning_rate).minimize(</span><br><span class="line">            self.loss, global_step=self.global_step)</span><br><span class="line"></span><br><span class="line">        predict = tf.equal(tf.argmax(self.label, <span class="number">1</span>), tf.argmax(self.y, <span class="number">1</span>))</span><br><span class="line">        self.accuracy = tf.reduce_mean(tf.cast(predict, <span class="string">"float"</span>))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TrainMnistLeNet</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.net = mnistLeNet()</span><br><span class="line">        self.sess = tf.Session()</span><br><span class="line">        self.sess.run(tf.global_variables_initializer())</span><br><span class="line">        self.data = mnist</span><br><span class="line"></span><br><span class="line">    <span class="comment">#模型训练过程</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">trainMnist</span><span class="params">(self)</span>:</span></span><br><span class="line">        batch_size = <span class="number">50</span></span><br><span class="line">        train_step = <span class="number">3000</span></span><br><span class="line">        <span class="comment"># 记录训练次数, 初始化为0</span></span><br><span class="line">        step = <span class="number">0</span></span><br><span class="line">        save_interval = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">        batch_size = <span class="number">50</span></span><br><span class="line">        train_step = <span class="number">3000</span></span><br><span class="line">        <span class="comment"># 记录训练次数, 初始化为0</span></span><br><span class="line">        step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每隔1000步保存模型</span></span><br><span class="line">        <span class="comment">#save_interval = 1000</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># tf.train.Saver是用来保存训练结果的。</span></span><br><span class="line">        <span class="comment"># max_to_keep 用来设置最多保存多少个模型，默认是5</span></span><br><span class="line">        <span class="comment"># 如果保存的模型超过这个值，最旧的模型将被删除</span></span><br><span class="line">        saver = tf.train.Saver(max_to_keep=<span class="number">10</span>)</span><br><span class="line">        ckpt  = tf.train.get_checkpoint_state(ckptfiles)</span><br><span class="line">        merged = tf.summary.merge_all()</span><br><span class="line">        writer = tf.summary.FileWriter(ckptfiles+<span class="string">'graph'</span>,self.sess.graph)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">            saver.restore(self.sess, ckpt.model_checkpoint_path)</span><br><span class="line">            <span class="comment"># 读取网络中的global_step的值，即当前已经训练的次数</span></span><br><span class="line">            step = self.sess.run(self.global_step)</span><br><span class="line">            print(<span class="string">'Continue from'</span>)</span><br><span class="line">            print(<span class="string">'        -&gt; Minibatch update : '</span>, step)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> step &lt; train_step:</span><br><span class="line">            x, label = self.data.train.next_batch(batch_size)</span><br><span class="line">            _, loss = self.sess.run([self.net.train, self.net.loss],</span><br><span class="line">                                    feed_dict=&#123;self.net.x: x, self.net.label: label&#125;)</span><br><span class="line">            step = self.sess.run(self.net.global_step)</span><br><span class="line">            rs=self.sess.run(merged)</span><br><span class="line">            writer.add_summary(rs, step)</span><br><span class="line">            <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">'第%5d步，当前loss：%.2f'</span> % (step, loss))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 模型保存在ckpt文件夹下</span></span><br><span class="line">        <span class="comment"># 模型文件名最后会增加global_step的值，比如1000的模型文件名为 model-1000</span></span><br><span class="line">        <span class="comment">#if step % save_interval == 0:</span></span><br><span class="line">        <span class="comment">#只保存一次模型</span></span><br><span class="line">        saver.save(self.sess, ckptfiles+<span class="string">'model'</span>, global_step=step)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calculate_accuracy</span><span class="params">(self)</span>:</span></span><br><span class="line">        test_x = self.data.test.images</span><br><span class="line">        test_label = self.data.test.labels</span><br><span class="line">        accuracy = self.sess.run(self.net.accuracy,</span><br><span class="line">                                 feed_dict=&#123;self.net.x: test_x, self.net.label: test_label&#125;)</span><br><span class="line">        print(<span class="string">"准确率: %.2f，共测试了%d张图片 "</span> % (accuracy, len(test_label)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    app = TrainMnistLeNet()</span><br><span class="line">    app.trainMnist()</span><br><span class="line">    app.calculate_accuracy()</span><br></pre></td></tr></table></figure><p>&nbsp;&nbsp;&nbsp;&nbsp;这个步骤其实比较简单，就是根据数据对整个网络的输入和输出进行实例化操作，在我的代码中是训练的Mnist数据，所以定义输入的变量的28*28的数据，结果为10个数字，然后获取数据进行训练，由于Mnist数据的解析和处理都在tensorflow的example中被处理了，在处理过程中就省略了这个过程，实际上应该定义一个类专门对数据进行处理和优化。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;写了很多关于tensorflow的部分，但是都比较零散，因为以前不管是对于python还是对于机器学习都了解得不够深刻，因此写出来的东西也就显得比较零散，代码不能够构成一个体系，所以也就谈不上什么积累，不过是多了解了一些关于t
      
    
    </summary>
    
      <category term="学习" scheme="http://www.wuweiblog.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow学习" scheme="http://www.wuweiblog.com/tags/tensorflow%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>RPC（共线条件方程）校正迭代方法分析</title>
    <link href="http://www.wuweiblog.com/2018/07/22/RPC%EF%BC%88%E5%85%B1%E7%BA%BF%E6%9D%A1%E4%BB%B6%E6%96%B9%E7%A8%8B%EF%BC%89%E6%A0%A1%E6%AD%A3%E8%BF%AD%E4%BB%A3%E6%96%B9%E6%B3%95%E5%88%86%E6%9E%90/"/>
    <id>http://www.wuweiblog.com/2018/07/22/RPC（共线条件方程）校正迭代方法分析/</id>
    <published>2018-07-22T13:47:52.000Z</published>
    <updated>2018-07-22T14:20:18.068Z</updated>
    
    <content type="html"><![CDATA[<p>这次主要分析GDAL中RPC校正的实现，以及在GDAL中PRPC校正的迭代方法，另外关于迭代计算还是有一些关于迭代的疑惑：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">bool</span></span><br><span class="line">RPCInverseTransformPoint( GDALRPCTransformInfo *psTransform,</span><br><span class="line">                          <span class="keyword">double</span> dfPixel, <span class="keyword">double</span> dfLine, <span class="keyword">double</span> dfUserHeight,</span><br><span class="line">                          <span class="keyword">double</span> *pdfLong, <span class="keyword">double</span> *pdfLat )</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// Memo:</span></span><br><span class="line">    <span class="comment">// Known to work with 40 iterations with DEM on all points (int coord and</span></span><br><span class="line">    <span class="comment">// +0.5,+0.5 shift) of flock1.20160216_041050_0905.tif, especially on (0,0).</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* -------------------------------------------------------------------- */</span></span><br><span class="line"><span class="comment">/*      Compute an initial approximation based on linear                */</span></span><br><span class="line"><span class="comment">/*      interpolation from our reference point.                         */</span></span><br><span class="line"><span class="comment">/* -------------------------------------------------------------------- */</span></span><br><span class="line">    <span class="keyword">double</span> dfResultX =</span><br><span class="line">        psTransform-&gt;adfPLToLatLongGeoTransform[<span class="number">0</span>] +</span><br><span class="line">        psTransform-&gt;adfPLToLatLongGeoTransform[<span class="number">1</span>] * dfPixel +</span><br><span class="line">        psTransform-&gt;adfPLToLatLongGeoTransform[<span class="number">2</span>] * dfLine;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">double</span> dfResultY =</span><br><span class="line">        psTransform-&gt;adfPLToLatLongGeoTransform[<span class="number">3</span>] +</span><br><span class="line">        psTransform-&gt;adfPLToLatLongGeoTransform[<span class="number">4</span>] * dfPixel +</span><br><span class="line">        psTransform-&gt;adfPLToLatLongGeoTransform[<span class="number">5</span>] * dfLine;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>( psTransform-&gt;bRPCInverseVerbose )</span><br><span class="line">    &#123;</span><br><span class="line">        CPLDebug(<span class="string">"RPC"</span>, <span class="string">"Computing inverse transform for (pixel,line)=(%f,%f)"</span>,</span><br><span class="line">                 dfPixel, dfLine);</span><br><span class="line">    &#125;</span><br><span class="line">    VSILFILE* fpLog = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="keyword">if</span>( psTransform-&gt;pszRPCInverseLog )</span><br><span class="line">    &#123;</span><br><span class="line">        fpLog =</span><br><span class="line">            VSIFOpenL( CPLResetExtension(psTransform-&gt;pszRPCInverseLog, <span class="string">"csvt"</span>),</span><br><span class="line">                       <span class="string">"wb"</span> );</span><br><span class="line">        <span class="keyword">if</span>( fpLog != <span class="literal">nullptr</span> )</span><br><span class="line">        &#123;</span><br><span class="line">            VSIFPrintfL( fpLog, <span class="string">"Integer,Real,Real,Real,String,Real,Real\n"</span> );</span><br><span class="line">            VSIFCloseL( fpLog );</span><br><span class="line">        &#125;</span><br><span class="line">        fpLog = VSIFOpenL( psTransform-&gt;pszRPCInverseLog, <span class="string">"wb"</span> );</span><br><span class="line">        <span class="keyword">if</span>( fpLog != <span class="literal">nullptr</span> )</span><br><span class="line">            VSIFPrintfL(</span><br><span class="line">                fpLog,</span><br><span class="line">                <span class="string">"iter,long,lat,height,WKT,error_pixel_x,error_pixel_y\n"</span> );</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* -------------------------------------------------------------------- */</span></span><br><span class="line"><span class="comment">/*      Now iterate, trying to find a closer LL location that will      */</span></span><br><span class="line"><span class="comment">/*      back transform to the indicated pixel and line.                 */</span></span><br><span class="line"><span class="comment">/* -------------------------------------------------------------------- */</span></span><br><span class="line">    <span class="keyword">double</span> dfPixelDeltaX = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">double</span> dfPixelDeltaY = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">double</span> dfLastResultX = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">double</span> dfLastResultY = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">double</span> dfLastPixelDeltaX = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">double</span> dfLastPixelDeltaY = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">double</span> dfDEMH = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">bool</span> bLastPixelDeltaValid = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> nMaxIterations =</span><br><span class="line">        (psTransform-&gt;nMaxIterations &gt; <span class="number">0</span>) ? psTransform-&gt;nMaxIterations :</span><br><span class="line">        (psTransform-&gt;poDS != <span class="literal">nullptr</span>) ? <span class="number">20</span> : <span class="number">10</span>;</span><br><span class="line">    <span class="keyword">int</span> nCountConsecutiveErrorBelow2 = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> iIter = <span class="number">0</span>;  <span class="comment">// Used after for.</span></span><br><span class="line">    <span class="keyword">for</span>( ; iIter &lt; nMaxIterations; iIter++ )</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">double</span> dfBackPixel = <span class="number">0.0</span>;</span><br><span class="line">        <span class="keyword">double</span> dfBackLine = <span class="number">0.0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Update DEMH.</span></span><br><span class="line">        dfDEMH = <span class="number">0.0</span>;</span><br><span class="line">        <span class="keyword">double</span> dfDEMPixel = <span class="number">0.0</span>;</span><br><span class="line">        <span class="keyword">double</span> dfDEMLine = <span class="number">0.0</span>;</span><br><span class="line">        <span class="keyword">if</span>( !GDALRPCGetHeightAtLongLat(psTransform, dfResultX, dfResultY,</span><br><span class="line">                                       &amp;dfDEMH, &amp;dfDEMPixel, &amp;dfDEMLine) )</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>( psTransform-&gt;poDS )</span><br><span class="line">            &#123;</span><br><span class="line">                CPLDebug(</span><br><span class="line">                    <span class="string">"RPC"</span>, <span class="string">"DEM (pixel, line) = (%g, %g)"</span>,</span><br><span class="line">                    dfDEMPixel, dfDEMLine);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// The first time, the guess might be completely out of the</span></span><br><span class="line">            <span class="comment">// validity of the DEM, so pickup the "reference Z" as the</span></span><br><span class="line">            <span class="comment">// first guess or the closest point of the DEM by snapping to it.</span></span><br><span class="line">            <span class="keyword">if</span>( iIter == <span class="number">0</span> )</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">bool</span> bUseRefZ = <span class="literal">true</span>;</span><br><span class="line">                <span class="keyword">if</span>( psTransform-&gt;poDS )</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="keyword">if</span>( dfDEMPixel &gt;= psTransform-&gt;poDS-&gt;GetRasterXSize() )</span><br><span class="line">                        dfDEMPixel = psTransform-&gt;poDS-&gt;GetRasterXSize() - <span class="number">0.5</span>;</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span>( dfDEMPixel &lt; <span class="number">0</span> )</span><br><span class="line">                        dfDEMPixel = <span class="number">0.5</span>;</span><br><span class="line">                    <span class="keyword">if</span>( dfDEMLine &gt;= psTransform-&gt;poDS-&gt;GetRasterYSize() )</span><br><span class="line">                        dfDEMLine = psTransform-&gt;poDS-&gt;GetRasterYSize() - <span class="number">0.5</span>;</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span>( dfDEMPixel &lt; <span class="number">0</span> )</span><br><span class="line">                        dfDEMPixel = <span class="number">0.5</span>;</span><br><span class="line">                    <span class="keyword">if</span>( GDALRPCGetDEMHeight( psTransform, dfDEMPixel,</span><br><span class="line">                                             dfDEMLine, &amp;dfDEMH) )</span><br><span class="line">                    &#123;</span><br><span class="line">                        bUseRefZ = <span class="literal">false</span>;</span><br><span class="line">                        CPLDebug(</span><br><span class="line">                            <span class="string">"RPC"</span>, <span class="string">"Iteration %d for (pixel, line) = (%g, %g): "</span></span><br><span class="line">                            <span class="string">"No elevation value at %.15g %.15g. "</span></span><br><span class="line">                            <span class="string">"Using elevation %g at DEM (pixel, line) = "</span></span><br><span class="line">                            <span class="string">"(%g, %g) (snapping to boundaries) instead"</span>,</span><br><span class="line">                            iIter, dfPixel, dfLine,</span><br><span class="line">                            dfResultX, dfResultY,</span><br><span class="line">                            dfDEMH, dfDEMPixel, dfDEMLine );</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>( bUseRefZ )</span><br><span class="line">                &#123;</span><br><span class="line">                    dfDEMH = psTransform-&gt;dfRefZ;</span><br><span class="line">                    CPLDebug(</span><br><span class="line">                        <span class="string">"RPC"</span>, <span class="string">"Iteration %d for (pixel, line) = (%g, %g): "</span></span><br><span class="line">                        <span class="string">"No elevation value at %.15g %.15g. "</span></span><br><span class="line">                        <span class="string">"Using elevation %g of reference point instead"</span>,</span><br><span class="line">                        iIter, dfPixel, dfLine,</span><br><span class="line">                        dfResultX, dfResultY,</span><br><span class="line">                        dfDEMH);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                CPLDebug(<span class="string">"RPC"</span>, <span class="string">"Iteration %d for (pixel, line) = (%g, %g): "</span></span><br><span class="line">                          <span class="string">"No elevation value at %.15g %.15g. Erroring out"</span>,</span><br><span class="line">                          iIter, dfPixel, dfLine, dfResultX, dfResultY);</span><br><span class="line">                <span class="keyword">if</span>( fpLog )</span><br><span class="line">                    VSIFCloseL(fpLog);</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        RPCTransformPoint( psTransform, dfResultX, dfResultY,</span><br><span class="line">                           dfUserHeight + dfDEMH,</span><br><span class="line">                           &amp;dfBackPixel, &amp;dfBackLine );</span><br><span class="line"></span><br><span class="line">        dfPixelDeltaX = dfBackPixel - dfPixel;</span><br><span class="line">        dfPixelDeltaY = dfBackLine - dfLine;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>( psTransform-&gt;bRPCInverseVerbose )</span><br><span class="line">        &#123;</span><br><span class="line">            CPLDebug(</span><br><span class="line">                <span class="string">"RPC"</span>, <span class="string">"Iter %d: dfPixelDeltaX=%.02f, dfPixelDeltaY=%.02f, "</span></span><br><span class="line">                <span class="string">"long=%f, lat=%f, height=%f"</span>,</span><br><span class="line">                iIter, dfPixelDeltaX, dfPixelDeltaY,</span><br><span class="line">                dfResultX, dfResultY, dfUserHeight + dfDEMH);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>( fpLog != <span class="literal">nullptr</span> )</span><br><span class="line">        &#123;</span><br><span class="line">            VSIFPrintfL(</span><br><span class="line">                fpLog, <span class="string">"%d,%.12f,%.12f,%f,\"POINT(%.12f %.12f)\",%f,%f\n"</span>,</span><br><span class="line">                iIter, dfResultX, dfResultY, dfUserHeight + dfDEMH,</span><br><span class="line">                dfResultX, dfResultY, dfPixelDeltaX, dfPixelDeltaY);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">double</span> dfError =</span><br><span class="line">            <span class="built_in">std</span>::max(<span class="built_in">std</span>::<span class="built_in">abs</span>(dfPixelDeltaX), <span class="built_in">std</span>::<span class="built_in">abs</span>(dfPixelDeltaY));</span><br><span class="line">        <span class="keyword">if</span>( dfError &lt; psTransform-&gt;dfPixErrThreshold )</span><br><span class="line">        &#123;</span><br><span class="line">            iIter = <span class="number">-1</span>;</span><br><span class="line">            <span class="keyword">if</span>( psTransform-&gt;bRPCInverseVerbose )</span><br><span class="line">            &#123;</span><br><span class="line">                CPLDebug( <span class="string">"RPC"</span>, <span class="string">"Converged!"</span> );</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>( psTransform-&gt;poDS != <span class="literal">nullptr</span> &amp;&amp;</span><br><span class="line">                 bLastPixelDeltaValid &amp;&amp;</span><br><span class="line">                 dfPixelDeltaX * dfLastPixelDeltaX &lt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">                 dfPixelDeltaY * dfLastPixelDeltaY &lt; <span class="number">0</span> )</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// When there is a DEM, if the error changes sign, we might</span></span><br><span class="line">            <span class="comment">// oscillate forever, so take a mean position as a new guess.</span></span><br><span class="line">            <span class="keyword">if</span>( psTransform-&gt;bRPCInverseVerbose )</span><br><span class="line">            &#123;</span><br><span class="line">                CPLDebug(</span><br><span class="line">                    <span class="string">"RPC"</span>, <span class="string">"Oscillation detected. "</span></span><br><span class="line">                    <span class="string">"Taking mean of 2 previous results as new guess"</span> );</span><br><span class="line">            &#125;</span><br><span class="line">            dfResultX =</span><br><span class="line">                ( <span class="built_in">fabs</span>(dfPixelDeltaX) * dfLastResultX +</span><br><span class="line">                  <span class="built_in">fabs</span>(dfLastPixelDeltaX) * dfResultX ) /</span><br><span class="line">                (<span class="built_in">fabs</span>(dfPixelDeltaX) + <span class="built_in">fabs</span>(dfLastPixelDeltaX));</span><br><span class="line">            dfResultY =</span><br><span class="line">                ( <span class="built_in">fabs</span>(dfPixelDeltaY) * dfLastResultY +</span><br><span class="line">                  <span class="built_in">fabs</span>(dfLastPixelDeltaY) * dfResultY ) /</span><br><span class="line">                (<span class="built_in">fabs</span>(dfPixelDeltaY) + <span class="built_in">fabs</span>(dfLastPixelDeltaY));</span><br><span class="line">            bLastPixelDeltaValid = <span class="literal">false</span>;</span><br><span class="line">            nCountConsecutiveErrorBelow2 = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">double</span> dfBoostFactor = <span class="number">1.0</span>;</span><br><span class="line">        <span class="keyword">if</span>( psTransform-&gt;poDS != <span class="literal">nullptr</span> &amp;&amp;</span><br><span class="line">            nCountConsecutiveErrorBelow2 &gt;= <span class="number">5</span> &amp;&amp; dfError &lt; <span class="number">2</span> )</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="comment">// When there is a DEM, if we remain below a given threshold (somewhat</span></span><br><span class="line">          <span class="comment">// arbitrarily set to 2 pixels) for some time, apply a "boost factor"</span></span><br><span class="line">          <span class="comment">// for the new guessed result, in the hope we will go out of the</span></span><br><span class="line">          <span class="comment">// somewhat current stuck situation.</span></span><br><span class="line">          dfBoostFactor = <span class="number">10</span>;</span><br><span class="line">          <span class="keyword">if</span>( psTransform-&gt;bRPCInverseVerbose )</span><br><span class="line">          &#123;</span><br><span class="line">              CPLDebug(<span class="string">"RPC"</span>, <span class="string">"Applying boost factor 10"</span>);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>( dfError &lt; <span class="number">2</span> )</span><br><span class="line">            nCountConsecutiveErrorBelow2++;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            nCountConsecutiveErrorBelow2 = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">double</span> dfNewResultX = dfResultX</span><br><span class="line">            - ( dfPixelDeltaX * psTransform-&gt;adfPLToLatLongGeoTransform[<span class="number">1</span>] *</span><br><span class="line">                dfBoostFactor )</span><br><span class="line">            - ( dfPixelDeltaY * psTransform-&gt;adfPLToLatLongGeoTransform[<span class="number">2</span>] *</span><br><span class="line">                dfBoostFactor );</span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">double</span> dfNewResultY = dfResultY</span><br><span class="line">            - ( dfPixelDeltaX * psTransform-&gt;adfPLToLatLongGeoTransform[<span class="number">4</span>] *</span><br><span class="line">                dfBoostFactor )</span><br><span class="line">            - ( dfPixelDeltaY * psTransform-&gt;adfPLToLatLongGeoTransform[<span class="number">5</span>] *</span><br><span class="line">                dfBoostFactor );</span><br><span class="line"></span><br><span class="line">        dfLastResultX = dfResultX;</span><br><span class="line">        dfLastResultY = dfResultY;</span><br><span class="line">        dfResultX = dfNewResultX;</span><br><span class="line">        dfResultY = dfNewResultY;</span><br><span class="line">        dfLastPixelDeltaX = dfPixelDeltaX;</span><br><span class="line">        dfLastPixelDeltaY = dfPixelDeltaY;</span><br><span class="line">        bLastPixelDeltaValid = <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>( fpLog != <span class="literal">nullptr</span> )</span><br><span class="line">        VSIFCloseL( fpLog );</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>( iIter != <span class="number">-1</span> )</span><br><span class="line">    &#123;</span><br><span class="line">        CPLDebug( <span class="string">"RPC"</span>, <span class="string">"Failed Iterations %d: Got: %.16g,%.16g  Offset=%g,%g"</span>,</span><br><span class="line">                  iIter,</span><br><span class="line">                  dfResultX, dfResultY,</span><br><span class="line">                  dfPixelDeltaX, dfPixelDeltaY );</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    *pdfLong = dfResultX;</span><br><span class="line">    *pdfLat = dfResultY;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>上述代码中有很多判断的部分，我们忽略掉这些部分直接看干货，关于PRC校正的方法在以前的文章中已经做过比较详细的分析了，在这里我们不对校正方法进行分析，直接看迭代过程：<br>首先定义了一系列的变量，包括什么迭代变量，误差限变量等，然后根据变换参数计算像素的初始坐标，计算方法为直接根据参考点进行线性插值得到的，实际上这里应该是存疑的，如果没有参考点应该怎么办，我估计这个转换参数在RPC参数中应该是保存的，所以在这里也不详细分析了，代码部分也没有具体实现，我们直接理解就是一个初始化的计算参数。迭代的计算过程为：</p><ul><li>根据坐标以及DEM计算初始位置的高程，然后就是一系列的判断，包括判断DEM的坐标系与给出影像的坐标系，判断是否能够得到高程，以及一系列其他的判断；然后最后的结果就是得到DEM的高程，整个判断结束；</li><li>RPC反算，根据坐标和RPC参数反算出对应的像素点的坐标;</li><li>计算当前给出的上一次给出的像素值和反解出的像素值的误差值；</li><li>判断误差值是否超限了，如果误差在误差限内则说明精度满足要求直接跳出循环了，如果超过误差限则进行迭代；（p.s:在这里GDAL有一个判断我觉得做得很好，在迭代的过程中给了一个猜测参数，如果整个迭代的过程出现oscillate现象，则重新给一个猜测值，这个值的给定估计也有一点经验）</li><li>新的值等于原来的值加上误差项（表现为差值）</li></ul><p>对于以上过程的前几步都是比较好理解的，但是对于这个最后一个新值的获取我有一些疑惑，如果我自己实现的话我会直接用新值带入RPC参数解算新的DEM和坐标并进行迭代，关于迭代的误差在以前的文章中也提到过，初始高程设置的不同会导致迭代次数和误差都特别大，想弄清楚两种迭代方式有什么区别，如果搞明白了我会在下一次的文章中进行详细的描述。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这次主要分析GDAL中RPC校正的实现，以及在GDAL中PRPC校正的迭代方法，另外关于迭代计算还是有一些关于迭代的疑惑：&lt;br&gt;&lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span c
      
    
    </summary>
    
      <category term="图像处理" scheme="http://www.wuweiblog.com/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
    
      <category term="图像处理数学原理" scheme="http://www.wuweiblog.com/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>混合高斯分布</title>
    <link href="http://www.wuweiblog.com/2018/07/15/%E6%B7%B7%E5%90%88%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/"/>
    <id>http://www.wuweiblog.com/2018/07/15/混合高斯分布/</id>
    <published>2018-07-15T02:01:55.000Z</published>
    <updated>2018-07-21T06:12:41.798Z</updated>
    
    <content type="html"><![CDATA[<p>本来是想着做一个混合高斯分布，但是想着点云的分布应该不是混合高斯布，所以又想看看是不是应该是均匀分布，但是我仔细一想还是应该是高斯分布，因为我们现在讨论的并不是点云本身的分布特点，而是点云聚类的分布特点，实际上对于给定的类别，距离聚类中心越近属于该类别的可能性就越大，因此还是应当是高斯分布。为了更加具体的说明问题，我模拟以下两个数据集：<br><img src="http://blogimage-1251632003.cosgz.myqcloud.com/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E5%88%86%E5%B8%831.jpg"><br>图中两个点集都是均匀分布，黄色框中为的黑色点为一个随机点，实际上我们认为我们每一个点都是随机均匀分布而且激光束发出的激光理论上也应该是均匀分布，但是实际上地物的分布有其自身的特点，且相似的地物具有聚集性（地理学第一定律）因此我们可以认为地物的分布是具有高斯分布特性的，而地物的分布实际上会影响点云在空间上的密度使其呈现出与地物分布类似的密度。因此我们有理由相信高斯分布县比喻均匀分布能够更好的对地物的分布进行拟合。  </p><h2 id="高斯分布："><a href="#高斯分布：" class="headerlink" title="高斯分布："></a>高斯分布：</h2><p>$$<br>\begin{aligned}<br>&amp;p(x)=\frac{1}{\sqrt{2}\pi}exp(-\frac{x^2}{2}) \<br>&amp;p(x,y)=p(x)*p(y)=\frac{1}{\sqrt{2}\pi}exp(-\frac{x^2+y^2}{2})<br>\end{aligned}<br>$$<br>以上为一维和二维的标准高斯分布，实际上我们将高斯分布扩展到多维，则需要用引入向量表示，即我们用向量$v$表示一个随机向量则多变量的高斯分布可以表示为$p(v)=\frac{1}{\sqrt{2}\pi}exp(-\frac{v^Tv}{2})$,实际上方差的平方要变成协方差，但是由于是标准的正态分布，因此直接$v^Tv$计算就可以了,针对一般情况需要进行一个变换了，由于均值不为0方差存在差异，则我们假设一个线性变换，通过这个线性变换能够将变量变换到标准正态分布上，这个线性变换为$x=A(x-\mu)$,则标准的正态分布可以表示为：<br>$$<br>p(v) = \frac{|A|}{\sqrt{2}\pi}exp[-\frac{1}{2}(x-\mu)\Sigma^{-1}(x-\mu)]<br>$$<br>在上式中$\Sigma$为协方差矩阵,则上式表示的为均值为$\mu$协方差矩阵为$A^TA^-1$的$n$维正态分布。则我们模拟一个二维高斯正态分布的图为：<br><img src="http://blogimage-1251632003.cosgz.myqcloud.com/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E5%88%86%E5%B8%832.jpg"><br>实际上高斯分布是一种常用而且简单的分布，且一般情况下地物聚类的分布特征都符合高斯分布，因此将高斯分布用来对地物进行分类是一个合理的做法。</p><h2 id="高斯混合分布："><a href="#高斯混合分布：" class="headerlink" title="高斯混合分布："></a>高斯混合分布：</h2><p>实际上单高斯分布相对来说比较简单，但是自然地物很少存在单高斯分布的情况，由于地物的复杂性，自然地物呈现的是聚合而且混杂的趋势，因此使用单一的高斯分布对地物分布进行拟合可能存在较大误差，此时需要考虑多高斯分布的情况：<br>$$<br>p(x)=\sum_{k=1}^{K}\pi_{k}\mathcal{N}(x|\mu_{k},\Sigma_K)<br>$$<br>其中$\mathcal{N}(x|\mu_{k})$表示为均值为$\mu_k$协方差矩阵为$\Sigma_K$的高斯分布，实际上高斯混合分布可以看作是$K$个高斯分布的求和。<br>从图上看，高斯混合分布如下图所示：<br><img src="http://blogimage-1251632003.cosgz.myqcloud.com/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E5%88%86%E5%B8%833.jpg"><br>上图是两个高斯分布的模型，从上图可以看出，如果采用一个高斯函数进行拟合会存在较大的误差，拟合效果也不好，至少需要两个高斯函数进行拟合才能够达到比较好的效果。因此我们选择了一个高斯函数进行拟合时可能会存在较大的误差，由此我们也引出了下一个需要讨论的话题，理论上无限个高斯函数可以拟合任意分布，因此只要在$K$足够大的情况下可以对任意函数进行无限精确的拟合，但是这并不是我们想要的结果，这个就是我们下面需要讨论的问题，那就是高斯混合分布的求解问题。</p><h2 id="高斯混合分布求解："><a href="#高斯混合分布求解：" class="headerlink" title="高斯混合分布求解："></a>高斯混合分布求解：</h2><h3 id="初级求解方式："><a href="#初级求解方式：" class="headerlink" title="初级求解方式："></a>初级求解方式：</h3><p>在此情况下，我们假设高斯模型的数量是已知的，那么实际上需要求解的参数就是每一个高斯模型的参数$\mu$和$\Sigma$，实际上我们需要求取的是分布的参数，那么如何求取分布参数呢，一般来说就是使得所有样本都分到最大概率的那一类中，采用的方法一般是最大似然方法，公式表示为：<br>$$<br>f=\prod_{i=1}^N p(x_i)<br>$$<br>实际上由于概率都小于1在连乘过程中容易出现精度不足的现象，因此通过取对数将连乘转换为累加进行处理。则将高斯混合分布的公式代入上式并去对数则参数求解问题转换为：<br>$$<br>    max\Sigma_{i=1}^{N}log(\Sigma_{k=1}^{K}\pi_k\mathcal{N}(x_i|\mu_k,\sigma_k))<br>$$<br>对于求极值问题一般都是求导然后导数等于0进行求解，但是上式太负载，求导过于复杂因此不建议采用求导的方式求极值，一般来说是采用<strong>EM</strong>方法进行求解。<br>实际上对于上式的<strong>EM</strong>求解这里有一个训练的过程，一般来说给的训练数据都是$(x,label)$即数据与其所属类别，对于样本$x$它属于某一个类别$k$的概率为：<br>$$<br>\omega_i(k)=\frac{\pi_k\mathcal{N}(x|\mu_k,\sigma_k)}{\Sigma_{j=1}^{K}\sigma_j\mathcal{N}(x|\mu_j,\sigma_j)}<br>$$<br>在这里是假设所有类别的均值和协方差矩阵都是已知的，判断样本属于类别$k$的概率。因此我们是需要给出一个初始值的。由给定的初始值就可以计算出属于每一类的概率。然后对于每一类实际是要计算其期望和方差，因此已知每一个样本属于某一类后每一类的期望和方差的计算方法为：<br>$$<br>\begin{aligned}<br>&amp; \mu_k=\frac{1}{N}\Sigma_{i=1}^{N}\omega_i(k)x_i \<br>&amp; \sigma_k=\frac{1}{N}\Sigma_{i=1}^{N}\omega_i(k)(x_i-\mu_k)(x_i-\mu_k)^T  \<br>&amp;N_k=\Sigma_{i=1}^{N}\omega_i(k)<br>\end{aligned}<br>$$<br>分析上面的公式我们可以根据样本对每一类的均值以及方差进行重新估计，得到新的均值和方差，并以此迭代最终达到收敛。最简单的实现方式为K-Means方式，通过迭代实现聚类。</p><h3 id="类别数目未知的情况："><a href="#类别数目未知的情况：" class="headerlink" title="类别数目未知的情况："></a>类别数目未知的情况：</h3><p>实际上初级求解方式是在类别数目已知的情况下做估计，对于很多问题，特别是高斯混合分布的问题，我们通常都不知道类别数目，在此情况下求解就与简单的求解方式有着区别，因为在进行参数估计的时候还需要对类别数目有一个估计，实际上给定的类别数目越多估计肯定越准确，但是如果给定类别数目过多可能出现过拟合的现象，所以实际上我们需要对类别数目有一个约束，通常情况下有三种约束方式：$L_0,L_1,L_2$约束，解释一下，0范约束表示类别前系数$\pi_i$不为0的情况尽量多，1范约束表示类别前系数$\pi_i$的1范值尽量小，2范约束表示类别前系数$\pi_i$的2范值尽量小;<br>从误差的角度来说，则我们将混合高斯分布看做是对真值的拟合，则误差描述为：<br>$$<br>E(x)=f(x)+r<br>$$<br>其中$f(x)$为拟合误差，$r$为约束项，实际上我们需要使得误差最小将高斯分布代入到以上的计算过程中；则有<br>$$<br>\begin{aligned}<br>E(x)&amp;=p_t(x)-p(x)+r\<br>&amp;=p_t(x)-\sum_{k=1}^{K}\pi_{k}\mathcal{N}(x|\mu_{k},\Sigma_K)<br>\end{aligned}+\alpha\sum_{i}^K|\pi_i|<br>$$<br>上式加上了$L1$约束，则在求解过程中高斯分布的数目都是需要求解的，同样采用E-M方法进行求解，但是在求解过程中还需要对K值进行调整使其达到最佳值，实际上$\alpha$是对稀疏度的约束，在求解过程中能够体现出来，值越大则越稀疏，越小则稀疏度越低。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本来是想着做一个混合高斯分布，但是想着点云的分布应该不是混合高斯布，所以又想看看是不是应该是均匀分布，但是我仔细一想还是应该是高斯分布，因为我们现在讨论的并不是点云本身的分布特点，而是点云聚类的分布特点，实际上对于给定的类别，距离聚类中心越近属于该类别的可能性就越大，因此还
      
    
    </summary>
    
      <category term="数学" scheme="http://www.wuweiblog.com/categories/%E6%95%B0%E5%AD%A6/"/>
    
    
      <category term="数学" scheme="http://www.wuweiblog.com/tags/%E6%95%B0%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>python修饰符</title>
    <link href="http://www.wuweiblog.com/2018/07/08/python%E4%BF%AE%E9%A5%B0%E7%AC%A6/"/>
    <id>http://www.wuweiblog.com/2018/07/08/python修饰符/</id>
    <published>2018-07-08T15:19:47.000Z</published>
    <updated>2018-07-10T02:54:31.501Z</updated>
    
    <content type="html"><![CDATA[<p>本来分类应该分类到编程这一类下，但是想想所有关于python的学习都放在机器学习下，另外当时学习python的目的就是搞机器学习，所以也就放在了这一类下面，其实python的语法我就不再进行介绍了，面向对象的语言的语法大致上都差不多只是略有点区别而已，但是以前一直有一点不明确，那就是关于修饰符的作用，在做项目的时候看到了并且胡乱使用了一通，今天特意就这个问题进行一下总结。</p><h2 id="内置修饰符"><a href="#内置修饰符" class="headerlink" title="内置修饰符"></a>内置修饰符</h2><p>python的类内置修饰符有三个，分别为staticmethod，classmethod以及property，其作用分别为1.把类中定义的实例方法变成静态方法；2.把类中定义的实例方法变成类方法；3.将类成员修改为类属性。由于Python模块中可以定义函数，因此静态方法和类方法的用处并不多；下面对于staticmethod和classmethod两种方法进行说明，我们知道在定义类和类的成员函数后对于成员函数的调用首先要实例化一个类对象，然后通过类对象来调用成员函数，但是对于静态成员函数的调用则不需要对类进行实例化，实际上以上两种修饰符的作用都类似，但是又有一些区别。我们看几个实例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">testclassmethod</span>:</span></span><br><span class="line"><span class="meta">@classmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printd</span><span class="params">(cls,a,b)</span>:</span></span><br><span class="line">print(a+b)</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">testclassmethod.printd(<span class="number">3</span>,<span class="number">5</span>)</span><br></pre></td></tr></table></figure></p><p>从上面这个例子我们可以看出通过classmethod修饰符的作用，通过修饰符修饰之后成员方法不需要通过实例化就可以对方法进行调用，但是通过修饰符修饰的方法中第一个参数并不是我们常见的self了，变成了cls，这个参数实际上表示类自身，通过这个参数可以调用类的属性和方法，相当于类的一个实例吧；下面我们看看staticmethod：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">teststaticmethod</span>:</span></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printd</span><span class="params">(a,b)</span>:</span></span><br><span class="line">print(a+b)</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">teststaticmethod.printd(<span class="number">3</span>,<span class="number">5</span>)</span><br><span class="line">teststaticmethod().printd(<span class="number">3</span>,<span class="number">5</span>)</span><br></pre></td></tr></table></figure></p><p>比较两部分代码我们可以看到，最主要的区别在于staticmethod进行修饰后不需要再定义一个代表类本身的参数。好了以上两种修饰符就介绍到这里，下面介绍装饰器的作用：</p><h2 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h2><p>在python中我们经常可以看到如下写法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test1</span><span class="params">(f)</span>:</span></span><br><span class="line">f()</span><br><span class="line">print(<span class="string">'test1'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@test1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test2</span><span class="params">()</span>:</span></span><br><span class="line">print(<span class="string">'test2'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">test2()</span><br></pre></td></tr></table></figure></p><p>这个简单的例子说明了装饰器的作用，实际上我们的调用顺序是test1，然后在test1中调用传入函数参数f，然后调用print，我们可以将装饰器理解成函数指针，将装饰器后的函数作为参数输入到装饰器函数中进行调用。<br>P.S. 以上代码都在python3.7 下编译通过，不同版本的python可能略有区别</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本来分类应该分类到编程这一类下，但是想想所有关于python的学习都放在机器学习下，另外当时学习python的目的就是搞机器学习，所以也就放在了这一类下面，其实python的语法我就不再进行介绍了，面向对象的语言的语法大致上都差不多只是略有点区别而已，但是以前一直有一点不明
      
    
    </summary>
    
      <category term="学习" scheme="http://www.wuweiblog.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习，图像处理" scheme="http://www.wuweiblog.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%8C%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>向往的生活</title>
    <link href="http://www.wuweiblog.com/2018/07/04/%E5%90%91%E5%BE%80%E7%9A%84%E7%94%9F%E6%B4%BB/"/>
    <id>http://www.wuweiblog.com/2018/07/04/向往的生活/</id>
    <published>2018-07-04T01:04:14.000Z</published>
    <updated>2018-07-04T23:08:48.854Z</updated>
    
    <content type="html"><![CDATA[<p>最近出差很多，乱七八糟的事情也很多，很长时间没有静下心来思考和总结了，总是感觉自己在匆匆忙忙的奔来奔去，在来往的忙碌中总是感觉丢失了一些东西，虽然看似很忙碌，可是事情似乎总是做的不如自己想的那么好，总有这样或者那样的问题让人觉得不怎么舒服。我不是一个追求完美的人，但是也总是想着能够努力把事情做到最好，可是最近似乎不怎么能够满意。这两天微信上一篇《摧毁一个中间男人有多么容易》的文章在微信朋友圈甚嚣尘上，我默默的看了一篇，从文中看到了满满的焦虑，似乎只要不是暴富我们的人生都有可能被文中所说的情况击垮。所以大家都很焦虑，为工作焦虑，为生活焦虑，为生老病死焦虑，我们在焦虑中惶惶不可终日。所以我总是问自己，到底什么才是我向往的生活。<br>最近湖南电视台出品了一个节目就叫向往的生活，几位明星在山中搭了一个小屋，过上了自给自足的生活，看起来十分美好，院子里的小狗，还有牛羊以及小鸭子，一个大院子，院子里的凉亭，看起来都是那么舒服，让人心生向往。可是似乎觉得那样的生活太美好以至于显得不够真实了。可是我们自己向往的生活又是什么样子呢，这真是一个很难回答的问题，我发现我们总是在生活中背负了太多，我们需要承载父母亲人的过去，需要承载子女的未来，实际上这些都不应该是我们所需要背负的，虽然这么说看起来不孝，也很冷酷，但是这就是我心中的想法。每个人都应该去追求自己人生的价值，从而让自己不至于因为碌碌无为而把希望寄托于子女身上；每个人都应该在活着的时候让自己过得精彩，从而在死亡来临的时候我们能够从容面对。希望从来都不应该是别人给的，生活也是，我们为了实现自己生活的向往和目标而努力，而不是为别人而活。<br>当然，我们国家的传统是很有奉献精神的，父母为子女奉献一生，从而失去自己的生活，那么子女一定要有反哺的意思，所以父母从小孩儿出生开始不仅要为子女的未来准备衣食住行，还要为子女的未来出谋划策，而子女也需要承受这种恩情的重量。这样每个人都是在为别人而活，我不知道这样是否能够真的过上自己想要的生活，还是仅仅是被生活折磨的不知道自己想要什么样的生活。我觉得每个人都应该为自己而活，我想只有为自己而活才能够快乐幸福，而这种幸福才能够影响身边的人去追求自己的幸福。<br>我希望能够为自己而活，我愿意承受自己生活的重量而不是承担所有生活的重量，我希望我可以忽视掉他人的眼光，我希望我能够实现自己的理想，而这就是我向往的生活。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近出差很多，乱七八糟的事情也很多，很长时间没有静下心来思考和总结了，总是感觉自己在匆匆忙忙的奔来奔去，在来往的忙碌中总是感觉丢失了一些东西，虽然看似很忙碌，可是事情似乎总是做的不如自己想的那么好，总有这样或者那样的问题让人觉得不怎么舒服。我不是一个追求完美的人，但是也总是
      
    
    </summary>
    
      <category term="随感" scheme="http://www.wuweiblog.com/categories/%E9%9A%8F%E6%84%9F/"/>
    
    
      <category term="随感" scheme="http://www.wuweiblog.com/tags/%E9%9A%8F%E6%84%9F/"/>
    
  </entry>
  
  <entry>
    <title>空房子</title>
    <link href="http://www.wuweiblog.com/2018/06/25/%E7%A9%BA%E6%88%BF%E5%AD%90/"/>
    <id>http://www.wuweiblog.com/2018/06/25/空房子/</id>
    <published>2018-06-24T22:33:41.000Z</published>
    <updated>2018-06-24T22:58:46.344Z</updated>
    
    <content type="html"><![CDATA[<p>两个星期前把菜包送走了，那天弄到了很晚，大概晚上一点多吧，第二天配菜玩了一天之后晚上就回来了，回到了空空荡荡的房间，本来菜包在的时候有时候会觉得特别烦它，因为它总是掉毛，而且喜欢霸占我的床，并且喜欢破坏家里的东西，可是那天，没有一只毛茸茸的宝宝跳起来迎接我，一种孤独感油然而生，总觉得家里空空荡荡。<br>幸而这一段时间都在出差，所以这种孤独的感觉被冲淡了不少，但是呆在家的时候，这样的孤独仍然是不可避免，很多时候我自以为会享受孤独，实际上自己从来不曾孤独过，不管是高中还是本科，或者是硕士，在宿舍至少有舍友在一起，不论的玩还是聊天都不曾有过孤独的感觉，所以觉得一个人的时光是多么的美好，可是现在真的彻底一个人了，又开始没有理由的慌张起来，不知道为什么会慌张，可是真的会感觉到慌张，有些不知所措。<br>其实一直觉得自己是一个内心丰富的人，能够抵挡得了孤独的侵蚀，甚至能够享受独孤，可是当真当我独自面对空空荡荡的房间的时候自己又不是那么确信了，关上灯，房里安静得如同鬼魅，外面却是吵吵闹闹，这个时候就想到了那著名的一句，热闹是他们的，我什么也没有。对呀我什么也没有，除了孤独，所以在孤独的时候更愿意去思考人生，思考的角度也与别人不同，于是我在想，其实我们这一生所经历过真正孤独的时光并不多，读书的时候有着同学和家人的陪伴，到毕业了又会有伴侣的陪伴或者也会有舍友，然后结婚了，与爱人一起过完自己的这一生，我们的一生似乎都在他人的陪伴下度过，而自己一个人的时光却很少经历，所以导致我们面对孤独的时候很难从生活中获取经验，我们所了解的不过是那些书中人们所面对孤独的方式，可是那都是有着强大自控力和强大意志力的人，我们也许无法做到和他们一样的优秀。而我在面对孤独的时候难免会有些恐慌，有些不知所措。<br>其实一开始我是很开心的，因为独处的时间的多么的宝贵，然而一段时间过后，这样的开心变成了折磨，因为孤独如潮水一样不停的包围着你，侵蚀着你，让你不知道何去何从，让你倍感压抑。其实我们一生，快乐的日子并没有想象中的那么多，当然实际上悲伤的日子也没有感觉的那么多，更多的时候是平淡的日子，而着平淡中如果还透着一丝孤独，那么总是会在骨子里感觉到一丝寒意吧。<br>我送走了我的狗子，我的房子终于变得空空荡荡了，我的房子变得空空荡荡了，我很想念我的狗子。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;两个星期前把菜包送走了，那天弄到了很晚，大概晚上一点多吧，第二天配菜玩了一天之后晚上就回来了，回到了空空荡荡的房间，本来菜包在的时候有时候会觉得特别烦它，因为它总是掉毛，而且喜欢霸占我的床，并且喜欢破坏家里的东西，可是那天，没有一只毛茸茸的宝宝跳起来迎接我，一种孤独感油然而
      
    
    </summary>
    
      <category term="随感" scheme="http://www.wuweiblog.com/categories/%E9%9A%8F%E6%84%9F/"/>
    
    
      <category term="随感" scheme="http://www.wuweiblog.com/tags/%E9%9A%8F%E6%84%9F/"/>
    
  </entry>
  
  <entry>
    <title>Flask服务器linux离线配置</title>
    <link href="http://www.wuweiblog.com/2018/06/20/Flask%E6%9C%8D%E5%8A%A1%E5%99%A8linux%E7%A6%BB%E7%BA%BF%E9%85%8D%E7%BD%AE/"/>
    <id>http://www.wuweiblog.com/2018/06/20/Flask服务器linux离线配置/</id>
    <published>2018-06-19T23:41:11.000Z</published>
    <updated>2018-06-19T23:42:08.211Z</updated>
    
    <content type="html"><![CDATA[<p>Flask为Python的一个轻量级服务器框架，用来做Restful风格的后台程序是十分合适的，再结合Nginx做负载均衡，则整个后台服务器能够承受较大规模的并发和用户访问，在项目中本来是在windows下开发的，不过实际部署环境是linux，弄得有些措手不及，不过好在整个Python框架都是支持跨平台的，所以不管是Windows还是Linux也都能够适用，只是整个环境配置会比较麻烦。<br>涉及到的几个主要的组件为：</p><ul><li>1.Flask以及相关组件</li><li>2.Tornado以及相关组件</li><li>3.SQLAlchemy以及相关组件</li></ul><p>以上三个组件是比较重要的组件，由于每个组件又存在一些依赖关系，所在安装过程中显得比较麻烦，下面我依次介绍每一个组件的安装依赖，以便于在下次部署的过程中能够方便的进行部署：<br>一般来说离线安装组件都是通过pip install 来安装whl文件，因此首先需要安装setuptools以及pip组件。</p><h3 id="Flask组件的安装"><a href="#Flask组件的安装" class="headerlink" title="Flask组件的安装"></a>Flask组件的安装</h3><p>实际上如果是在线环境，则使用yum或者apt-get安装都是极其方便的，在线环境下会自动下载各个依赖，但是在离线环境下就必须先下载安装好各个依赖然后才能够进行Flask的安装，Flask的依赖包括：<br>Werkzeug&gt;=0.7；<br>Jinja2&gt;=2.4, which requires；<br>MarkupSafe；<br>Babel&gt;=0.8, which requires；<br>pytz；<br>itsdangerous&gt;=0.21；<br>实际上安装的过程比较简单，首先下载好离线包，如果没有whl文件就下载源码直接通过编译安装，如果又whl文件则通过pip根据whl文件进行安装，完成依赖库的安装后，就可以安装Flask了，安装的方法同样是下载whl文件然后通过pip install进行安装；</p><h3 id="Tornado组件的安装"><a href="#Tornado组件的安装" class="headerlink" title="Tornado组件的安装"></a>Tornado组件的安装</h3><p>Tornado的安装比较简单，首先下载源码，实际上tornado并没有找到whl文件所以只能够通过源码安装，安装的方式相对来说也比较简单，首先通过tar -zxvf命令解压文件，然后进入文件夹，这是应该又一个setup.py文件，直接通过python setup.py instll 安装tornado，安装过程中没有错误则说明安装完成；</p><h3 id="SQLAlchemy的安装"><a href="#SQLAlchemy的安装" class="headerlink" title="SQLAlchemy的安装"></a>SQLAlchemy的安装</h3><p>要通过python连接MySQL数据库，则需要一些组件，而且整个过程相对会复杂一些，首先需要安装python-devel，在安装的过程中一定要注意python的版本，下载的时候也最好下载对应操作系统，对应python版本的库，以免引起冲突；python-devel是一个rpm库，直接通过rpm -ivh命令进行安装，若在安装过程中没有提示错误，则说明安装成功，安装python运行库后需要安装mysqldb组件，首先下载python-MySQLdb压缩文件，进入压缩文件目录后可以看到有setup.py文件，直接通过python install进行安装就可以了。</p><p>完成以上所有组件的安装后直接运行服务，如果还缺某一个组件，则会提示import的头文件不存在，此时只需要将文件下载下来安装就可以了，整个配置过程是比较方便的，另外要注意的就是python连接数据库的组件，需要注意操作系统和python的版本，安装正确的版本才能够正确是使用</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Flask为Python的一个轻量级服务器框架，用来做Restful风格的后台程序是十分合适的，再结合Nginx做负载均衡，则整个后台服务器能够承受较大规模的并发和用户访问，在项目中本来是在windows下开发的，不过实际部署环境是linux，弄得有些措手不及，不过好在整个
      
    
    </summary>
    
    
      <category term="学习" scheme="http://www.wuweiblog.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>月亮与六便士</title>
    <link href="http://www.wuweiblog.com/2018/06/17/%E6%9C%88%E4%BA%AE%E4%B8%8E%E5%85%AD%E4%BE%BF%E5%A3%AB/"/>
    <id>http://www.wuweiblog.com/2018/06/17/月亮与六便士/</id>
    <published>2018-06-17T05:24:33.000Z</published>
    <updated>2018-08-25T17:28:49.124Z</updated>
    
    <content type="html"><![CDATA[<p>很久没有写点东西了，前一段时间一直太忙了，晚上还要检查代码，江门的项目的部署以及香港项目的结题的事情都压在一起，慌乱得不行，导致了没有时间好好总结一下，正好趁着这个假期把该总结的东西给总结了，把想要写的文章给写了，也算是给自己一个交代。<br>《月亮与六便士》也算得上是一部著名的作品了，前一段时间还是把它看完了，不得不说相比于网络口水文，经典文学的作品看起来要艰难很多，但是也给人更多的思考。作品以法国画家高更为原型，塑造了一个证券经纪人突然抛弃妻子，奔赴一所不知名的小岛将自己的余生专注于绘画的传奇故事。<br>其实倒也说不上传奇，只是这个故事会给我们的价值观带来很大的冲击罢了，一个证券经纪人，放弃安稳的工作，抛下家人，抛弃自己的妻儿和所有财富，只身在一个陌生的地方，把自己的所有精力，精神以及生命都投入到了自己热爱的绘画工作中，直到死去。这其实想想我们大多数人有何尝不是想思特里克兰德的前半生一样，为了生活而苟且，为了生活中的菜米油盐而放下了诗和远方。也许生活不只眼前的苟且，可是我们是否又有勇气去追求我们心中的诗和远方呢？恐怕不是所有人都有放下一切重新开始的勇气吧。我们是否又能够真的看清自己内心的期盼呢，是否我们现在正在过的生活就是我们想要的生活，是否只有名利和金钱才能够满足我们日益增长的欲望呢。小说始终只是小说，说白了也就是如何过完自己的一生而已，我们是要做别人眼中的成功人士还是做自己心中的英雄？这的确是一个两难的问题，选择太难，所以大部分人其实都是在夹缝中求生存而已，所以我们可以做着自己不喜欢的工作而寄希望于有朝一日能够财务自由而去做想做的事情。我们口口声声要来一场说走就走的旅行。如果内心热爱，何必财务自由，如果内心自由何必旅行呢！<br>理想的丰满和现实的骨干永远是不可调和的矛盾，我们永远都在选择，是遵从内心还是屈服于这个世界，思特里克兰德能够遵从于自己的内心，能够不在乎这个世界的意见，最后他的成功成为了他传奇一生的注脚，可是我们普通人呢，我们放下了所有又是否能够找到一生所爱呢？对于大多数人来说月亮虽然美丽，可是却遥不可及，而眼前的六便士却能够解决我们生活的大多数问题，如何选择自然心中有数吧！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;很久没有写点东西了，前一段时间一直太忙了，晚上还要检查代码，江门的项目的部署以及香港项目的结题的事情都压在一起，慌乱得不行，导致了没有时间好好总结一下，正好趁着这个假期把该总结的东西给总结了，把想要写的文章给写了，也算是给自己一个交代。&lt;br&gt;《月亮与六便士》也算得上是一部
      
    
    </summary>
    
      <category term="书评" scheme="http://www.wuweiblog.com/categories/%E4%B9%A6%E8%AF%84/"/>
    
    
      <category term="月亮与六便士" scheme="http://www.wuweiblog.com/tags/%E6%9C%88%E4%BA%AE%E4%B8%8E%E5%85%AD%E4%BE%BF%E5%A3%AB/"/>
    
  </entry>
  
  <entry>
    <title>狗子日记十一月四号</title>
    <link href="http://www.wuweiblog.com/2018/06/17/%E7%8B%97%E5%AD%90%E6%97%A5%E8%AE%B0%E5%8D%81%E4%B8%80%E6%9C%88%E5%9B%9B%E5%8F%B7/"/>
    <id>http://www.wuweiblog.com/2018/06/17/狗子日记十一月四号/</id>
    <published>2018-06-17T04:49:31.928Z</published>
    <updated>2017-11-05T14:28:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>下午的时候刘艳在家打扫卫生，她突然很激动的跟我说：＂我捡到了一粒黑色的扣子！＂<br>我表示一脸茫然，怎么会有黑色扣子，难道是哪件衣服上掉的？于是我说：＂黑色扣子，怎么会有黑色扣子？＂<br>随后又传来一声尖叫:”啊～～～！”<br>把我吓了一跳，＂怎么啦！＂我赶紧问．然后出去看看发生了啥.<br>她看到我出来又很激动的跟我说：＂那个不是黑色的扣子，那个是菜包的屎，沾上了它的毛～气死我啦！＂<br>于是我们转头看向菜包，正趴在地上的菜包感觉到了我们两个人充满杀气的目光突然惊恐的站了起来：＂你们要干啥！你们不要这么看着本大王~＂<br>于是我们开始质问:”菜包，你怎么把你的粑粑弄到客厅来了~”<br>菜包一脸茫然：＂你在说什么，我完全听不懂的样子!＂<br>我们满头黑线:”….你又在装，看来每天不揍你你就不舒服呀！”，于是我抄起了我的拖鞋．<br>菜包吓得赶快翻肚皮：＂我冤枉呀～，我真的什么都不知道，你们就是打死我也没有用呀~＂<br>本着宁可错杀一千不能放过一个的原则，我们依然把菜包揍了一顿，然后心满意足的回房间了.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;下午的时候刘艳在家打扫卫生，她突然很激动的跟我说：＂我捡到了一粒黑色的扣子！＂&lt;br&gt;我表示一脸茫然，怎么会有黑色扣子，难道是哪件衣服上掉的？于是我说：＂黑色扣子，怎么会有黑色扣子？＂&lt;br&gt;随后又传来一声尖叫:”啊～～～！”&lt;br&gt;把我吓了一跳，＂怎么啦！＂我赶紧问．然后
      
    
    </summary>
    
      <category term="小说" scheme="http://www.wuweiblog.com/categories/%E5%B0%8F%E8%AF%B4/"/>
    
    
      <category term="狗子日记" scheme="http://www.wuweiblog.com/tags/%E7%8B%97%E5%AD%90%E6%97%A5%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>多愁善感</title>
    <link href="http://www.wuweiblog.com/2018/05/14/%E5%A4%9A%E6%84%81%E5%96%84%E6%84%9F/"/>
    <id>http://www.wuweiblog.com/2018/05/14/多愁善感/</id>
    <published>2018-05-14T12:42:14.000Z</published>
    <updated>2018-05-14T13:29:22.000Z</updated>
    
    <content type="html"><![CDATA[<center><p>想说却还没说的 还很多<br>攒着是因为想写成歌<br>让人轻轻地唱着 淡淡地记着<br>就算终于忘了 也值了<br>说不定我一生涓滴意念<br>侥幸汇成河<br>然后我俩各自一端<br>望着大河弯弯 终于敢放胆<br>嘻皮笑脸 面对 人生的难<br>也许我们从未成熟<br>还没能晓得 就快要老了<br>尽管心里活着的还是那个年轻人<br>因为不安而频频回首<br>无知地索求 羞耻于求救<br>不知疲倦地翻越 每一个山丘<br>越过山丘 虽然已白了头<br>喋喋不休 时不我予的哀愁<br>还未如愿见着不朽<br>就把自己先搞丢<br>越过山丘 才发现无人等候<br>喋喋不休 再也唤不回温柔<br>为何记不得上一次是谁给的拥抱<br>在什么时候<br>我没有刻意隐藏 也无意让你感伤<br>多少次我们无醉不欢<br>咒骂人生太短 唏嘘相见恨晚<br>让女人把妆哭花了 也不管<br>遗憾我们从未成熟<br>还没能晓得 就已经老了<br>尽力却仍不明白<br>身边的年轻人<br>给自己随便找个理由<br>向情爱的挑逗 命运的左右<br>不自量力地还手 直至死方休<br>越过山丘 虽然已白了头<br>喋喋不休 时不我予的哀愁<br>还未如愿见着不朽<br>就把自己先搞丢<br>越过山丘 才发现无人等候<br>喋喋不休 再也唤不回了温柔<br>为何记不得上一次是谁给的拥抱<br>在什么时候<br>越过山丘 虽然已白了头<br>喋喋不休 时不我予的哀愁<br>还未如愿见着不朽<br>就把自己先搞丢<br>越过山丘 才发现无人等候<br>喋喋不休 再也唤不回了温柔<br>为何记不得上一次是谁给的拥抱<br>在什么时候<br>喋喋不休 时不我予的哀愁<br>向情爱的挑逗 命运的左右<br>不自量力地还手 直至死方休<br>为何记不得上一次是谁给的拥抱<br>在什么时候<br>             ——李宗盛《山丘》<br></p></center><br>不知道什么时候开始喜欢听李宗盛了，今天特意让天猫精灵播放了几首李宗盛的歌，总是感觉最近有些多愁善感了，而我自己察觉到自己情绪的变化就在昨天，昨天的时候一个人在家宅了一天，没有干什么正经事情，看了一部青春剧，打了几局星际争霸1，发现原来自己连AI都已经打不过了，只好默默的又去看剧了。青春剧似乎真的能够让人变得青春，看到剧中人扮演的高中生又不禁想起了自己的高中生活。五一之前聪哥来了广州一趟，我，亮仔还有聪哥一起小聚了一下，在一起的时候也是诸多感叹，然后五一因为科姐要回长沙了，所以又和科姐小聚了一下。在一起参观了诸多豪车，一起吹着许多牛逼，实际上大家都怂得很，毕竟我们吧积蓄加起来凑一个首付都太勉强。想想高中的同学们相识都已经十年了，十年的时间，真的让人有了太多太多的感慨。从高中到现在，到未来的生活，我们一直都在翻越这生活的山丘。说实话，有没有因为感到碌碌无为而羞愧？说实话我并没有，该奋斗的时候我也不曾放松，一直到现在，到未来，只是会因为自己的年少无知而感到微微有些失落.  <p></p><p>很喜欢这首歌，不是因为歌声中唱出的沧桑，而是沧桑背后的虽然繁华落尽而吾往矣的强大。有人告诉我们，世界上最悲伤的事情不过是英雄末路，美人迟暮；然而这个世界上最令人神往的事情却是英雄末路依然横刀向天，美人迟暮也能接受柴米油盐酱醋茶的生活。所以我们向情爱的挑逗，向命运的左右说不，所以我们不自量力的还手，直自死方休。</p><p>不知道是怎么回事，总是间歇性的对生活有总乱七八遭的感叹，该舍的舍不得，间歇性的喜欢跟往事瞎扯，可能是自己因为自己从来没有放纵过自己的情绪与欲望，所以总会间歇性的抽风。而随着生活一步步向前，总是无法像学生时代那样总是一心一意的做某一件事情，总是觉得未来似乎有无限的可能，随着生活一步步的向前，我们的选择似乎越来越少，所以有些慌了，有些紧张吧，就像那只待宰的羔羊，不管是否害怕，未来总是会来，而当我们的未来越来越窄的时候会不会有些心慌呢？</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;center&gt;

&lt;p&gt;想说却还没说的 还很多&lt;br&gt;攒着是因为想写成歌&lt;br&gt;让人轻轻地唱着 淡淡地记着&lt;br&gt;就算终于忘了 也值了&lt;br&gt;说不定我一生涓滴意念&lt;br&gt;侥幸汇成河&lt;br&gt;然后我俩各自一端&lt;br&gt;望着大河弯弯 终于敢放胆&lt;br&gt;嘻皮笑脸 面对 人生的难&lt;br&gt;也
      
    
    </summary>
    
      <category term="随感" scheme="http://www.wuweiblog.com/categories/%E9%9A%8F%E6%84%9F/"/>
    
    
      <category term="随感" scheme="http://www.wuweiblog.com/tags/%E9%9A%8F%E6%84%9F/"/>
    
  </entry>
  
  <entry>
    <title>不读书(五)</title>
    <link href="http://www.wuweiblog.com/2018/05/07/%E4%B8%8D%E8%AF%BB%E4%B9%A6(%E4%BA%94)/"/>
    <id>http://www.wuweiblog.com/2018/05/07/不读书(五)/</id>
    <published>2018-05-07T15:19:36.000Z</published>
    <updated>2018-08-29T00:12:55.376Z</updated>
    
    <content type="html"><![CDATA[<p>也许不应该在读了这么多书严肃文学的情况下去单独写一本网络小说，但是不得不说，这本书对于我来说还是有一点触动，《将夜》听起来就是一个挺玄幻的的名字，然后又是一个老套的穿越故事，但是相比于其他老套的穿越故事，这个故事还是有那么一点点的不同。不同之处在于每一个人对于命运都有着自己的看法和坚持，每个人都看不清未来，所以每个人都为了那未知的未来而努力而奋斗。<br>很多时候我们其实没有选择，无法选择我们的出生，无法选择很多很多事情，但是有些事情又是可以选择的，比如未来，比如改变。有时候觉得人生太短暂了，短短的几十年，似乎突然就过去了，可是如果我们活得足够长我们会怎样呢？身边的人都与自己渐行渐远，自己孑然一身存活在这个世界上，人们在没有了生存的压力后总是要寻找生活的意义，或者说生命的意义，那么这个问题就很哲学了，我们究竟为了什么而生活，而真正的生活又是什么样子？<br>每每回顾自己这么多年的生活，都会感慨自己这么多年来其实一直是挺顺利的，虽然没有取得让人瞩目的成就，也并没有落到多么不堪的境地，所以有时候会想，这样的生活究竟是好呢还是不好呢，总会在心里有这样或那样的疑惑。不多说自己的感慨了，还是谈谈书的内容吧，相比于一些网络爽文，这本书算是一本比较好的书了。书院中的人都是出世的人，而书的主角算是一个在世俗中摸爬滚打的人，对于我来说，出世就是我们对于世俗的迎合，我们可以压抑自己的欲望，克制自己的痛苦，底下我们的头，只是为了生活，但是在我们心中也有那些坚持，坚持仁！坚持理！坚持爱和希望。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;也许不应该在读了这么多书严肃文学的情况下去单独写一本网络小说，但是不得不说，这本书对于我来说还是有一点触动，《将夜》听起来就是一个挺玄幻的的名字，然后又是一个老套的穿越故事，但是相比于其他老套的穿越故事，这个故事还是有那么一点点的不同。不同之处在于每一个人对于命运都有着自己
      
    
    </summary>
    
      <category term="书评" scheme="http://www.wuweiblog.com/categories/%E4%B9%A6%E8%AF%84/"/>
    
    
      <category term="将夜,书评" scheme="http://www.wuweiblog.com/tags/%E5%B0%86%E5%A4%9C-%E4%B9%A6%E8%AF%84/"/>
    
  </entry>
  
  <entry>
    <title>摄影测量P矩阵</title>
    <link href="http://www.wuweiblog.com/2018/04/08/%E6%91%84%E5%BD%B1%E6%B5%8B%E9%87%8FP%E7%9F%A9%E9%98%B5/"/>
    <id>http://www.wuweiblog.com/2018/04/08/摄影测量P矩阵/</id>
    <published>2018-04-08T14:57:45.000Z</published>
    <updated>2018-04-10T15:01:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>对于理解P矩阵，首先需要理解几个坐标系如图<br><img src="http://blogimage-1251632003.cosgz.myqcloud.com/camera_coordinate.png" align="center"><br>分别为像平面坐标系，像空间坐标系，物方坐标系以及世界坐标系。在讨论的过程中我们暂时不考虑世界坐标系，和像平面坐标系，只考虑像方和物方坐标系如图：  上图中C点为摄影机中心，也认为是坐标系原点，p点为图像中心，假设图像上任意（x,y,f）对应的物方坐标系中的点为(X,Y,Z),则根据三角形相似我们可以列出如下公式：<br>$$<br>\frac{x}{X}=\frac{y}{Y}=\frac{f}{Z}(1)<br>$$<br>实际上以上的(x,y,f)为像空间坐标系中的坐标，对于影像来说，我们获取的坐标为像素坐标，像素坐标是以图像的左上角点为原点沿着图像方向的坐标系统，这里有一个转换公式$x=u_x-x_0,y=y_0-u_y$其中$u_x,x_0,y_0,u_y$分别为x方向像素坐标，像主点的水平中心，y方向像素坐标，像主点垂直中；因此将像素坐标代入公式(1)可得：<br>$$<br>\frac{u_x-x_0}{X}=\frac{y_0-u_y}{Y}=\frac{f}{Z}(2)<br>$$<br>则根据式(2)可得：<br>$$<br>u_x = X\frac{f}{Z}+x_0-&gt;Zu_x=Xf+Zx_0(3)<br>$$<br>$$<br>u_y = -Y\frac{f}{Z}+y_0-&gt;Zu_y=-Yf+Zy_0(4)<br>$$<br>根据以上两式可得：$(Zu_x,Zu_y,Z)=(Xf+Zx_0,-Yf+Z-y_0,Z)$将其写成矩阵的形式则有<br>$$<br>Z(u_x,u_y,1)=<br>\begin{bmatrix}1&amp;0&amp;0\\ 0&amp;-1&amp;0\\ 0&amp;0&amp;1\end{bmatrix}\cdot<br>\begin{bmatrix}f&amp;0&amp;x_0\\ 0&amp;f&amp;y_0\\ 0&amp;0&amp;1\end{bmatrix}\cdot<br>\begin{bmatrix}X\\ Y\\ Z\end{bmatrix}(5)<br>$$<br>以上就式像平面坐标系到物方坐标系的转换，实际上以上矩阵分为三个部分，第一个部分是由于像素坐标和像平面坐标引起的，主要体现坐标轴的方向，第二个部分主要式内方位元素，也就是通常所说的内参，而第三个部分主要是像方坐标系的坐标，根据式(5)实际上可以建立起图像坐标到物方坐标的关系。然而在真实世界中坐标原点往往不是摄影中心，摄影中心和世界坐标系的原点往往存在着一个偏移，另外以影像坐标为原点的坐标系中x轴与y轴与像平面平行，而z轴垂直于像平面。对于真实世界坐标系，以摄影中心为原点的坐标系与世界坐标之间存在着角度的偏移，因此将物方坐标系校正到世界坐标系的过程中存在两个步骤：1.角度的校正；2.位置的平移，角度的校正通过旋转矩阵来实现，而位置的平移则通过平移向量实现，则在此过程中三个角度和三个平移向量就构成了我们通常说的外方位元素。则像方坐标系到世界坐标系的转换公式为：<br>$$<br>\begin{bmatrix}X_w\\ Y_w\\ Z_w\end{bmatrix}=<br>\begin{bmatrix}a_1&amp;a_2&amp;a_3\\ b_1&amp;b_2&amp;b_3\\ c_1&amp;c_2&amp;c_3\end{bmatrix}\cdot<br>\begin{bmatrix}X\\ Y\\ Z\end{bmatrix}+<br>\begin{bmatrix}X_s\\ Y_s\\ Z_s\end{bmatrix}(6)<br>$$<br>根据公式(5,6)可得图像坐标系像世界坐标的转换的公式,此公式中的矩阵P就是要求的矩阵，实际上在控制点足够的情况下可以根据控制点直接求解P矩阵，在摄影测量中P矩阵是通过外参和内参得到，而在计算机视觉中通常并不强调世界坐标系下的绝对坐标，更感兴趣的是相对坐标，因此在计算的过程从A图像到世界坐标然后投影到B图像，这是一个典型的双目视觉的过程，而在这个过程中计算机视觉的的方法会首先根据同名点直接求解变换关系，实际上就是旋转和平移的关系，然后再通过矩阵分解的方式求解出变换矩阵。以计算机视觉的方式求解在求解过程中并不关心每一步矩阵的具体物理意义，而是将理论上非线性问题通过足够多的匹配点和控制点转换为线性问题，然后通过矩阵分解方式得到具有物理意义的参量。通过此种方式求解能够避免在求解过程中出现过多的将非线性问题转换为线性问题而出现的迭代求解的困难，但是要求控制点较多，且由于每一步都是严密求解，对求解的精度要求较高。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;对于理解P矩阵，首先需要理解几个坐标系如图&lt;br&gt;&lt;img src=&quot;http://blogimage-1251632003.cosgz.myqcloud.com/camera_coordinate.png&quot; align=&quot;center&quot;&gt;&lt;br&gt;分别为像平面坐标系，像空间
      
    
    </summary>
    
      <category term="数学" scheme="http://www.wuweiblog.com/categories/%E6%95%B0%E5%AD%A6/"/>
    
    
      <category term="数学" scheme="http://www.wuweiblog.com/tags/%E6%95%B0%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>狗日的生活</title>
    <link href="http://www.wuweiblog.com/2018/03/13/%E7%8B%97%E6%97%A5%E7%9A%84%E7%94%9F%E6%B4%BB/"/>
    <id>http://www.wuweiblog.com/2018/03/13/狗日的生活/</id>
    <published>2018-03-13T13:28:07.000Z</published>
    <updated>2018-03-13T13:53:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>这几天看到一篇文章叫’没有钱的时候如何过得优雅’，也看到某乎上很多大牛的鸡汤，其实关于生活的话题我好像没有什么资格插嘴，关于优雅的生活那就更加谈不上了．曾经我也有同样的困惑，如何过得优雅？当然咯，可能提问者的重点在于没有钱，不过我想其实生活对于普通人来说本来就不是一件优雅的事情，就如同我问以什么样的姿势拉屎才显得优雅是一样的，为啥没有人对拉屎姿势提出疑问呢？这真是一个有趣的事情，当然今天我们谈论的是生活并不是拉屎．不过我们还是可以分析一下，当我们谈论生活的时候我们在谈论什么，实际上我认为生活与拉屎都有共同之处，那就是无论如何都不会优雅，或者说不会一直优雅．如果贫穷没有限制我的想象的话，我大概可以说不管拥有多大的财富，我们在生活中总有不优雅的时候，不管别人看起来多么优雅的人，想到他拉屎的样子我也想不出有多么优雅．<br>所以我这里想说的并不是优雅的生活，这狗日的生活其实一直在逼迫着我们，让我们放下身段去迁就它，可是不管怎么样我们总有一些坚持，总有一些底线是要坚守的，如果我们连最后的底线都因为生活而放弃了，那我们不是一屁股坐在了粪坑里么，所以一定有一些事，有一些信念是我们要坚守的，而为了那些信念，我们的双眼变得模糊，我们双手变得粗糙，我们在生活上越发的不优雅，可是我们在精神上却越发的坚定．其实这是一本很温暖的书，可是我却看到了生活的残酷，其实每一个配角都是值得同情的，他们没有错，他们想要优雅的生活却反而让自己变得不优雅了，而不想优雅生活的人最后却优雅的死去，这是一个多么奇怪的故事，我想这并不是真的生活，真的生活是欧维默默的死去，并在n久之后才被人发现．这狗日的生活一定不会让人这么轻易的得到传说中一切美好的事情，所以灵魂优雅的人一定会孤独的死去，而生活优雅的人一定会在灵魂羞愧和卑微中丧生，无一幸免……</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这几天看到一篇文章叫’没有钱的时候如何过得优雅’，也看到某乎上很多大牛的鸡汤，其实关于生活的话题我好像没有什么资格插嘴，关于优雅的生活那就更加谈不上了．曾经我也有同样的困惑，如何过得优雅？当然咯，可能提问者的重点在于没有钱，不过我想其实生活对于普通人来说本来就不是一件优雅的
      
    
    </summary>
    
      <category term="书评" scheme="http://www.wuweiblog.com/categories/%E4%B9%A6%E8%AF%84/"/>
    
    
      <category term="一个叫欧维的男人决定去死，书评" scheme="http://www.wuweiblog.com/tags/%E4%B8%80%E4%B8%AA%E5%8F%AB%E6%AC%A7%E7%BB%B4%E7%9A%84%E7%94%B7%E4%BA%BA%E5%86%B3%E5%AE%9A%E5%8E%BB%E6%AD%BB%EF%BC%8C%E4%B9%A6%E8%AF%84/"/>
    
  </entry>
  
  <entry>
    <title>社交网络</title>
    <link href="http://www.wuweiblog.com/2018/03/07/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C/"/>
    <id>http://www.wuweiblog.com/2018/03/07/社交网络/</id>
    <published>2018-03-07T14:05:57.000Z</published>
    <updated>2018-03-07T14:38:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>本来以为是介绍社交网络带来的变化，结果是讲facebook的起源和发展，大概这个就是扎克伯格的自传吧，首先我们谈谈这个电影，实际上facebook一开始的思想是一个交”哈佛关系网”的一个思路，目的是为了方便哈佛学生交流和交友，然后扎克伯格在这个思想的基础上进行扩展以及进一步发展，当然如同所有的创业一样，扎克伯格在创业的过程中也面临了很多的问题，这个也可以看作是一个类似＜中国合伙人＞的例子吧，不过结果似乎不如中国合伙人那般好，可是天才总有不一样的掌控的欲望吧，想想乔布斯，可以发现实际上天才都有着常人无法理解的偏执和坚持．实际上电影如果是一个记录片可能会更好一些，整个电影显得有些无聊所以在这里就不多谈．<br>从电影中看到，实际上facebook的发展是飞速的，为什么会有这样的发展，实际上这个是我在看完这部电影后想要思考的问题，从＜未来简史＞这本书看来，信息的交流实际上是一个利好，能够促进进化，但是到现在有一个词也频繁出现在我们面前，那就是过度社交．<br>作为一个社会人，我们每个人都有这基本的社交需求，我们需要有朋友，我们需要和人交流，而在社交网络出现以前，我们只能和周边的人交流，不管我们喜不喜欢或者说愿不愿意，我们的社交是以地域为分界的，不管我们愿不愿意，我们都必须与身边，或者周围的人产生社交关系，在这样的社交关系中，我们个人的想法或是看法都更容易与周围环境趋同，这个现象是难以避免的，特立独行的人总是少部分．而随着社交网络的发展，我们的社交关系可以变得不受地域的限制，在此情况下我们更容易找到有共同语言的社交圈子，换句话说，在互联网上，社交关系只有观点，兴趣上的契合，与基于地域限制的社交关系相比，基于社交网络的社交关系更加纯粹，个人的兴趣和想法更容易找到共鸣，因此在网络时代我们似乎看到更多特立独行的人，实际上在他们的社交圈子中，可能我们才是小众．当然以上所说都是社交网络所带来的利好，实际上，社交网络也是一柄双刃剑，由于网络的虚拟的，是脱离现实的，当现实的社交关系与网络的关系有着较大落差的时候有人便会沉溺于网络无法面对现实的生活．当然这样的人毕竟是少数，但是不得不说，网络的虚拟性会让很多人将其想象的过于美好而忽略了现实，另外随着社交网络的发展，社交方式变得极其简单和方便，我们拿起手机就开始了社交活动，以至于我们的生活已经被这些社交活动所占据而无法开展更加有意义的活动，我们无法丢开手机不刷微信，微博，QQ空间安静的看看书，安静的练练字，或者弹弹琴，我们的生活被社交占据，以至于我们花费了大量的时间在无效的社交上和忽略了自我．<br>在社交网络如此发达的今天，我们作为社会人的作用被无限放大，但是我们对自我的审视和自我的思考变得更加的薄弱，所以我们可能有更加强大的外在条件，我们能够轻易获取更多人的支持，可是我们自己的内心也变得更加的薄弱，也许我们应该更多的去思考社交网络的利弊．</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本来以为是介绍社交网络带来的变化，结果是讲facebook的起源和发展，大概这个就是扎克伯格的自传吧，首先我们谈谈这个电影，实际上facebook一开始的思想是一个交”哈佛关系网”的一个思路，目的是为了方便哈佛学生交流和交友，然后扎克伯格在这个思想的基础上进行扩展以及进一步
      
    
    </summary>
    
      <category term="影评" scheme="http://www.wuweiblog.com/categories/%E5%BD%B1%E8%AF%84/"/>
    
    
      <category term="社交网络，影评" scheme="http://www.wuweiblog.com/tags/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%EF%BC%8C%E5%BD%B1%E8%AF%84/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow-二十五弹</title>
    <link href="http://www.wuweiblog.com/2018/03/05/tensorflow-%E4%BA%8C%E5%8D%81%E4%BA%94%E5%BC%B9/"/>
    <id>http://www.wuweiblog.com/2018/03/05/tensorflow-二十五弹/</id>
    <published>2018-03-05T15:55:02.000Z</published>
    <updated>2018-03-06T15:37:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>忙活了几天终于整合完了，实现了手写数字识别的服务器版本！大家请撒花！！！！，废话不多说，直接上干货，实际上本章内容分为两个部分，首先是机器学习部分，这一部分在上一章中已经有说明，因此在本章中不会详细分析，第二个部分为服务器部分，服务器是使用的Python的Flask框架，主要思路过程为：<br><img src="http://blogimage-1251632003.cosgz.myqcloud.com/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B.png"><br>在这一章中主要讨论服务器建立的思路以及在识别的过程中的相关问题．实际上服务器的搭建比较简单，熟悉Flask框架的同学都能够很快的搭建一个服务器，但是其中有几个小问题需要注意，让我们先看代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> os,base64,json,datetime</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, request,render_template</span><br><span class="line"><span class="keyword">from</span> flask_uploads <span class="keyword">import</span> UploadSet, configure_uploads, IMAGES</span><br><span class="line"><span class="keyword">from</span> CNN_Model <span class="keyword">import</span> readModel</span><br><span class="line">app = Flask(__name__)</span><br><span class="line">m_predict = readModel.Predict()</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/', methods=['GET', 'POST'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">upload_file</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">if</span> request.method == <span class="string">'POST'</span>:</span><br><span class="line">        dataList = json.loads(request.data)</span><br><span class="line">        imagedata = base64.b64decode(dataList[<span class="string">'image'</span>])</span><br><span class="line">        date = datetime.datetime.now()</span><br><span class="line">        datestr = date.strftime(<span class="string">'%Y-%m-%d_%H-%M-%S'</span>)</span><br><span class="line">        image_path = <span class="string">'./ImageFiles/'</span>+datestr+<span class="string">'.png'</span></span><br><span class="line">        file=open(image_path,<span class="string">'wb'</span>)</span><br><span class="line">        file.write(imagedata)</span><br><span class="line">        file.close()</span><br><span class="line">        full_path=os.getcwd()+<span class="string">'/ImageFiles/'</span>+datestr+<span class="string">'.png'</span></span><br><span class="line">        <span class="keyword">return</span> str(m_predict.predict(full_path))</span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">'draw.html'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    app.run()</span><br></pre></td></tr></table></figure></p><p>以上就是整个服务端的代码，代码主要就是一个图片上传，通过解析POST命令获取相关影像数据，实际上由于影像是绘制的，因此在获取过程中直接获取的是影像数据，然后将影像数据重命名为时间，并保存到本地，然后调用深度网络识别模块对影像进行识别并返回识别结果；虽然过程简单但是有几个坑是要注意的，在调用深度学习的识别过程中不能使用相对路径，需要使用绝对路径，因为调用深度学习的识别模块后相对路径可能出现错误，由此造成识别结果错误；另外返回值需要返回一个string类型的值，因此需要将数字的识别结果转换为string类型的字符,好了整个服务端的代码就介绍完毕了，下面是客户端的代码，主要分为两个部分，html文件以及js文件,在flask框架中需要将html文件保存到template文件夹中，将js文件保存到statics文件夹中，这是由于在渲染过程中，服务器会自动在这两个文件夹中进行搜索．代码为：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"draw.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>Document<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">style</span> <span class="attr">type</span>=<span class="string">"text/css"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">    canvas&#123;border:1px solid green;&#125;</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"http://code.jquery.com/jquery-1.4.1.min.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"../static/draw.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">align</span>=<span class="string">"center"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">canvas</span> <span class="attr">id</span>=<span class="string">"myCanvas"</span> <span class="attr">width</span>=<span class="string">"200"</span> <span class="attr">height</span>=<span class="string">"200"</span> <span class="attr">style</span>=<span class="string">"border:2px solid #6699cc"</span>&gt;</span><span class="tag">&lt;/<span class="name">canvas</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"control-ops"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">id</span>=<span class="string">"form1"</span> <span class="attr">runat</span>=<span class="string">"server"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">"button"</span> <span class="attr">class</span>=<span class="string">"btn btn-primary"</span> <span class="attr">onclick</span>=<span class="string">"clearArea()"</span>&gt;</span>清空画板<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">    Line width : <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">"selWidth"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"13"</span>&gt;</span>13<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"17"</span>&gt;</span>17<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"19"</span>&gt;</span>19<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"21"</span>&gt;</span>21<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"23"</span>&gt;</span>23<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"25"</span>&gt;</span>25<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"27"</span>&gt;</span>27<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"29"</span>&gt;</span>29<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"31"</span>&gt;</span>31<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"33"</span> <span class="attr">selected</span>=<span class="string">"selected"</span>&gt;</span>33<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"35"</span>&gt;</span>35<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"37"</span>&gt;</span>37<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span> = <span class="string">"button"</span> <span class="attr">class</span>=<span class="string">"btn btn-primary"</span> <span class="attr">onclick</span>=<span class="string">"UploadPic()"</span>&gt;</span>识别<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">Result: <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">name</span>=<span class="string">"result"</span> <span class="attr">id</span>=<span class="string">"recgResult"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>实际上界面很简单，整个界面如图：<br><img src="http://blogimage-1251632003.cosgz.myqcloud.com/%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E6%9C%8D%E5%8A%A1%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%88%AA%E5%9B%BE.png"><br>界面十分简单，一个绘制窗口的canvas一个清空按钮，一个识别按钮以及识别结果的输出框，实际上识别包括两个过程，绘图结果的上传和识别，实际上按钮调用的函数和画图函数都在js文件中：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> mousePressed = <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">var</span> lastX, lastY;</span><br><span class="line"><span class="keyword">var</span> ctx;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">InitThis</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  ctx= <span class="built_in">document</span>.getElementById(<span class="string">'myCanvas'</span>).getContext(<span class="string">"2d"</span>);</span><br><span class="line"><span class="keyword">var</span> w = ctx.canvas.width;</span><br><span class="line">    <span class="keyword">var</span> h = ctx.canvas.height;</span><br><span class="line">ctx.fillStyle = <span class="string">'#ffffff'</span>;</span><br><span class="line">ctx.fillRect(<span class="number">0</span>,<span class="number">0</span>,w,h);</span><br><span class="line"></span><br><span class="line">    $(<span class="string">'#myCanvas'</span>).mousedown(<span class="function"><span class="keyword">function</span> (<span class="params">e</span>) </span>&#123;</span><br><span class="line">        mousePressed = <span class="literal">true</span>;</span><br><span class="line">        Draw(e.pageX - $(<span class="keyword">this</span>).offset().left, e.pageY - $(<span class="keyword">this</span>).offset().top, <span class="literal">false</span>);</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    $(<span class="string">'#myCanvas'</span>).mousemove(<span class="function"><span class="keyword">function</span> (<span class="params">e</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (mousePressed) &#123;</span><br><span class="line">            Draw(e.pageX - $(<span class="keyword">this</span>).offset().left, e.pageY - $(<span class="keyword">this</span>).offset().top, <span class="literal">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    $(<span class="string">'#myCanvas'</span>).mouseup(<span class="function"><span class="keyword">function</span> (<span class="params">e</span>) </span>&#123;</span><br><span class="line">        mousePressed = <span class="literal">false</span>;</span><br><span class="line">    &#125;);</span><br><span class="line">    $(<span class="string">'#myCanvas'</span>).mouseleave(<span class="function"><span class="keyword">function</span> (<span class="params">e</span>) </span>&#123;</span><br><span class="line">        mousePressed = <span class="literal">false</span>;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Draw</span>(<span class="params">x, y, isDown</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (isDown) &#123;</span><br><span class="line">        ctx.beginPath();</span><br><span class="line">        ctx.strokeStyle = $(<span class="string">'#selColor'</span>).val();</span><br><span class="line">        ctx.lineWidth = $(<span class="string">'#selWidth'</span>).val();</span><br><span class="line">        ctx.lineJoin = <span class="string">"round"</span>;</span><br><span class="line">        ctx.moveTo(lastX, lastY);</span><br><span class="line">        ctx.lineTo(x, y);</span><br><span class="line">        ctx.closePath();</span><br><span class="line">        ctx.stroke();</span><br><span class="line">    &#125;</span><br><span class="line">    lastX = x; lastY = y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">clearArea</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="comment">// Use the identity matrix while clearing the canvas</span></span><br><span class="line">    ctx.setTransform(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">    ctx.clearRect(<span class="number">0</span>, <span class="number">0</span>, ctx.canvas.width, ctx.canvas.height);</span><br><span class="line"><span class="keyword">var</span> w = ctx.canvas.width;</span><br><span class="line"><span class="keyword">var</span> h = ctx.canvas.height;</span><br><span class="line">ctx.fillStyle = <span class="string">'#ffffff'</span>;</span><br><span class="line">ctx.fillRect(<span class="number">0</span>,<span class="number">0</span>,w,h);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">UploadPic</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line"><span class="keyword">var</span> Pic = <span class="built_in">document</span>.getElementById(<span class="string">"myCanvas"</span>).toDataURL(<span class="string">"image/png"</span>);</span><br><span class="line">    Pic = Pic.replace(<span class="regexp">/^data:image\/(png|jpg);base64,/</span>, <span class="string">""</span>)</span><br><span class="line">$.ajax(&#123;</span><br><span class="line">type:<span class="string">'POST'</span>,</span><br><span class="line">url:<span class="string">''</span>,</span><br><span class="line">data:<span class="string">'&#123;"image":"'</span>+Pic+<span class="string">'"&#125;'</span>,</span><br><span class="line">contentType:<span class="string">'application/json;charset=utf-8'</span>,</span><br><span class="line">dataType:<span class="string">'json'</span>,</span><br><span class="line">success:<span class="function"><span class="keyword">function</span>(<span class="params">msg</span>)</span>&#123;</span><br><span class="line">$(<span class="string">'#recgResult'</span>).val(msg);</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">window</span>.onload = <span class="function"><span class="keyword">function</span> (<span class="params"></span>)</span>&#123;</span><br><span class="line">InitThis();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>js文件包含了四个函数，分别为初始化函数，绘制函数，清空画图版函数和图片上传函数，在这里着重说一下图片上传，在js中是通过ajax构造request参数的方式将图片数据转换为数据串然后上传到服务器上的，另外有一个需要注意的点canvas保存的是png影像，会有一个透明度，透明的png会造成较大的识别误差，因此需要将背景绘制为白色；到此整个服务器端识别过程就结束了．由于上一章详细说明了神经网络的构建，在这里就不进行详细说明，有一个点需要注意，在训练过程中所使用的mnist数据归一化到了0-1之间，且进行了取反操作，因此我们在读取图片后不要忘记对图片进行归一化和取反，否则会造成图像识别结果出现较大误差．<br>识别结果如图：<br><img src="http://blogimage-1251632003.cosgz.myqcloud.com/%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E6%9C%8D%E5%8A%A1%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%88%AA%E5%9B%BE.png"><br>整个项目上传在github中，有兴趣可以在<a href="https://github.com/RemoteSensingFrank" target="_blank" rel="noopener">我的github主页</a>上查看</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;忙活了几天终于整合完了，实现了手写数字识别的服务器版本！大家请撒花！！！！，废话不多说，直接上干货，实际上本章内容分为两个部分，首先是机器学习部分，这一部分在上一章中已经有说明，因此在本章中不会详细分析，第二个部分为服务器部分，服务器是使用的Python的Flask框架，主
      
    
    </summary>
    
      <category term="学习" scheme="http://www.wuweiblog.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow学习" scheme="http://www.wuweiblog.com/tags/tensorflow%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow－二十四弹</title>
    <link href="http://www.wuweiblog.com/2018/02/28/tensorflow%EF%BC%8D%E4%BA%8C%E5%8D%81%E5%9B%9B%E5%BC%B9/"/>
    <id>http://www.wuweiblog.com/2018/02/28/tensorflow－二十四弹/</id>
    <published>2018-02-28T14:27:13.000Z</published>
    <updated>2018-02-28T15:08:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>在上次的学习中我学习了如何读取模型，现在我们已经了解了如何训练和如何读取模型，于是我就想做一些真正的应用，如何才能将机器学习应用起来，或者说如何给别人用，这个是需要思考的问题，结合前一段时间学习的通过python搭建服务器，我想到，是不是可以将我们的深度学习的模型也打一个包然后通过web服务的形式给用户使用呢？我觉得这是一个好想法，因此我开始着手进行工作．抛开服务器部分不谈，我们先来谈谈学习过程这个部分.<br>为了能够将模型进行更好的模块化，参考网上资料，我将整个过程分为三个模块，分别为：</p><ul><li>１．网络定义模块</li><li>２．模型训练模块</li><li>３．识别预测模块</li></ul><p>根据三个模块的名称我们能够很方便的了解各个模块的作用，为了帮助理解，我说明一下为什么要分为三个模块而不是简单的分为模型训练和预测识别两个模块，实际上我们在训练识别过程中都是同样的神经网络模型，如果不将网络定义模块独立出来，则可能出现网络重复定义的问题，而且随着网络变得越来越复杂，两次网络定义出现不一致的可能性就越大，因此需要将网络模型的定义独立出来，在训练和识别的过程中进行调用；首先看网络定义模块：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#-*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Network</span>:</span></span><br><span class="line">    <span class="comment">#初始化权重</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(self,shape)</span>:</span></span><br><span class="line">        <span class="comment">#从截断的正态分布中输出随机值</span></span><br><span class="line">        initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</span><br><span class="line">        <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#初始化偏置</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(self,shape)</span>:</span></span><br><span class="line">        <span class="comment">#设置常数为0.1</span></span><br><span class="line">        initial = tf.constant(<span class="number">0.1</span>, shape=shape)</span><br><span class="line">        <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#二维卷积运算</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(self,x, W)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>], padding=<span class="string">"SAME"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最大值池化</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],</span><br><span class="line">                              strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>], padding=<span class="string">"SAME"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.learning_rate = <span class="number">0.001</span></span><br><span class="line">        <span class="comment"># 记录已经训练的次数</span></span><br><span class="line">        self.global_step = tf.Variable(<span class="number">0</span>, trainable=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">        self.x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>])</span><br><span class="line">        self.label = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>])</span><br><span class="line">        self.x_image = tf.reshape(self.x, [<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment">#第一层</span></span><br><span class="line">        self.w1 = self.weight_variable([<span class="number">5</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">32</span>])<span class="comment">#5×5的卷积核 32种特征</span></span><br><span class="line">        self.b1 = self.bias_variable([<span class="number">32</span>])</span><br><span class="line">        self.h1 = tf.nn.relu(self.conv2d(self.x_image, self.w1) + self.b1)</span><br><span class="line">        self.h_pool1 = self.max_pool_2x2(self.h1) <span class="comment">#池化</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#第二层</span></span><br><span class="line">        self.w2 = self.weight_variable([<span class="number">5</span>,<span class="number">5</span>,<span class="number">32</span>,<span class="number">64</span>])</span><br><span class="line">        self.b2 = self.bias_variable([<span class="number">64</span>])</span><br><span class="line">        self.h_conv2 = tf.nn.relu(self.conv2d(self.h_pool1, self.w2) + self.b2)</span><br><span class="line">        self.h_pool2 = self.max_pool_2x2(self.h_conv2)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#全连接</span></span><br><span class="line">        self.W_fc1 = self.weight_variable([<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>, <span class="number">1024</span>])</span><br><span class="line">        self.b_fc1 = self.bias_variable([<span class="number">1024</span>])</span><br><span class="line">        self.h_pool2_flat = tf.reshape(self.h_pool2, [<span class="number">-1</span>, <span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</span><br><span class="line">        self.h_fc1 = tf.nn.relu(tf.matmul(self.h_pool2_flat, self.W_fc1) + self.b_fc1)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#输出</span></span><br><span class="line">        <span class="comment">#keep_prob=0.5</span></span><br><span class="line">        <span class="comment">#self.h_fc1_drop = tf.nn.dropout(self.h_fc1, keep_prob)</span></span><br><span class="line">        self.W_fc2 = self.weight_variable([<span class="number">1024</span>, <span class="number">10</span>])</span><br><span class="line">        self.b_fc2 = self.bias_variable([<span class="number">10</span>])</span><br><span class="line">        self.y = tf.nn.softmax(tf.matmul(self.h_fc1, self.W_fc2) + self.b_fc2)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#loss</span></span><br><span class="line">        self.loss = -tf.reduce_sum(self.label * tf.log(self.y + <span class="number">1e-10</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># minimize 可传入参数 global_step， 每次训练 global_step的值会增加1</span></span><br><span class="line">        <span class="comment"># 因此，可以通过计算self.global_step这个张量的值，知道当前训练了多少步</span></span><br><span class="line">        self.train = tf.train.AdamOptimizer(self.learning_rate).minimize(</span><br><span class="line">            self.loss, global_step=self.global_step)</span><br><span class="line"></span><br><span class="line">        predict = tf.equal(tf.argmax(self.label, <span class="number">1</span>), tf.argmax(self.y, <span class="number">1</span>))</span><br><span class="line">        self.accuracy = tf.reduce_mean(tf.cast(predict, <span class="string">"float"</span>))</span><br></pre></td></tr></table></figure></p><p>从代码中可以看出，实际上就是很简单的一个CNN的神经网楼，包含两个卷积层，一个全连接层和一个输出层，在网络定义中定义了训练方式，损失函数，预测函数已经精度，对于有tensorflow基础的同学来说应该相当简单；在定义好网络之后我们就需要添加模型训练的代码了：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#-*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"../mnist/MNIST_data/"</span>,one_hot=<span class="keyword">True</span>)</span><br><span class="line"><span class="keyword">from</span> cnnNetwork <span class="keyword">import</span> Network</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Train</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.net = Network()</span><br><span class="line">        self.sess = tf.Session()</span><br><span class="line">        self.sess.run(tf.global_variables_initializer())</span><br><span class="line">        self.data = mnist</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self)</span>:</span></span><br><span class="line">        batch_size = <span class="number">50</span></span><br><span class="line">        train_step = <span class="number">2000</span></span><br><span class="line">        <span class="comment"># 记录训练次数, 初始化为0</span></span><br><span class="line">        step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每隔1000步保存模型</span></span><br><span class="line">        save_interval = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># tf.train.Saver是用来保存训练结果的。</span></span><br><span class="line">        <span class="comment"># max_to_keep 用来设置最多保存多少个模型，默认是5</span></span><br><span class="line">        <span class="comment"># 如果保存的模型超过这个值，最旧的模型将被删除</span></span><br><span class="line">        saver = tf.train.Saver(max_to_keep=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        ckpt = tf.train.get_checkpoint_state(<span class="string">'./'</span>)</span><br><span class="line">        <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">            saver.restore(self.sess, ckpt.model_checkpoint_path)</span><br><span class="line">            <span class="comment"># 读取网络中的global_step的值，即当前已经训练的次数</span></span><br><span class="line">            step = self.sess.run(self.net.global_step)</span><br><span class="line">            print(<span class="string">'Continue from'</span>)</span><br><span class="line">            print(<span class="string">'        -&gt; Minibatch update : '</span>, step)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> step &lt; train_step:</span><br><span class="line">            x, label = self.data.train.next_batch(batch_size)</span><br><span class="line">            _, loss = self.sess.run([self.net.train, self.net.loss],</span><br><span class="line">                                    feed_dict=&#123;self.net.x: x, self.net.label: label&#125;)</span><br><span class="line">            step = self.sess.run(self.net.global_step)</span><br><span class="line">            <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">'第%5d步，当前loss：%.2f'</span> % (step, loss))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 模型保存在ckpt文件夹下</span></span><br><span class="line">            <span class="comment"># 模型文件名最后会增加global_step的值，比如1000的模型文件名为 model-1000</span></span><br><span class="line">            <span class="comment">#if step % save_interval == 0:</span></span><br><span class="line">        saver.save(self.sess, <span class="string">'model'</span>, global_step=step)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calculate_accuracy</span><span class="params">(self)</span>:</span></span><br><span class="line">        test_x = self.data.test.images</span><br><span class="line">        test_label = self.data.test.labels</span><br><span class="line">        accuracy = self.sess.run(self.net.accuracy,</span><br><span class="line">                                 feed_dict=&#123;self.net.x: test_x, self.net.label: test_label&#125;)</span><br><span class="line">        print(<span class="string">"准确率: %.2f，共测试了%d张图片 "</span> % (accuracy, len(test_label)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    app = Train()</span><br><span class="line">    app.train()</span><br><span class="line">    app.calculate_accuracy()</span><br></pre></td></tr></table></figure></p><p>额，实际上也没有什么好说的，主要有几点要注意，首先是定义训练的步长，第二点是在训练过程中如果可以尽量保存训练中间步骤，这样可以避免在长时间的训练过程中突然出现异常，则可以从上一次保存的训练参数开始重新训练以节省时间，在以上代码中并没有保存训练结果，不过保存训练结果是有必要，所以在以后训练大型网络模型的时候还是要尽量隔一定时间或者一定步长后保存训练结果，至于训练结果的保存方法，我们在前一次已经详细讨论过，在这里就不进行讨论了；在训练过程中每次训练的数据集大小和训练步长都可以自己设定，这个就没有什么好说的，只是将以前CNN的过程拆分而已；最后的部分就是预测部分，这一部分比较重要，实际上如果要作为服务调用，我们主要也是调用预测这一模块，因此我会比较详细的分析预测部分的代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"../mnist/MNIST_data/"</span>,one_hot = <span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> cnnNetwork <span class="keyword">import</span> Network</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Predict</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.net = Network()</span><br><span class="line">        self.sess = tf.Session()</span><br><span class="line">        self.sess.run(tf.global_variables_initializer())</span><br><span class="line">        self.data = mnist</span><br><span class="line">        <span class="comment"># 加载模型到sess中</span></span><br><span class="line">        self.restore()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">restore</span><span class="params">(self)</span>:</span></span><br><span class="line">        saver = tf.train.Saver()</span><br><span class="line">        ckpt = tf.train.get_checkpoint_state(<span class="string">'./'</span>)</span><br><span class="line">        <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">            saver.restore(self.sess, ckpt.model_checkpoint_path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> FileNotFoundError(<span class="string">"未保存任何模型"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, image_path)</span>:</span></span><br><span class="line">        <span class="comment"># 读图片并转为黑白的</span></span><br><span class="line">        x, label = self.data.train.next_batch(<span class="number">10</span>)</span><br><span class="line">        y = self.sess.run(self.net.y, feed_dict=&#123;self.net.x: x&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 因为x只传入了一张图片，取y[0]即可</span></span><br><span class="line">        <span class="comment"># np.argmax()取得独热编码最大值的下标，即代表的数字</span></span><br><span class="line">        print(<span class="string">'        -&gt; Predict digit'</span>, np.argmax(y[<span class="number">0</span>]))</span><br><span class="line">        print(<span class="string">'        -&gt; Predict digit'</span>, np.argmax(y[<span class="number">1</span>]))</span><br><span class="line">        print(<span class="string">'        -&gt; Predict digit'</span>, np.argmax(y[<span class="number">2</span>]))</span><br><span class="line">        print(<span class="string">'        -&gt; Predict digit'</span>, np.argmax(y[<span class="number">3</span>]))</span><br><span class="line">        print(<span class="string">'        -&gt; Predict digit'</span>, np.argmax(y[<span class="number">4</span>]))</span><br><span class="line">        print(<span class="string">'        -&gt; Predict digit'</span>, np.argmax(y[<span class="number">5</span>]))</span><br><span class="line"></span><br><span class="line">        print(label)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    app = Predict()</span><br><span class="line">    app.predict(<span class="string">'./'</span>)</span><br></pre></td></tr></table></figure></p><p>实际在应用过程中应该是读取影像进行预测，不过为了检测模型我这里直接还是用MNIST数据集进行预测，预测部分主要有两个模块第一个模块是读取模型的模块，实际上也很简单就是读取模型，不过与上一次不同的是，由于这一次我们将网络的定义独立了，因此我们可以直接读取模型进行计算；第二个部分就是预测部分，我们看到，实际上我们在预测过程中通过sess的run函数传递了两个参数，一个是net中的ｙ，这个参数是没有值的，一个是net中的ｘ，这个参数是通过MNIST数据集进行初始化的，理论上来说我们的输入只需要一个x为什么还需要y？我理解是告诉tensorflow输出和输出参数，y是预测结果，而ｘ是待预测的数据，因此需要输入两个参数．<br>由此整个训练和预测就结束了，下一节我们会讲讲如何通过python搭建简单的数据库，给出RESTFUL风格的API接口进行预测，另外模型预测部分的代码也会进行适当的修改以适应图像识别的需求．</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在上次的学习中我学习了如何读取模型，现在我们已经了解了如何训练和如何读取模型，于是我就想做一些真正的应用，如何才能将机器学习应用起来，或者说如何给别人用，这个是需要思考的问题，结合前一段时间学习的通过python搭建服务器，我想到，是不是可以将我们的深度学习的模型也打一个包
      
    
    </summary>
    
      <category term="学习" scheme="http://www.wuweiblog.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow学习" scheme="http://www.wuweiblog.com/tags/tensorflow%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow-二十三弹</title>
    <link href="http://www.wuweiblog.com/2018/02/25/tensorflow-%E4%BA%8C%E5%8D%81%E4%B8%89%E5%BC%B9/"/>
    <id>http://www.wuweiblog.com/2018/02/25/tensorflow-二十三弹/</id>
    <published>2018-02-25T12:54:40.000Z</published>
    <updated>2018-02-25T14:04:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>今天就tensorflow训练好的模型的存取问题进行一些讨论，主要翻译了一下一篇英文博客，另外加上了一些自己的尝试和处理经验，英文博客的地址为：<a href="http://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/" target="_blank" rel="noopener">http://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/</a>　这个是官方的一个说明，我先翻译这个文章，如果英文好的可以直接跳过，主要内容为：<br>文章主要分为四个部分，第一个部分的介绍我们不进行翻译，相信对tensorflow有基本了解的同学都能懂，另外前几篇博客中都有介绍，我直接从第二个部分开始翻译：</p><h2 id="２．tensorflow模型的保存"><a href="#２．tensorflow模型的保存" class="headerlink" title="２．tensorflow模型的保存"></a>２．tensorflow模型的保存</h2><p>我们说如果对于一个图像分类的应用，训练了一个卷积神经网络．在训练的过程中我们可以查看loss和accuracy变量，一旦训练完成则可以手动停止训练过程，或者参数不再变化后停止训练过程．当训练完成后需要将训练结果保存起来以便于以后进行应用，而在tensorflow中如果你希望保存整个网络图和所有变量，我们需要创建一个tf.train.Saver()类的实例，如下：<br>saver = tf.train.Saver()<br>记住，tensorflow的变量只有在session中才被激活，因此如果希望保存图，则必须要在session中调用创建的saver变量<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">saver = tf.train.Saver()</span><br><span class="line">saver.save(sess, <span class="string">'my-test-model'</span>)</span><br></pre></td></tr></table></figure></p><p>在这里，sess是session的一个对象，‘my-test-model’是你想保存模型的文件名，下面是完整的代码示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">w1 = tf.Variable(tf.random_normal(shape=[<span class="number">2</span>]), name=<span class="string">'w1'</span>)</span><br><span class="line">w2 = tf.Variable(tf.random_normal(shape=[<span class="number">5</span>]), name=<span class="string">'w2'</span>)</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">saver.save(sess, <span class="string">'my_test_model'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># This will save following files in Tensorflow v &gt;= 0.11</span></span><br><span class="line"><span class="comment"># my_test_model.data-00000-of-00001</span></span><br><span class="line"><span class="comment"># my_test_model.index</span></span><br><span class="line"><span class="comment"># my_test_model.meta</span></span><br><span class="line"><span class="comment"># checkpoint</span></span><br></pre></td></tr></table></figure></p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">w1 = tf.Variable(tf.random_normal(shape=[<span class="number">2</span>]), name=<span class="string">'w1'</span>)</span><br><span class="line">w2 = tf.Variable(tf.random_normal(shape=[<span class="number">5</span>]), name=<span class="string">'w2'</span>)</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">saver.save(sess, <span class="string">'my_test_model'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># This will save following files in Tensorflow v &gt;= 0.11</span></span><br><span class="line"><span class="comment"># my_test_model.data-00000-of-00001</span></span><br><span class="line"><span class="comment"># my_test_model.index</span></span><br><span class="line"><span class="comment"># my_test_model.meta</span></span><br><span class="line"><span class="comment"># checkpoint</span></span><br></pre></td></tr></table></figure><p>如果我们想在模型训练一千次后将模型保存，我们可以通过如下代码实现：<br>saver.save(sess, ‘my_test_model’,global_step=1000)<br>以上代码会在模型名称后添加‘-1000’的后缀，另外如下文件将会被创建：</p><p>my_test_model-1000.index<br>my_test_model-1000.meta<br>my_test_model-1000.data-00000-of-00001<br>checkpoint  </p><p>my_test_model-1000.index<br>my_test_model-1000.meta<br>my_test_model-1000.data-00000-of-00001<br>checkpoint  </p><p>在训练过程中我们希望每迭代1000次就保存一次模型，但是.meta文件只会在最开始被创建一次，我们不需要多次创建，我们只需要将最近一次的迭代参数写入文件中，当我们不想将训练参数写入文件中时我们可以通过如下代码实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">saver.save(sess, <span class="string">'my-model'</span>, global_step=step,write_meta_graph=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">saver.save(sess, <span class="string">'my-model'</span>, global_step=step,write_meta_graph=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure></p><p>If you want to keep only 4 latest models and want to save one model after every 2 hours during training you can use max_to_keep and keep_checkpoint_every_n_hours like this.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#saves a model every 2 hours and maximum 4 latest models are saved.</span></span><br><span class="line">saver = tf.train.Saver(max_to_keep=<span class="number">4</span>, keep_checkpoint_every_n_hours=<span class="number">2</span>)</span><br></pre></td></tr></table></figure> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#saves a model every 2 hours and maximum 4 latest models are saved.</span></span><br><span class="line">saver = tf.train.Saver(max_to_keep=<span class="number">4</span>, keep_checkpoint_every_n_hours=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>注意，我们在保存过程中没有对任何变量进行指定，在这样的情况下会保存所有变量，如果我们不想保存所有变量，我们可以在创建实例的时候指出哪些变量是需要保存的，示例代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">w1 = tf.Variable(tf.random_normal(shape=[<span class="number">2</span>]), name=<span class="string">'w1'</span>)</span><br><span class="line">w2 = tf.Variable(tf.random_normal(shape=[<span class="number">5</span>]), name=<span class="string">'w2'</span>)</span><br><span class="line">saver = tf.train.Saver([w1,w2])</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">saver.save(sess, <span class="string">'my_test_model'</span>,global_step=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure></p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">w1 = tf.Variable(tf.random_normal(shape=[<span class="number">2</span>]), name=<span class="string">'w1'</span>)</span><br><span class="line">w2 = tf.Variable(tf.random_normal(shape=[<span class="number">5</span>]), name=<span class="string">'w2'</span>)</span><br><span class="line">saver = tf.train.Saver([w1,w2])</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">saver.save(sess, <span class="string">'my_test_model'</span>,global_step=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure><p>通过以上方法可以指定graph中所有部分的变量</p><h2 id="3-导入训练好的模型"><a href="#3-导入训练好的模型" class="headerlink" title="3. 导入训练好的模型:"></a>3. 导入训练好的模型:</h2><p>如果你想使用他人训练好的模型，你需要做以下两件事情：<br>a) 创建网络网络:<br>你可以通过编写python代码手动创建与原始模型一样的网络，或者如果你觉得这么做太麻烦，由于我们将网络结构已经保存在meta文件中，因此我们可以直接导入网络模型：<br>saver = tf.train.import_meta_graph(‘my_test_model-1000.meta’)<br>记住，在.meta文件中只保存了网络结构，因此在导入网络后还需要加载在图中训练的参数</p><p>b) 加载模型参数:<br>我们在保存网络的过程中也保存了网络参数，因此我们可以通过tf.train.Saver()类的实例来读取神经网络的参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  new_saver = tf.train.import_meta_graph(<span class="string">'my_test_model-1000.meta'</span>)</span><br><span class="line">  new_saver.restore(sess, tf.train.latest_checkpoint(<span class="string">'./'</span>))</span><br></pre></td></tr></table></figure> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  new_saver = tf.train.import_meta_graph(<span class="string">'my_test_model-1000.meta'</span>)</span><br><span class="line">  new_saver.restore(sess, tf.train.latest_checkpoint(<span class="string">'./'</span>))</span><br></pre></td></tr></table></figure><p>加载参数后我们如果想要获取某一个张量可以通过如下代码实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:    </span><br><span class="line">    saver = tf.train.import_meta_graph(<span class="string">'my-model-1000.meta'</span>)</span><br><span class="line">    saver.restore(sess,tf.train.latest_checkpoint(<span class="string">'./'</span>))</span><br><span class="line">    print(sess.run(<span class="string">'w1:0'</span>))</span><br><span class="line"><span class="comment">##Model has been restored. Above statement will print the saved value of w1.</span></span><br></pre></td></tr></table></figure></p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:    </span><br><span class="line">    saver = tf.train.import_meta_graph(<span class="string">'my-model-1000.meta'</span>)</span><br><span class="line">    saver.restore(sess,tf.train.latest_checkpoint(<span class="string">'./'</span>))</span><br><span class="line">    print(sess.run(<span class="string">'w1:0'</span>))</span><br><span class="line"><span class="comment">##Model has been restored. Above statement will print the saved value of w1.</span></span><br></pre></td></tr></table></figure><p>到目前为止，你已经了解了如何保存和导入tensorflow的模型，在下一章中会详细说明如何去使用和加载训练号的模型</p><h2 id="4-加载训练好的模型的实例"><a href="#4-加载训练好的模型的实例" class="headerlink" title="4. 加载训练好的模型的实例"></a>4. 加载训练好的模型的实例</h2><p>现在你应该已经知道如何保存和加载模型了，我们进一步说明如何加载训练好的模型以及如何通过模型进行预测，拟合或通过模型进行进一步的训练．在使用tensorflow训练的过程中定义的计算图中包括训练数据以及一些高维变量如学习率，训练步数等．标准的做法是所有变量都使用placeholders来定义，我们首先创建一个网络然后保存网络，网络保存后placeholders定义的变量的值不会被存储</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#Prepare to feed input, i.e. feed_dict and placeholders</span></span><br><span class="line">w1 = tf.placeholder(<span class="string">"float"</span>, name=<span class="string">"w1"</span>)</span><br><span class="line">w2 = tf.placeholder(<span class="string">"float"</span>, name=<span class="string">"w2"</span>)</span><br><span class="line">b1= tf.Variable(<span class="number">2.0</span>,name=<span class="string">"bias"</span>)</span><br><span class="line">feed_dict =&#123;w1:<span class="number">4</span>,w2:<span class="number">8</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Define a test operation that we will restore</span></span><br><span class="line">w3 = tf.add(w1,w2)</span><br><span class="line">w4 = tf.multiply(w3,b1,name=<span class="string">"op_to_restore"</span>)</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line"><span class="comment">#Create a saver object which will save all the variables</span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="comment">#Run the operation by feeding input</span></span><br><span class="line"><span class="keyword">print</span> sess.run(w4,feed_dict)</span><br><span class="line"><span class="comment">#Prints 24 which is sum of (w1+w2)*b1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Now, save the graph</span></span><br><span class="line">saver.save(sess, <span class="string">'my_test_model'</span>,global_step=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">#Prepare to feed input, i.e. feed_dict and placeholders</span></span><br><span class="line">w1 = tf.placeholder(<span class="string">"float"</span>, name=<span class="string">"w1"</span>)</span><br><span class="line">w2 = tf.placeholder(<span class="string">"float"</span>, name=<span class="string">"w2"</span>)</span><br><span class="line">b1= tf.Variable(<span class="number">2.0</span>,name=<span class="string">"bias"</span>)</span><br><span class="line">feed_dict =&#123;w1:<span class="number">4</span>,w2:<span class="number">8</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Define a test operation that we will restore</span></span><br><span class="line">w3 = tf.add(w1,w2)</span><br><span class="line">w4 = tf.multiply(w3,b1,name=<span class="string">"op_to_restore"</span>)</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line"><span class="comment">#Create a saver object which will save all the variables</span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="comment">#Run the operation by feeding input</span></span><br><span class="line"><span class="keyword">print</span> sess.run(w4,feed_dict)</span><br><span class="line"><span class="comment">#Prints 24 which is sum of (w1+w2)*b1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Now, save the graph</span></span><br><span class="line">saver.save(sess, <span class="string">'my_test_model'</span>,global_step=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure><p>现在当我们想要保存模型的时候我们只需要保存图和权重，另外准备一个新的feed_dict就可以使用心得数据训练网络了，另外我们也可以获取到村包的操作和placeholder变量通过graph.get_tensor_by_name()方法</p><ul><li><p>How to access saved variable/Tensor/placeholders</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w1 = graph.get_tensor_by_name(<span class="string">"w1:0"</span>)</span><br></pre></td></tr></table></figure></li><li><p>How to access saved operation</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">op_to_restore = graph.get_tensor_by_name(<span class="string">"op_to_restore:0"</span>)</span><br></pre></td></tr></table></figure></li><li><p>How to access saved variable/Tensor/placeholders</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w1 = graph.get_tensor_by_name(<span class="string">"w1:0"</span>)</span><br></pre></td></tr></table></figure></li><li><p>How to access saved operation</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">op_to_restore = graph.get_tensor_by_name(<span class="string">"op_to_restore:0"</span>)</span><br></pre></td></tr></table></figure></li></ul><p>如果我们只是想对于不同的训练数据使用模型训练，则我们只需要简单的通过feed_dict传递参数就好了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">sess=tf.Session()    </span><br><span class="line"><span class="comment">#First let's load meta graph and restore weights</span></span><br><span class="line">saver = tf.train.import_meta_graph(<span class="string">'my_test_model-1000.meta'</span>)</span><br><span class="line">saver.restore(sess,tf.train.latest_checkpoint(<span class="string">'./'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, let's access and create placeholders variables and</span></span><br><span class="line"><span class="comment"># create feed-dict to feed new data</span></span><br><span class="line"></span><br><span class="line">graph = tf.get_default_graph()</span><br><span class="line">w1 = graph.get_tensor_by_name(<span class="string">"w1:0"</span>)</span><br><span class="line">w2 = graph.get_tensor_by_name(<span class="string">"w2:0"</span>)</span><br><span class="line">feed_dict =&#123;w1:<span class="number">13.0</span>,w2:<span class="number">17.0</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Now, access the op that you want to run.</span></span><br><span class="line">op_to_restore = graph.get_tensor_by_name(<span class="string">"op_to_restore:0"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> sess.run(op_to_restore,feed_dict)</span><br><span class="line"><span class="comment">#This will print 60 which is calculated</span></span><br><span class="line"><span class="comment">#using new values of w1 and w2 and saved value of b1.</span></span><br></pre></td></tr></table></figure> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">sess=tf.Session()    </span><br><span class="line"><span class="comment">#First let's load meta graph and restore weights</span></span><br><span class="line">saver = tf.train.import_meta_graph(<span class="string">'my_test_model-1000.meta'</span>)</span><br><span class="line">saver.restore(sess,tf.train.latest_checkpoint(<span class="string">'./'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, let's access and create placeholders variables and</span></span><br><span class="line"><span class="comment"># create feed-dict to feed new data</span></span><br><span class="line"></span><br><span class="line">graph = tf.get_default_graph()</span><br><span class="line">w1 = graph.get_tensor_by_name(<span class="string">"w1:0"</span>)</span><br><span class="line">w2 = graph.get_tensor_by_name(<span class="string">"w2:0"</span>)</span><br><span class="line">feed_dict =&#123;w1:<span class="number">13.0</span>,w2:<span class="number">17.0</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Now, access the op that you want to run.</span></span><br><span class="line">op_to_restore = graph.get_tensor_by_name(<span class="string">"op_to_restore:0"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> sess.run(op_to_restore,feed_dict)</span><br><span class="line"><span class="comment">#This will print 60 which is calculated</span></span><br><span class="line"><span class="comment">#using new values of w1 and w2 and saved value of b1.</span></span><br></pre></td></tr></table></figure><p>如果你需要在原始的模型基础上添加更多的操作，添加更多层进行重新训练，则代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">sess=tf.Session()    </span><br><span class="line"><span class="comment">#First let's load meta graph and restore weights</span></span><br><span class="line">saver = tf.train.import_meta_graph(<span class="string">'my_test_model-1000.meta'</span>)</span><br><span class="line">saver.restore(sess,tf.train.latest_checkpoint(<span class="string">'./'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">* Now, let<span class="string">'s access and create placeholders variables and</span></span><br><span class="line"><span class="string">* create feed-dict to feed new data</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">graph = tf.get_default_graph()</span></span><br><span class="line"><span class="string">w1 = graph.get_tensor_by_name("w1:0")</span></span><br><span class="line"><span class="string">w2 = graph.get_tensor_by_name("w2:0")</span></span><br><span class="line"><span class="string">feed_dict =&#123;w1:13.0,w2:17.0&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">* Now, access the op that you want to run.</span></span><br><span class="line"><span class="string">op_to_restore = graph.get_tensor_by_name("op_to_restore:0")</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">* Add more to the current graph</span></span><br><span class="line"><span class="string">add_on_op = tf.multiply(op_to_restore,2)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">print sess.run(add_on_op,feed_dict)</span></span><br><span class="line"><span class="string">* This will print 120.</span></span><br></pre></td></tr></table></figure></p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">sess=tf.Session()    </span><br><span class="line">* First let<span class="string">'s load meta graph and restore weights</span></span><br><span class="line"><span class="string">saver = tf.train.import_meta_graph('</span>my_test_model<span class="number">-1000.</span>meta<span class="string">')</span></span><br><span class="line"><span class="string">saver.restore(sess,tf.train.latest_checkpoint('</span>./<span class="string">'))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">* Now, let'</span>s access <span class="keyword">and</span> create placeholders variables <span class="keyword">and</span></span><br><span class="line">* create feed-dict to feed new data</span><br><span class="line"></span><br><span class="line">graph = tf.get_default_graph()</span><br><span class="line">w1 = graph.get_tensor_by_name(<span class="string">"w1:0"</span>)</span><br><span class="line">w2 = graph.get_tensor_by_name(<span class="string">"w2:0"</span>)</span><br><span class="line">feed_dict =&#123;w1:<span class="number">13.0</span>,w2:<span class="number">17.0</span>&#125;</span><br><span class="line"></span><br><span class="line">* Now, access the op that you want to run.</span><br><span class="line">op_to_restore = graph.get_tensor_by_name(<span class="string">"op_to_restore:0"</span>)</span><br><span class="line"></span><br><span class="line">* Add more to the current graph</span><br><span class="line">add_on_op = tf.multiply(op_to_restore,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> sess.run(add_on_op,feed_dict)</span><br><span class="line">* This will <span class="keyword">print</span> <span class="number">120.</span></span><br></pre></td></tr></table></figure><p>另外你也可以保存部分就的网络结构并添加新的结构去训练更好的网络<br>……<br>……<br>saver = tf.train.import_meta_graph(‘vgg.meta’)</p><ul><li>Access the graph<br>graph = tf.get_default_graph()</li><li><p>Prepare the feed_dict for feeding data for fine-tuning</p></li><li><p>Access the appropriate output for fine-tuning<br>fc7= graph.get_tensor_by_name(‘fc7:0’)</p></li><li><p>use this if you only want to change gradients of the last layer</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">fc7 = tf.stop_gradient(fc7) <span class="comment"># It's an identity function</span></span><br><span class="line">fc7_shape= fc7.get_shape().as_list()</span><br><span class="line"></span><br><span class="line">new_outputs=<span class="number">2</span></span><br><span class="line">weights = tf.Variable(tf.truncated_normal([fc7_shape[<span class="number">3</span>], num_outputs], stddev=<span class="number">0.05</span>))</span><br><span class="line">biases = tf.Variable(tf.constant(<span class="number">0.05</span>, shape=[num_outputs]))</span><br><span class="line">output = tf.matmul(fc7, weights) + biases</span><br><span class="line">pred = tf.nn.softmax(output)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, you run this with fine-tuning data in sess.run()</span></span><br></pre></td></tr></table></figure></li></ul><p>……<br>……<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">saver = tf.train.import_meta_graph(<span class="string">'vgg.meta'</span>)</span><br></pre></td></tr></table></figure></p><p>Access the graph<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">* graph = tf.get_default_graph()</span><br></pre></td></tr></table></figure></p><ul><li><p>Prepare the feed_dict for feeding data for fine-tuning</p></li><li><p>Access the appropriate output for fine-tuning</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fc7= graph.get_tensor_by_name(<span class="string">'fc7:0'</span>)</span><br></pre></td></tr></table></figure></li><li><p>use this if you only want to change gradients of the last layer</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">fc7 = tf.stop_gradient(fc7) <span class="comment"># It's an identity function</span></span><br><span class="line">fc7_shape= fc7.get_shape().as_list()</span><br><span class="line"></span><br><span class="line">new_outputs=<span class="number">2</span></span><br><span class="line">weights = tf.Variable(tf.truncated_normal([fc7_shape[<span class="number">3</span>], num_outputs], stddev=<span class="number">0.05</span>))</span><br><span class="line">biases = tf.Variable(tf.constant(<span class="number">0.05</span>, shape=[num_outputs]))</span><br><span class="line">output = tf.matmul(fc7, weights) + biases</span><br><span class="line">pred = tf.nn.softmax(output)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, you run this with fine-tuning data in sess.run()</span></span><br></pre></td></tr></table></figure><p>以上就是全部翻译，但是在实际处理过程中遇到了一些问题，实际上在深度学习的应用过程中我们的变量可能定义如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'input'</span>):</span><br><span class="line">    x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>],name = <span class="string">'x-input'</span>)</span><br><span class="line">    y = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>, <span class="number">10</span>],name=<span class="string">'y-input'</span>)</span><br><span class="line">    x_image = tf.reshape(x,[<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>],name=<span class="string">'img'</span>)</span><br><span class="line">    tf.summary.image(<span class="string">'image'</span>,x_image,<span class="number">20</span>)</span><br></pre></td></tr></table></figure></p><p>通过with结构进行区分，在此情况下get_tensor_by_name函数获取变量的过程中需要添加上with的结构进行区分，否则无法获取到变量．整个tensorflow模型的保存和加载就介绍如下．</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天就tensorflow训练好的模型的存取问题进行一些讨论，主要翻译了一下一篇英文博客，另外加上了一些自己的尝试和处理经验，英文博客的地址为：&lt;a href=&quot;http://cv-tricks.com/tensorflow-tutorial/save-restore-te
      
    
    </summary>
    
      <category term="学习" scheme="http://www.wuweiblog.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow学习" scheme="http://www.wuweiblog.com/tags/tensorflow%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
